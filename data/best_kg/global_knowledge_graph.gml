graph [
  directed 1
  node [
    id 0
    label "Transformer"
    type "architecture"
    documents "attention_is_all_you_need,deit,gpt3_language_models,gpt3,palm,reformer"
    mentions 6
    aliases "transformer,Transformer"
    description "A new network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 1
    label "Attention Mechanism"
    type "method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Attention Mechanism"
    description "A mechanism that allows modeling of dependencies without regard to their distance in input or output sequences."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 2
    label "BLEU"
    type "metric"
    documents "attention_is_all_you_need,gpt3_language_models,gpt3"
    mentions 3
    aliases "BLEU"
    description "A metric for evaluating the quality of machine translation by comparing a machine's output with a reference output."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 3
    label "WMT 2014 English-to-German"
    type "dataset"
    documents "attention_is_all_you_need,attention_is_all_you_need"
    mentions 2
    aliases "WMT 2014 English-to-German,WMT 2014 English-German dataset"
    description "A dataset used for evaluating machine translation performance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 4
    label "WMT 2014 English-to-French"
    type "dataset"
    documents "attention_is_all_you_need,attention_is_all_you_need"
    mentions 2
    aliases "WMT 2014 English-to-French,WMT 2014 English-French dataset"
    description "A dataset used for evaluating machine translation performance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 5
    label "Google Brain"
    type "organization"
    documents "attention_is_all_you_need,transformer_xl"
    mentions 2
    aliases "Google Brain"
    description "A deep learning research team at Google."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 6
    label "Google Research"
    type "organization"
    documents "attention_is_all_you_need,deit,palm,reformer,vision_transformer"
    mentions 5
    aliases "Google Research"
    description "A research division of Google focusing on various scientific and technological advancements."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 7
    label "Ashish Vaswani"
    type "person"
    documents "attention_is_all_you_need,deit,reformer"
    mentions 3
    aliases "Ashish Vaswani"
    description "One of the authors who designed and implemented the first Transformer models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 8
    label "Noam Shazeer"
    type "person"
    documents "attention_is_all_you_need,deit,reformer"
    mentions 3
    aliases "Noam Shazeer"
    description "One of the authors who proposed scaled dot-product attention and multi-head attention."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 9
    label "Niki Parmar"
    type "person"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Niki Parmar"
    description "One of the authors involved in the design and implementation of the Transformer."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 10
    label "Jakob Uszkoreit"
    type "person"
    documents "attention_is_all_you_need,deit,reformer,vision_transformer"
    mentions 4
    aliases "Jakob Uszkoreit"
    description "One of the authors who proposed replacing RNNs with self-attention."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 11
    label "Llion Jones"
    type "person"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Llion Jones"
    description "One of the authors responsible for the initial codebase and efficient inference."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 12
    label "Aidan N. Gomez"
    type "person"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Aidan N. Gomez"
    description "One of the authors involved in designing various parts of the Tensor2Tensor framework."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 13
    label "&#321;ukasz Kaiser"
    type "person"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "&#321;ukasz Kaiser"
    description "One of the authors who contributed to the design and implementation of Tensor2Tensor."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 14
    label "Illia Polosukhin"
    type "person"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Illia Polosukhin"
    description "One of the authors who contributed to the design and implementation of the Transformer."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 15
    label "Encoder"
    type "Architecture"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Encoder"
    description "A component of the model composed of a stack of identical layers with multi-head self-attention and feed-forward networks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 16
    label "Decoder"
    type "Architecture"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Decoder"
    description "A component of the model that generates output sequences, incorporating attention mechanisms over encoder outputs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 17
    label "Multi-Head Attention"
    type "Method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Multi-Head Attention"
    description "An attention mechanism that allows the model to jointly attend to information from different representation subspaces."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 18
    label "Scaled Dot-Product Attention"
    type "Method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Scaled Dot-Product Attention"
    description "An attention function that computes a weighted sum of values based on the compatibility of queries and keys."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 19
    label "Residual Connection"
    type "Method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Residual Connection"
    description "A technique used to facilitate training by allowing gradients to flow through the network more easily."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 20
    label "Layer Normalization"
    type "Method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Layer Normalization"
    description "A normalization technique applied to the outputs of sub-layers to stabilize and accelerate training."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 21
    label "Feed-Forward Network"
    type "Method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Feed-Forward Network"
    description "A fully connected network applied to each position separately in the encoder and decoder."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 22
    label "Embedding Layer"
    type "Architecture"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Embedding Layer"
    description "A layer that converts input tokens and output tokens into vector representations."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 23
    label "Softmax Function"
    type "Method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Softmax Function"
    description "A function used to convert decoder outputs into predicted next-token probabilities."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 24
    label "Attention Function"
    type "Method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Attention Function"
    description "A function that maps queries and key-value pairs to an output."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 25
    label "ReLU Activation"
    type "Method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "ReLU Activation"
    description "An activation function used in feed-forward networks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 26
    label "Attention(Q, K, V)"
    type "Function"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Attention(Q, K, V)"
    description "The mathematical representation of the attention mechanism."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 27
    label "d_model"
    type "Metric"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "d_model"
    description "The dimensionality of the model's representations."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 28
    label "n"
    type "Metric"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "n"
    description "The sequence length."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 29
    label "k"
    type "Metric"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "k"
    description "The kernel size of convolutions."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 30
    label "r"
    type "Metric"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "r"
    description "The size of the neighborhood in restricted self-attention."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 31
    label "Self-Attention"
    type "method"
    documents "attention_is_all_you_need,reformer"
    mentions 2
    aliases "Self-Attention,Self-attention"
    description "A mechanism that allows the model to weigh the importance of different tokens in a sequence."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 32
    label "Recurrent Neural Network (RNN)"
    type "architecture"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Recurrent Neural Network (RNN)"
    description "A type of neural network designed for sequential data processing."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 33
    label "Convolutional Neural Network (CNN)"
    type "architecture"
    documents "attention_is_all_you_need,reformer,vision_transformer"
    mentions 3
    aliases "CNN (Convolutional Neural Network),Convolutional Neural Network (CNN)"
    description "A type of neural network primarily used for processing grid-like data such as images."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 34
    label "Positional Encoding"
    type "method"
    documents "attention_is_all_you_need,transformer_xl,transformer_xl"
    mentions 3
    aliases "Positional Encoding,relative positional encoding,positional encoding"
    description "A technique used to inject information about the position of tokens in a sequence."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 35
    label "Adam Optimizer"
    type "method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Adam Optimizer"
    description "An optimization algorithm used for training machine learning models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 36
    label "BLEU Score"
    type "metric"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "BLEU Score"
    description "A metric for evaluating the quality of text which has been machine-translated."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 37
    label "Byte-Pair Encoding"
    type "method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Byte-Pair Encoding"
    description "A data compression technique used for encoding text."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 38
    label "Word-Piece Vocabulary"
    type "method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Word-Piece Vocabulary"
    description "A subword tokenization method used in natural language processing."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 39
    label "Residual Dropout"
    type "method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Residual Dropout"
    description "A regularization technique applied to neural networks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 40
    label "Label Smoothing"
    type "method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Label Smoothing"
    description "A technique used during training to prevent overfitting by softening the target labels."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 41
    label "Separable Convolutions"
    type "method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Separable Convolutions"
    description "A type of convolution that reduces the computational complexity of standard convolutions."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 42
    label "NVIDIA P100 GPU"
    type "hardware"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "NVIDIA P100 GPU"
    description "A type of graphics processing unit used for training deep learning models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 43
    label "ConvS2SEnsemble"
    type "model"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "ConvS2SEnsemble"
    description "An ensemble model used for machine translation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 44
    label "WMT2014"
    type "dataset"
    documents "attention_is_all_you_need,attention_is_all_you_need"
    mentions 2
    aliases "WMT2014,WMT 2014"
    description "A benchmark dataset for machine translation tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 45
    label "P100 GPUs"
    type "hardware"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "P100 GPUs"
    description "A type of GPU used for training the models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 46
    label "Penn Treebank"
    type "dataset"
    documents "attention_is_all_you_need,transformer_xl"
    mentions 2
    aliases "Penn Treebank"
    description "A dataset used for English constituency parsing."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 47
    label "Wall Street Journal"
    type "dataset"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Wall Street Journal"
    description "A portion of the Penn Treebank used for training."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 48
    label "Beam Search"
    type "method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Beam Search"
    description "A search algorithm used during inference to generate translations."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 49
    label "Attention Heads"
    type "architecture component"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Attention Heads"
    description "Components of the Transformer that allow it to focus on different parts of the input."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 50
    label "Semi-supervised Setting"
    type "training method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Semi-supervised Setting"
    description "A training approach that uses both labeled and unlabeled data."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 51
    label "Vinyals &#38; Kaiser (2014)"
    type "publication"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Vinyals &#38; Kaiser (2014)"
    description "A reference for previous work in English constituency parsing."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 52
    label "Dyer et al. (2016)"
    type "publication"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Dyer et al. (2016)"
    description "A reference for previous work in English constituency parsing."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 53
    label "Zhu et al. (2013)"
    type "publication"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Zhu et al. (2013)"
    description "A reference for previous work in English constituency parsing."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 54
    label "Huang &#38; Harper (2009)"
    type "publication"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Huang &#38; Harper (2009)"
    description "A reference for previous work in English constituency parsing."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 55
    label "McClosky et al. (2006)"
    type "publication"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "McClosky et al. (2006)"
    description "A reference for previous work in English constituency parsing."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 56
    label "Luong et al. (2015)"
    type "publication"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Luong et al. (2015)"
    description "A reference for previous work in English constituency parsing."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 57
    label "attention-based models"
    type "method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "attention-based models"
    description "Models that use attention mechanisms to improve performance in tasks like translation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 58
    label "images"
    type "data type"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "images"
    description "Visual data type that the authors plan to apply their models to."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 59
    label "audio"
    type "data type"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "audio"
    description "Sound data type that the authors plan to apply their models to."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 60
    label "video"
    type "data type"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "video"
    description "Moving visual data type that the authors plan to apply their models to."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 61
    label "local, restricted attention mechanisms"
    type "method"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "local, restricted attention mechanisms"
    description "Attention mechanisms designed to efficiently handle large inputs and outputs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 62
    label "code repository"
    type "resource"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "code repository"
    description "GitHub repository for the code used to train and evaluate models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 63
    label "Nal Kalchbrenner"
    type "person"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Nal Kalchbrenner"
    description "Researcher acknowledged for comments and inspiration."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 64
    label "Stephan Gouws"
    type "person"
    documents "attention_is_all_you_need"
    mentions 1
    aliases "Stephan Gouws"
    description "Researcher acknowledged for comments and inspiration."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 65
    label "CLIP"
    type "model"
    documents "clip,segment_anything"
    mentions 2
    aliases "CLIP"
    description "A model that jointly trains an image encoder and a text encoder to predict correct pairings of image and text."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 66
    label "GPT-3"
    type "model"
    documents "clip,gpt3_language_models,gpt3,llama,palm,segment_anything"
    mentions 6
    aliases "GPT-3,GPT-4"
    description "A state-of-the-art language model that is competitive across many tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 67
    label "ImageNet"
    type "dataset"
    documents "clip,deit,reformer,vision_transformer,vision_transformer"
    mentions 5
    aliases "ImageNet,ImageNet ReaL"
    description "A large dataset used for image classification tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 68
    label "YFCC100M"
    type "dataset"
    documents "clip"
    mentions 1
    aliases "YFCC100M"
    description "A dataset containing images and associated metadata used for training models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 69
    label "ResNet-50"
    type "model"
    documents "clip,swin_transformer"
    mentions 2
    aliases "ResNet-50"
    description "A convolutional neural network architecture used for image classification."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 70
    label "VirTex"
    type "model"
    documents "clip"
    mentions 1
    aliases "VirTex"
    description "A model that uses natural language supervision for image representation learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 71
    label "ICMLM"
    type "model"
    documents "clip"
    mentions 1
    aliases "ICMLM"
    description "A model that employs masked language modeling for learning image representations."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 72
    label "ConVIRT"
    type "model"
    documents "clip"
    mentions 1
    aliases "ConVIRT"
    description "A model that uses contrastive objectives to learn image representations from text."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 73
    label "Dai &#38; Le"
    type "people"
    documents "clip"
    mentions 1
    aliases "Dai &#38; Le"
    description "Researchers who contributed to advancements in pre-training methods in NLP."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 74
    label "Peters et al."
    type "people"
    documents "clip"
    mentions 1
    aliases "Peters et al."
    description "Researchers who contributed to advancements in pre-training methods in NLP."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 75
    label "OpenAI"
    type "organization"
    documents "clip,gpt3_language_models,gpt3"
    mentions 3
    aliases "OpenAI"
    description "The organization behind the development of CLIP and other AI models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 76
    label "400 million (image, text) pairs"
    type "dataset"
    documents "clip"
    mentions 1
    aliases "400 million (image, text) pairs"
    description "A dataset used for training the model, consisting of image and text pairs collected from the internet."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 77
    label "OCR"
    type "task"
    documents "clip"
    mentions 1
    aliases "OCR"
    description "Optical Character Recognition, a task in computer vision."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 78
    label "geo-localization"
    type "task"
    documents "clip"
    mentions 1
    aliases "geo-localization"
    description "A task in computer vision that involves determining the geographic location of an image."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 79
    label "fine-grained object classification"
    type "task"
    documents "clip"
    mentions 1
    aliases "fine-grained object classification"
    description "A task in computer vision that involves classifying objects into very specific categories."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 80
    label "zero-shot transfer"
    type "method"
    documents "clip,gpt3_language_models"
    mentions 2
    aliases "zero-shot transfer"
    description "A method that allows a model to perform tasks without specific training on those tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 81
    label "JFT-300M"
    type "dataset"
    documents "clip,deit,reformer,swin_transformer,vision_transformer"
    mentions 5
    aliases "JFT-300M"
    description "A dataset with noisy labels used for training models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 82
    label "MS-COCO"
    type "dataset"
    documents "clip"
    mentions 1
    aliases "MS-COCO"
    description "A high-quality crowd-labeled dataset for image captioning and object detection."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 83
    label "Visual Genome"
    type "dataset"
    documents "clip"
    mentions 1
    aliases "Visual Genome"
    description "A dataset containing images and their associated descriptions."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 84
    label "GPT"
    type "architecture"
    documents "clip,clip"
    mentions 2
    aliases "GPT-1,GPT"
    description "Generative Pre-trained Transformer, a family of language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 85
    label "Li et al. (2017)"
    type "person"
    documents "clip"
    mentions 1
    aliases "Li et al. (2017)"
    description "Researchers who achieved 11.5% accuracy on ImageNet in a zero-shot setting."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 86
    label "Xie et al. (2020)"
    type "person"
    documents "clip,deit,reformer,vision_transformer"
    mentions 4
    aliases "Xie et al. (2020)"
    description "Researchers who established the current state of the art with 88.4% accuracy."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 87
    label "Mahajan et al. (2018)"
    type "person"
    documents "clip,deit,reformer,vision_transformer"
    mentions 4
    aliases "Mahajan et al. (2018)"
    description "Researchers who demonstrated the effectiveness of predicting hashtags on Instagram images."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 88
    label "Kolesnikov et al. (2019)"
    type "person"
    documents "clip"
    mentions 1
    aliases "Kolesnikov et al. (2019)"
    description "Researchers who showed large gains on transfer benchmarks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 89
    label "Dosovitskiy et al. (2020)"
    type "person"
    documents "clip"
    mentions 1
    aliases "Dosovitskiy et al. (2020)"
    description "Researchers who contributed to the understanding of transfer performance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 90
    label "Hestness et al. (2017)"
    type "person"
    documents "clip"
    mentions 1
    aliases "Hestness et al. (2017)"
    description "Researchers who studied the relationship between compute and transfer performance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 91
    label "Kaplan et al. (2020)"
    type "person"
    documents "clip"
    mentions 1
    aliases "Kaplan et al. (2020)"
    description "Researchers who analyzed the predictability of transfer performance based on compute."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 92
    label "McCann et al. (2017)"
    type "person"
    documents "clip"
    mentions 1
    aliases "McCann et al. (2017)"
    description "Researchers who discussed improvements in deep contextual representation learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 93
    label "WIT"
    type "dataset"
    documents "clip"
    mentions 1
    aliases "WIT"
    description "WebImageText dataset used for training CLIP, consisting of image-text pairs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 94
    label "Vision Transformer"
    type "architecture"
    documents "clip"
    mentions 1
    aliases "Vision Transformer"
    description "An architecture used for image encoding, based on transformer models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 95
    label "EfficientNet"
    type "architecture"
    documents "clip,swin_transformer"
    mentions 2
    aliases "EfficientNet"
    description "A family of convolutional neural networks that optimize accuracy and efficiency."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 96
    label "WebText"
    type "dataset"
    documents "clip,gpt3_language_models,gpt3"
    mentions 3
    aliases "WebText"
    description "A dataset used to train the GPT-2 model."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 97
    label "Zhang et al. (2020)"
    type "person"
    documents "clip"
    mentions 1
    aliases "Zhang et al. (2020)"
    description "Researchers who adapted contrastive representation learning for medical imaging."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 98
    label "Oord et al. (2018)"
    type "person"
    documents "clip"
    mentions 1
    aliases "Oord et al. (2018)"
    description "Researchers who popularized the InfoNCE loss for contrastive representation learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 99
    label "Chen et al. (2020)"
    type "person"
    documents "clip"
    mentions 1
    aliases "Chen et al. (2020)"
    description "Researchers who explored generative models and contrastive models in representation learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 100
    label "Sohn (2016)"
    type "person"
    documents "clip"
    mentions 1
    aliases "Sohn (2016)"
    description "Introduced the multi-class N-pair loss in deep metric learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 101
    label "Tian et al. (2019)"
    type "person"
    documents "clip"
    mentions 1
    aliases "Tian et al. (2019)"
    description "Researchers who found that contrastive objectives can learn better representations."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 102
    label "ResNet-101"
    type "architecture"
    documents "clip,deit,reformer,swin_transformer,vision_transformer"
    mentions 5
    aliases "ResNet-101,ResNet"
    description "A deeper version of ResNet-50 with 101 layers."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 103
    label "Vision Transformer (ViT)"
    type "architecture"
    documents "clip,deit,reformer,vision_transformer"
    mentions 4
    aliases "Vision Transformer (ViT)"
    description "A transformer-based model for image classification."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 104
    label "Adam optimizer"
    type "algorithm"
    documents "clip"
    mentions 1
    aliases "Adam optimizer"
    description "An optimization algorithm that computes adaptive learning rates for each parameter."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 105
    label "cross_entropy_loss"
    type "metric"
    documents "clip,gpt3_language_models,gpt3"
    mentions 3
    aliases "cross_entropy_loss,cross-entropy loss"
    description "A loss function used for classification tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 106
    label "MOTIVATION"
    type "section"
    documents "clip"
    mentions 1
    aliases "MOTIVATION"
    description "A section discussing the rationale behind zero-shot transfer."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 107
    label "zero-shot learning"
    type "method"
    documents "clip,gpt3_language_models,gpt3"
    mentions 3
    aliases "zero-shot learning,Zero-Shot Learning"
    description "A method that generalizes to unseen object categories without additional training."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 108
    label "temperature parameter (&#964;)"
    type "parameter"
    documents "clip"
    mentions 1
    aliases "temperature parameter (&#964;)"
    description "A parameter used to scale logits in the softmax function."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 109
    label "V100 GPU"
    type "hardware"
    documents "clip,gpt3_language_models,gpt3"
    mentions 3
    aliases "V100 GPU"
    description "A type of GPU used for high-performance computing."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 110
    label "mixed-precision training"
    type "method"
    documents "clip"
    mentions 1
    aliases "mixed-precision training"
    description "A training technique that uses both 16-bit and 32-bit floating-point types."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 111
    label "gradient checkpointing"
    type "method"
    documents "clip"
    mentions 1
    aliases "gradient checkpointing"
    description "A technique to save memory during training by storing only a subset of activations."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 112
    label "CIFAR-10"
    type "dataset"
    documents "clip,deit,deit,reformer,reformer,vision_transformer,vision_transformer"
    mentions 7
    aliases "CIFAR-10,CIFAR-100"
    description "A dataset commonly used for image classification tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 113
    label "TinyImages"
    type "dataset"
    documents "clip"
    mentions 1
    aliases "TinyImages"
    description "A dataset from which CIFAR-10 is derived."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 114
    label "SVHN"
    type "dataset"
    documents "clip"
    mentions 1
    aliases "SVHN"
    description "A dataset for street number transcription from Google Street View images."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 115
    label "Visual N-Grams"
    type "method"
    documents "clip"
    mentions 1
    aliases "Visual N-Grams"
    description "A method for zero-shot transfer in image classification."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 116
    label "hypernetwork"
    type "architecture"
    documents "clip"
    mentions 1
    aliases "hypernetwork"
    description "A network that generates weights for another network based on input."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 117
    label "Inception-V4"
    type "architecture"
    documents "clip"
    mentions 1
    aliases "Inception-V4"
    description "A deep learning model for image classification."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 118
    label "Jelinek-Mercer smoothing"
    type "method"
    documents "clip"
    mentions 1
    aliases "Jelinek-Mercer smoothing"
    description "A technique used to optimize probabilities in language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 119
    label "Szegedy et al. (2016)"
    type "people"
    documents "clip"
    mentions 1
    aliases "Szegedy et al. (2016)"
    description "Researchers who contributed to the development of Inception-V4."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 120
    label "Liu et al. (2018)"
    type "people"
    documents "clip"
    mentions 1
    aliases "Liu et al. (2018)"
    description "Researchers who identified task learning as a side-effect in language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 121
    label "Lei Ba et al. (2015)"
    type "people"
    documents "clip"
    mentions 1
    aliases "Lei Ba et al. (2015)"
    description "Researchers who introduced a zero-shot image classifier."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 122
    label "Elhoseiny et al. (2013)"
    type "people"
    documents "clip"
    mentions 1
    aliases "Elhoseiny et al. (2013)"
    description "Researchers associated with early work on zero-shot learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 123
    label "Flowers102"
    type "dataset"
    documents "clip"
    mentions 1
    aliases "Flowers102"
    description "An image classification dataset focused on flower species."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 124
    label "GTSRB"
    type "dataset"
    documents "clip"
    mentions 1
    aliases "GTSRB"
    description "German Traffic Sign Recognition Benchmark dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 125
    label "SUN"
    type "dataset"
    documents "clip"
    mentions 1
    aliases "SUN"
    description "A dataset used for scene recognition."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 126
    label "Yahoo"
    type "dataset"
    documents "clip"
    mentions 1
    aliases "Yahoo"
    description "A dataset used for image classification."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 127
    label "VTAB"
    type "dataset"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "VTAB"
    description "A suite of 19 tasks for evaluating transfer learning in vision."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 128
    label "Alexey Dosovitskiy"
    type "person"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Alexey Dosovitskiy"
    description "One of the authors of the paper and a researcher at Google Research."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 129
    label "Lucas Beyer"
    type "person"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Lucas Beyer"
    description "One of the authors of the paper and a researcher at Google Research."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 130
    label "Alexander Kolesnikov"
    type "person"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Alexander Kolesnikov"
    description "One of the authors of the paper and a researcher at Google Research."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 131
    label "Dirk Weissenborn"
    type "person"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Dirk Weissenborn"
    description "One of the authors of the paper and a researcher at Google Research."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 132
    label "Xiaohua Zhai"
    type "person"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Xiaohua Zhai"
    description "One of the authors of the paper and a researcher at Google Research."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 133
    label "Thomas Unterthiner"
    type "person"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Thomas Unterthiner"
    description "One of the authors of the paper and a researcher at Google Research."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 134
    label "Mostafa Dehghani"
    type "person"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Mostafa Dehghani"
    description "One of the authors of the paper and a researcher at Google Research."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 135
    label "Matthias Minderer"
    type "person"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Matthias Minderer"
    description "One of the authors of the paper and a researcher at Google Research."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 136
    label "Georg Heigold"
    type "person"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Georg Heigold"
    description "One of the authors of the paper and a researcher at Google Research."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 137
    label "Sylvain Gelly"
    type "person"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Sylvain Gelly"
    description "One of the authors of the paper and a researcher at Google Research."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 138
    label "Neil Houlsby"
    type "person"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Neil Houlsby"
    description "One of the authors of the paper and a researcher at Google Research."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 139
    label "ImageNet-21k"
    type "dataset"
    documents "deit,reformer,swin_transformer,swin_transformer,vision_transformer"
    mentions 5
    aliases "ImageNet-21k,ImageNet-1K,ImageNet-22K"
    description "A large dataset used for pre-training the Vision Transformer."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 140
    label "MLP Head"
    type "Architecture Component"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "MLP Head"
    description "A multi-layer perceptron used as a classification head in the ViT."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 141
    label "Transformer Encoder"
    type "Architecture Component"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Transformer Encoder"
    description "A component of the ViT that processes input sequences using self-attention."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 142
    label "Multi-Head Self-Attention (MSA)"
    type "Architecture Component"
    documents "deit,vision_transformer"
    mentions 2
    aliases "Multi-Head Self-Attention (MSA)"
    description "A mechanism in transformers that allows the model to focus on different parts of the input."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 143
    label "Position Embeddings"
    type "Architecture Component"
    documents "deit,longformer,reformer"
    mentions 3
    aliases "Position Embeddings"
    description "Learnable embeddings added to retain positional information in the input sequence."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 144
    label "Self-Supervised Learning"
    type "Learning Method"
    documents "deit,reformer"
    mentions 2
    aliases "Self-Supervised Learning"
    description "A method of training models using unlabeled data."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 145
    label "ICLR 2021"
    type "Conference"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "ICLR 2021"
    description "The conference where the paper was published."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 146
    label "Touvron et al. (2019)"
    type "Citation"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Touvron et al. (2019)"
    description "A referenced work discussing fine-tuning and higher resolution."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 147
    label "Sun et al. (2017)"
    type "Citation"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Sun et al. (2017)"
    description "A referenced work studying CNN performance scaling."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 148
    label "Kolesnikov et al. (2020)"
    type "Citation"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Kolesnikov et al. (2020)"
    description "A referenced work performing empirical exploration of CNN transfer learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 149
    label "Djolonga et al. (2020)"
    type "Citation"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Djolonga et al. (2020)"
    description "A referenced work related to CNN transfer learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 150
    label "Vaswani et al. (2017)"
    type "Citation"
    documents "deit,longformer,reformer,transformer_xl,vision_transformer"
    mentions 5
    aliases "Vaswani et al. (2017)"
    description "The original paper introducing the Transformer architecture."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 151
    label "GELU"
    type "Activation Function"
    documents "deit,reformer,swin_transformer,vision_transformer"
    mentions 4
    aliases "GELU"
    description "An activation function used in the MLP layers."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 152
    label "ILSVRC-2012 ImageNet"
    type "dataset"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "ILSVRC-2012 ImageNet"
    description "A dataset with 1k classes and 1.3M images used for image classification."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 153
    label "JFT"
    type "dataset"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "JFT"
    description "A dataset with 18k classes and 303M high-resolution images."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 154
    label "Oxford-IIIT Pets"
    type "dataset"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Oxford-IIIT Pets"
    description "A dataset containing images of pets for classification."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 155
    label "Oxford Flowers-102"
    type "dataset"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Oxford Flowers-102"
    description "A dataset containing images of flowers for classification."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 156
    label "ViT-Base"
    type "model"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "ViT-Base"
    description "A Vision Transformer model variant with 12 layers and 86M parameters."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 157
    label "ViT-Large"
    type "model"
    documents "deit,deit,reformer,reformer,vision_transformer,vision_transformer"
    mentions 6
    aliases "ViT-Huge,ViT-Large"
    description "A Vision Transformer model variant with 24 layers and 307M parameters."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 158
    label "Adam"
    type "optimizer"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Adam"
    description "An optimization algorithm used for training models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 159
    label "SGD"
    type "optimizer"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "SGD"
    description "Stochastic Gradient Descent, an optimization algorithm used for fine-tuning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 160
    label "Noisy Student"
    type "model"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Noisy Student"
    description "A large EfficientNet trained using semi-supervised learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 161
    label "Big Transfer (BiT)"
    type "model"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Big Transfer (BiT)"
    description "A method for supervised transfer learning with large ResNets."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 162
    label "Polyak &#38; Juditsky (1992)"
    type "publication"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Polyak &#38; Juditsky (1992)"
    description "A paper discussing averaging techniques used in model training."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 163
    label "ViT-L/16"
    type "model"
    documents "deit,deit,reformer,segment_anything,vision_transformer,vision_transformer"
    mentions 6
    aliases "ViT-L/16,ViT-B/16,ViT-L/14"
    description "Vision Transformer model pre-trained on ImageNet-21k"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 164
    label "TPUv3"
    type "hardware"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "TPUv3"
    description "Cloud TPU version 3 used for training"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 165
    label "BiT"
    type "method"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "BiT"
    description "State-of-the-art method based on ResNet co-trained on ImageNet and YouTube"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 166
    label "VIVI"
    type "method"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "VIVI"
    description "ResNet co-trained on ImageNet and YouTube"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 167
    label "S4L"
    type "method"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "S4L"
    description "Supervised plus semi-supervised learning method on ImageNet"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 168
    label "ViT-H/14"
    type "model"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "ViT-H/14"
    description "Vision Transformer model that outperforms BiT-R152x4 on Natural and Structured tasks"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 169
    label "weight decay"
    type "hyperparameter"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "weight decay"
    description "Regularization parameter used to optimize model performance"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 170
    label "dropout"
    type "hyperparameter"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "dropout"
    description "Regularization technique used to prevent overfitting"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 171
    label "label smoothing"
    type "hyperparameter"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "label smoothing"
    description "Regularization technique used to improve model generalization"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 172
    label "ViT-B/32"
    type "model"
    documents "deit,deit,vision_transformer,vision_transformer"
    mentions 4
    aliases "ViT-B/32,ViT-L/32"
    description "Vision Transformer model with specific architecture"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 173
    label "ViT-B"
    type "model"
    documents "deit,vision_transformer"
    mentions 2
    aliases "ViT-B"
    description "Vision Transformer model with all hidden dimensions halved"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 174
    label "Hybrid models"
    type "architecture"
    documents "deit"
    mentions 1
    aliases "Hybrid models"
    description "Models combining ResNet and Vision Transformer architectures"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 175
    label "ICLR2021"
    type "conference"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "ICLR2021"
    description "Conference where the paper was published"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 176
    label "Attention"
    type "mechanism"
    documents "deit"
    mentions 1
    aliases "Attention"
    description "Mechanism used in Vision Transformers to integrate information across the image"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 177
    label "Principal components"
    type "concept"
    documents "deit"
    mentions 1
    aliases "Principal components"
    description "Statistical method used to analyze learned embeddings"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 178
    label "self-attention"
    type "method"
    documents "deit,longformer,swin_transformer,transformer_xl,vision_transformer"
    mentions 5
    aliases "self-attention"
    description "A mechanism that allows the model to weigh the importance of different parts of the input data."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 179
    label "CNN"
    type "architecture"
    documents "deit,reformer,swin_transformer"
    mentions 3
    aliases "CNN"
    description "Convolutional Neural Networks, commonly used for image processing tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 180
    label "masked language modeling"
    type "method"
    documents "deit"
    mentions 1
    aliases "masked language modeling"
    description "A self-supervised learning task used in models like BERT."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 181
    label "self-supervised pre-training"
    type "method"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "self-supervised pre-training"
    description "A training approach where the model learns from unlabeled data."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 182
    label "attention distance"
    type "metric"
    documents "deit,reformer"
    mentions 2
    aliases "attention distance"
    description "A measure of how far information is integrated across the image based on attention weights."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 183
    label "Andreas Steiner"
    type "person"
    documents "deit,reformer,vision_transformer"
    mentions 3
    aliases "Andreas Steiner"
    description "A colleague at Google who contributed to the infrastructure."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 184
    label "Joan Puigcerver"
    type "person"
    documents "deit,reformer"
    mentions 2
    aliases "Joan Puigcerver"
    description "A colleague at Google who assisted with large-scale training infrastructure."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 185
    label "Maxim Neumann"
    type "person"
    documents "deit,reformer"
    mentions 2
    aliases "Maxim Neumann"
    description "A colleague at Google who helped with large-scale training infrastructure."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 186
    label "Dmitry Lepikhin"
    type "person"
    documents "deit,reformer"
    mentions 2
    aliases "Dmitry Lepikhin"
    description "A colleague at Google involved in discussions related to the work."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 187
    label "Aravindh Mahendran"
    type "person"
    documents "deit,reformer"
    mentions 2
    aliases "Aravindh Mahendran"
    description "A colleague at Google involved in discussions related to the work."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 188
    label "Daniel Keysers"
    type "person"
    documents "deit,reformer"
    mentions 2
    aliases "Daniel Keysers"
    description "A colleague at Google involved in discussions related to the work."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 189
    label "Mario Lucic"
    type "person"
    documents "deit,reformer"
    mentions 2
    aliases "Mario Lucic"
    description "A colleague at Google involved in discussions related to the work."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 190
    label "Colin Raffel"
    type "person"
    documents "deit,reformer"
    mentions 2
    aliases "Colin Raffel"
    description "A colleague at Google involved in discussions related to the work."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 191
    label "Devlin et al. (2019)"
    type "reference"
    documents "deit,longformer,reformer"
    mentions 3
    aliases "Devlin et al. (2019)"
    description "Authors of the BERT paper, which introduced masked language modeling."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 192
    label "Chen et al. (2020b)"
    type "reference"
    documents "deit,reformer"
    mentions 2
    aliases "Chen et al. (2020b)"
    description "Authors of a paper on contrastive pre-training."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 193
    label "He et al. (2020)"
    type "reference"
    documents "deit,reformer"
    mentions 2
    aliases "He et al. (2020)"
    description "Authors of a paper on unsupervised visual representation learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 194
    label "Bachman et al. (2019)"
    type "reference"
    documents "deit,reformer"
    mentions 2
    aliases "Bachman et al. (2019)"
    description "Authors of a paper on maximizing mutual information across views."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 195
    label "He&#769;naff et al. (2020)"
    type "reference"
    documents "deit"
    mentions 1
    aliases "He&#769;naff et al. (2020)"
    description "Authors of a paper on contrastive learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 196
    label "Carion et al. (2020)"
    type "reference"
    documents "deit,reformer"
    mentions 2
    aliases "Carion et al. (2020)"
    description "Authors of a paper on end-to-end object detection with transformers."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 197
    label "NLP"
    type "field"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "NLP"
    description "Natural Language Processing, a field of AI focused on the interaction between computers and human language."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 198
    label "few-shot learning"
    type "method"
    documents "gpt3_language_models,gpt3_language_models,gpt3,gpt3,palm"
    mentions 5
    aliases "one-shot learning,few-shot learning"
    description "A learning paradigm where a model learns to perform a task with very few examples."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 199
    label "pre-training"
    type "method"
    documents "gpt3_language_models,reformer"
    mentions 2
    aliases "Pre-training,pre-training"
    description "The initial training phase of a model on a large corpus of text."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 200
    label "fine-tuning"
    type "method"
    documents "gpt3_language_models,gpt3,reformer"
    mentions 3
    aliases "Fine-tuning,fine-tuning"
    description "The process of adapting a pre-trained model to a specific task using a smaller dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 201
    label "language tasks"
    type "concept"
    documents "gpt3_language_models"
    mentions 1
    aliases "language tasks"
    description "Various tasks that involve understanding or generating human language."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 202
    label "translation"
    type "task"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "translation"
    description "The task of converting text from one language to another."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 203
    label "question-answering"
    type "task"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "question-answering"
    description "The task of providing answers to questions based on a given context."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 204
    label "cloze tasks"
    type "task"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "cloze tasks"
    description "Tasks that involve filling in the blanks in a sentence."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 205
    label "3-digit arithmetic"
    type "task"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "3-digit arithmetic"
    description "A task that involves performing arithmetic operations with three-digit numbers."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 206
    label "Common Crawl"
    type "dataset"
    documents "gpt3_language_models,gpt3,llama"
    mentions 3
    aliases "Common Crawl"
    description "A dataset used for training language models, consisting of web-crawled data."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 207
    label "SuperGLUE"
    type "benchmark"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "SuperGLUE"
    description "A benchmark for evaluating the performance of NLP models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 208
    label "Johns Hopkins University"
    type "organization"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "Johns Hopkins University"
    description "An academic institution associated with one of the authors."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 209
    label "parameters"
    type "metric"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "parameters"
    description "The number of adjustable weights in a neural network model."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 210
    label "societal impacts"
    type "concept"
    documents "gpt3_language_models"
    mentions 1
    aliases "societal impacts"
    description "The broader implications of language models like GPT-3 on society."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 211
    label "in-context learning"
    type "method"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "in-context learning"
    description "A meta-learning approach where a model uses contextual information to adapt to tasks without gradient updates."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 212
    label "meta-learning"
    type "method"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "meta-learning"
    description "A learning paradigm where models develop a broad set of skills during training to adapt quickly to new tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 213
    label "Natural Questions"
    type "dataset"
    documents "gpt3_language_models,gpt3,llama"
    mentions 3
    aliases "Natural Questions"
    description "A benchmark dataset used to evaluate question answering systems."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 214
    label "CoQA"
    type "dataset"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "CoQA"
    description "A conversational question answering dataset used to evaluate models on dialogue-based tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 215
    label "TriviaQA"
    type "dataset"
    documents "gpt3_language_models,gpt3,llama,longformer"
    mentions 4
    aliases "TriviaQA"
    description "A dataset for question answering that includes trivia questions."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 216
    label "log loss"
    type "metric"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "log loss"
    description "A performance metric that correlates well with many downstream NLP tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 217
    label "RWC+19"
    type "reference"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "RWC+19"
    description "A citation for a paper discussing in-context learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 218
    label "YdC+19"
    type "reference"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "YdC+19"
    description "A citation for a paper discussing generalization in models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 219
    label "MPL19"
    type "reference"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "MPL19"
    description "A citation for a paper related to model performance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 220
    label "GSL+18"
    type "reference"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "GSL+18"
    description "A citation for a paper discussing the performance of fine-tuned models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 221
    label "NK19"
    type "reference"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "NK19"
    description "A citation for a paper related to model evaluation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 222
    label "KMH+20"
    type "reference"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "KMH+20"
    description "A citation for a paper discussing the correlation of log loss with model performance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 223
    label "RNSS18"
    type "reference"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "RNSS18"
    description "A citation for a paper discussing the early transformer models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 224
    label "DCLT18"
    type "reference"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "DCLT18"
    description "A citation for a paper discussing the scaling of transformer models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 225
    label "SPP+19"
    type "reference"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "SPP+19"
    description "A citation for a paper discussing improvements in transformer models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 226
    label "RSR+19"
    type "reference"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "RSR+19"
    description "A citation for a paper discussing the scaling of language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 227
    label "Tur20"
    type "reference"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "Tur20"
    description "A citation for a paper discussing the latest advancements in transformer models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 228
    label "ANLI"
    type "dataset"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "ANLI"
    description "A natural language inference dataset used to evaluate model performance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 229
    label "RACE"
    type "dataset"
    documents "gpt3_language_models,gpt3,llama"
    mentions 3
    aliases "RACE"
    description "A reading comprehension dataset for evaluating language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 230
    label "QuAC"
    type "dataset"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "QuAC"
    description "A dataset for question answering in a conversational context."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 231
    label "CommonCrawl"
    type "dataset"
    documents "gpt3_language_models,gpt3,llama"
    mentions 3
    aliases "CommonCrawl"
    description "A web corpus used for training language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 232
    label "Data Contamination"
    type "concept"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "Data Contamination,data contamination"
    description "The issue of training models on datasets that may include content from test datasets."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 233
    label "Bias and Fairness"
    type "concept"
    documents "gpt3_language_models"
    mentions 1
    aliases "Bias and Fairness"
    description "Concerns regarding the ethical implications and societal impacts of AI models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 234
    label "Books1"
    type "dataset"
    documents "gpt3_language_models,gpt3_language_models,gpt3,gpt3"
    mentions 4
    aliases "Books2,Books1"
    description "An internet-based corpus used in training language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 235
    label "Wikipedia"
    type "dataset"
    documents "gpt3_language_models,gpt3,llama,palm"
    mentions 4
    aliases "Wikipedia"
    description "An English-language encyclopedia used in training language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 236
    label "Sparse Transformer"
    type "architecture"
    documents "gpt3_language_models,gpt3,longformer"
    mentions 3
    aliases "Sparse Transformer"
    description "An architecture that uses alternating dense and locally banded sparse attention patterns."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 237
    label "Validation loss"
    type "metric"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "Validation loss"
    description "A measure used to evaluate the performance of models during training."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 238
    label "Scaling Laws for Neural Language Models"
    type "research"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "Scaling Laws for Neural Language Models"
    description "A study that analyzes the relationship between model size and performance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 239
    label "Microsoft"
    type "organization"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "Microsoft"
    description "Provider of high-bandwidth cluster for training."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 240
    label "LAMBADA"
    type "dataset"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "LAMBADA"
    description "A dataset testing long-range dependencies in text."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 241
    label "Storycloze"
    type "dataset"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "Storycloze"
    description "A dataset used for evaluating story completion tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 242
    label "Winograd"
    type "dataset"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "Winograd"
    description "A dataset for evaluating commonsense reasoning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 243
    label "ARC"
    type "dataset"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "ARC"
    description "A dataset for evaluating reasoning capabilities."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 244
    label "OpenBookQA"
    type "dataset"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "OpenBookQA"
    description "A dataset for evaluating question answering."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 245
    label "F1 similarity score"
    type "metric"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "F1 similarity score"
    description "A metric for evaluating model performance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 246
    label "K"
    type "parameter"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "K"
    description "The number of examples drawn from the training set for few-shot learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 247
    label "model parallelism"
    type "method"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "model parallelism"
    description "A technique used to distribute model training across multiple GPUs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 248
    label "gradient noise scaling"
    type "method"
    documents "gpt3_language_models,gpt3"
    mentions 2
    aliases "gradient noise scaling"
    description "A technique used to guide the choice of batch size during training."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 249
    label "task-specific fine-tuning"
    type "Method"
    documents "gpt3"
    mentions 1
    aliases "task-specific fine-tuning"
    description "The process of adapting a pre-trained model to a specific task using a labeled dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 250
    label "human evaluators"
    type "People"
    documents "gpt3"
    mentions 1
    aliases "human evaluators"
    description "Individuals who assess the quality of generated text."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 251
    label "F1 Score"
    type "metric"
    documents "gpt3,longformer"
    mentions 2
    aliases "F1 Score"
    description "A measure of a model's accuracy on a dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 252
    label "accuracy"
    type "metric"
    documents "gpt3,segment_anything,vision_transformer"
    mentions 3
    aliases "accuracy"
    description "The ratio of correctly predicted instances to the total instances."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 253
    label "LLaMA-I"
    type "Language Model"
    documents "llama,llama,segment_anything"
    mentions 3
    aliases "LLaMA,LLaMA-I"
    description "A collection of foundation language models ranging from 7B to 65B parameters."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 254
    label "Chinchilla"
    type "Language Model"
    documents "llama,palm"
    mentions 2
    aliases "Chinchilla"
    description "A large language model with 70B parameters, used for performance comparison."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 255
    label "PaLM"
    type "Language Model"
    documents "llama,palm"
    mentions 2
    aliases "PaLM"
    description "A large language model with 540B parameters, used for performance comparison."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 256
    label "MetaAI"
    type "Organization"
    documents "llama"
    mentions 1
    aliases "MetaAI"
    description "The organization behind the development of LLaMA."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 257
    label "Hoffmann et al. (2022)"
    type "Research Paper"
    documents "llama,palm"
    mentions 2
    aliases "Hoffmann et al. (2022)"
    description "A study that discusses scaling laws for language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 258
    label "C4"
    type "Dataset"
    documents "llama"
    mentions 1
    aliases "C4"
    description "A dataset used for training, consisting of web data filtered for quality."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 259
    label "Github"
    type "Dataset"
    documents "llama"
    mentions 1
    aliases "Github"
    description "A dataset containing public GitHub repositories."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 260
    label "Books"
    type "Dataset"
    documents "llama,palm"
    mentions 2
    aliases "Books"
    description "A dataset containing public domain books."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 261
    label "ArXiv"
    type "Dataset"
    documents "llama"
    mentions 1
    aliases "ArXiv"
    description "A dataset containing scientific papers from arXiv."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 262
    label "StackExchange"
    type "Dataset"
    documents "llama"
    mentions 1
    aliases "StackExchange"
    description "A dataset containing questions and answers from Stack Exchange."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 263
    label "Transformer Architecture"
    type "Architecture"
    documents "llama"
    mentions 1
    aliases "Transformer Architecture"
    description "The neural network architecture used for training LLaMA."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 264
    label "Performance Metrics"
    type "Metric"
    documents "llama"
    mentions 1
    aliases "Performance Metrics"
    description "Benchmarks used to evaluate the performance of language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 265
    label "CCNet"
    type "dataset"
    documents "llama"
    mentions 1
    aliases "CCNet"
    description "A dataset used for increasing consistency across papers."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 266
    label "Stack Exchange"
    type "website"
    documents "llama"
    mentions 1
    aliases "Stack Exchange"
    description "A platform for high-quality questions and answers across various domains."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 267
    label "Google BigQuery"
    type "service"
    documents "llama"
    mentions 1
    aliases "Google BigQuery"
    description "A cloud-based data warehouse for querying large datasets."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 268
    label "Apache License"
    type "license"
    documents "llama"
    mentions 1
    aliases "Apache License"
    description "A permissive free software license."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 269
    label "BSD License"
    type "license"
    documents "llama"
    mentions 1
    aliases "BSD License"
    description "A family of permissive free software licenses."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 270
    label "MIT License"
    type "license"
    documents "llama"
    mentions 1
    aliases "MIT License"
    description "A permissive free software license."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 271
    label "Byte-Pair Encoding (BPE)"
    type "algorithm"
    documents "llama"
    mentions 1
    aliases "Byte-Pair Encoding (BPE)"
    description "A tokenization algorithm used for processing text."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 272
    label "RMSNorm"
    type "normalization function"
    documents "llama"
    mentions 1
    aliases "RMSNorm"
    description "A normalization function used to improve training stability."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 273
    label "SwiGLU"
    type "activation function"
    documents "llama,palm"
    mentions 2
    aliases "SwiGLU"
    description "An activation function used to improve performance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 274
    label "Rotary Positional Embeddings (RoPE)"
    type "embedding technique"
    documents "llama"
    mentions 1
    aliases "Rotary Positional Embeddings (RoPE)"
    description "A technique for adding positional information to transformer models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 275
    label "AdamW"
    type "optimizer"
    documents "llama,swin_transformer"
    mentions 2
    aliases "AdamW"
    description "An optimization algorithm used for training models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 276
    label "CommonSense Reasoning Tasks"
    type "task"
    documents "llama"
    mentions 1
    aliases "CommonSense Reasoning Tasks"
    description "A set of tasks for evaluating models on common sense reasoning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 277
    label "Gopher"
    type "model"
    documents "llama,palm"
    mentions 2
    aliases "Gopher"
    description "A large language model developed by DeepMind."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 278
    label "Table 2"
    type "table"
    documents "llama,llama"
    mentions 2
    aliases "Table 3,Table 2"
    description "A table containing model sizes, architectures, and optimization hyper-parameters."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 279
    label "OPT"
    type "model"
    documents "llama"
    mentions 1
    aliases "OPT"
    description "Open-sourced language models compared with LLaMA."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 280
    label "OPT-IML"
    type "model"
    documents "llama"
    mentions 1
    aliases "OPT-IML"
    description "An instruction-tuned model compared with LLaMA."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 281
    label "HumanEval"
    type "dataset"
    documents "llama"
    mentions 1
    aliases "HumanEval"
    description "A benchmark for evaluating code generation from natural language."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 282
    label "MBPP"
    type "dataset"
    documents "llama"
    mentions 1
    aliases "MBPP"
    description "A benchmark for evaluating code generation from natural language."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 283
    label "MATH"
    type "dataset"
    documents "llama"
    mentions 1
    aliases "MATH"
    description "A dataset of mathematical problems for evaluation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 284
    label "GSM8k"
    type "dataset"
    documents "llama"
    mentions 1
    aliases "GSM8k"
    description "A dataset of middle school mathematical problems."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 285
    label "BoolQ"
    type "dataset"
    documents "llama"
    mentions 1
    aliases "BoolQ"
    description "A common sense reasoning benchmark."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 286
    label "Flan-PaLM"
    type "dataset"
    documents "llama"
    mentions 1
    aliases "Flan-PaLM"
    description "An instruction-tuned model benchmark."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 287
    label "WinoGrande"
    type "dataset"
    documents "llama"
    mentions 1
    aliases "WinoGrande"
    description "A common sense reasoning benchmark."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 288
    label "ARCeasy"
    type "dataset"
    documents "llama"
    mentions 1
    aliases "ARCeasy"
    description "A common sense reasoning benchmark."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 289
    label "ARChallenge"
    type "dataset"
    documents "llama"
    mentions 1
    aliases "ARChallenge"
    description "A common sense reasoning benchmark."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 290
    label "Exact Match"
    type "metric"
    documents "llama"
    mentions 1
    aliases "Exact Match"
    description "A performance metric for evaluating question answering."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 291
    label "Zero-shot"
    type "evaluation setting"
    documents "llama"
    mentions 1
    aliases "Zero-shot"
    description "An evaluation setting where models are tested without prior examples."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 292
    label "Few-shot"
    type "evaluation setting"
    documents "llama"
    mentions 1
    aliases "Few-shot"
    description "An evaluation setting where models are tested with a few examples."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 293
    label "pass@"
    type "metric"
    documents "llama,llama"
    mentions 2
    aliases "pass@,pass@1"
    description "A performance metric for evaluating code generation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 294
    label "MMLU"
    type "benchmark"
    documents "llama"
    mentions 1
    aliases "MMLU"
    description "Massive multitask language understanding benchmark."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 295
    label "LaMDA"
    type "model"
    documents "llama,palm"
    mentions 2
    aliases "LaMDA"
    description "A language model developed by Google, compared with LLaMA."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 296
    label "LLaMA-65B"
    type "model"
    documents "llama"
    mentions 1
    aliases "LLaMA-65B"
    description "A large language model with 65 billion parameters."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 297
    label "Gutenberg"
    type "dataset"
    documents "llama"
    mentions 1
    aliases "Gutenberg"
    description "A digital library of free eBooks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 298
    label "Books3"
    type "dataset"
    documents "llama"
    mentions 1
    aliases "Books3"
    description "A dataset used in training language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 299
    label "pass@100"
    type "metric"
    documents "llama"
    mentions 1
    aliases "pass@100"
    description "A metric indicating the percentage of correct answers within 100 attempts."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 300
    label "pass@80"
    type "metric"
    documents "llama"
    mentions 1
    aliases "pass@80"
    description "A metric indicating the percentage of correct answers within 80 attempts."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 301
    label "RealToxicityPrompts"
    type "benchmark"
    documents "llama"
    mentions 1
    aliases "RealToxicityPrompts"
    description "A benchmark for evaluating the toxicity of language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 302
    label "PerspectiveAPI"
    type "API"
    documents "llama"
    mentions 1
    aliases "PerspectiveAPI"
    description "An API used to evaluate the toxicity of generated text."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 303
    label "Chen et al. (2021)"
    type "citation"
    documents "llama"
    mentions 1
    aliases "Chen et al. (2021)"
    description "A reference to a paper discussing methods for unbiased estimates."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 304
    label "Chowdhery et al. (2022)"
    type "citation"
    documents "llama"
    mentions 1
    aliases "Chowdhery et al. (2022)"
    description "A reference to a paper discussing the PaLM-Coder model."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 305
    label "Iyer et al. (2022)"
    type "citation"
    documents "llama"
    mentions 1
    aliases "Iyer et al. (2022)"
    description "A reference to a paper discussing instruction-tuned models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 306
    label "Zhang et al. (2022)"
    type "citation"
    documents "llama"
    mentions 1
    aliases "Zhang et al. (2022)"
    description "A reference to a paper discussing toxic content generation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 307
    label "WinoGender"
    type "dataset"
    documents "llama,palm"
    mentions 2
    aliases "Winogender,WinoGender"
    description "A dataset for evaluating co-reference resolution and biases related to gender."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 308
    label "CrowS-Pairs"
    type "dataset"
    documents "llama"
    mentions 1
    aliases "CrowS-Pairs"
    description "A dataset used to measure biases in various categories including gender and religion."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 309
    label "TruthfulQA"
    type "benchmark"
    documents "llama"
    mentions 1
    aliases "TruthfulQA"
    description "A benchmark for measuring the truthfulness of language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 310
    label "Rae et al. (2021)"
    type "publication"
    documents "llama,longformer,palm"
    mentions 3
    aliases "Rae et al. (2020),Rae et al. (2021)"
    description "A reference to previous work on gender bias in models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 311
    label "API"
    type "technology"
    documents "llama"
    mentions 1
    aliases "API"
    description "Application Programming Interface used for model interaction."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 312
    label "Carbon Emission"
    type "metric"
    documents "llama"
    mentions 1
    aliases "Carbon Emission"
    description "A measure of the carbon footprint associated with model training."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 313
    label "Perplexity"
    type "metric"
    documents "llama,transformer_xl,transformer_xl"
    mentions 3
    aliases "perplexity (PPL),perplexity,Perplexity"
    description "A measure used to evaluate the performance of language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 314
    label "Co-reference resolution"
    type "method"
    documents "llama"
    mentions 1
    aliases "Co-reference resolution"
    description "A task in natural language processing to determine which words refer to the same entity."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 315
    label "Longformer"
    type "architecture"
    documents "longformer"
    mentions 1
    aliases "Longformer"
    description "A modified Transformer architecture with a self-attention operation that scales linearly with sequence length."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 316
    label "Allen Institute for Artificial Intelligence"
    type "organization"
    documents "longformer"
    mentions 1
    aliases "Allen Institute for Artificial Intelligence"
    description "The organization where the authors of the paper are affiliated."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 317
    label "text8"
    type "dataset"
    documents "longformer,transformer_xl"
    mentions 2
    aliases "text8"
    description "A benchmark dataset used for evaluating language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 318
    label "enwik8"
    type "dataset"
    documents "longformer,transformer_xl"
    mentions 2
    aliases "enwik8"
    description "Another benchmark dataset used for evaluating language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 319
    label "WikiHop"
    type "dataset"
    documents "longformer"
    mentions 1
    aliases "WikiHop"
    description "A dataset used for evaluating long document tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 320
    label "Longformer-Encoder-Decoder (LED)"
    type "architecture"
    documents "longformer"
    mentions 1
    aliases "Longformer-Encoder-Decoder (LED)"
    description "A variant of Longformer designed for long document generative sequence-to-sequence tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 321
    label "RoBERTa"
    type "architecture"
    documents "longformer"
    mentions 1
    aliases "RoBERTa"
    description "A pre-trained Transformer model that Longformer outperforms on long document tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 322
    label "Transformer-XL"
    type "architecture"
    documents "longformer,transformer_xl"
    mentions 2
    aliases "Transformer-XL"
    description "A model that addresses the computational efficiency of Transformers on long sequences."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 323
    label "Dai et al. (2019)"
    type "reference"
    documents "longformer"
    mentions 1
    aliases "Dai et al. (2019)"
    description "A reference to prior work on generative language modeling."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 324
    label "Radford et al. (2019)"
    type "reference"
    documents "longformer"
    mentions 1
    aliases "Radford et al. (2019)"
    description "A reference to prior work on generative language modeling."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 325
    label "Cohan et al. (2018)"
    type "reference"
    documents "longformer"
    mentions 1
    aliases "Cohan et al. (2018)"
    description "A reference to prior work on summarization datasets."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 326
    label "BlockSparse"
    type "method"
    documents "longformer"
    mentions 1
    aliases "BlockSparse"
    description "A method implemented in C++ for specific versions of TensorFlow."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 327
    label "CUDA"
    type "technology"
    documents "longformer"
    mentions 1
    aliases "CUDA"
    description "A parallel computing platform and application programming interface model created by NVIDIA."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 328
    label "TensorFlow"
    type "framework"
    documents "longformer"
    mentions 1
    aliases "TensorFlow"
    description "An open-source machine learning framework."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 329
    label "QA"
    type "task"
    documents "longformer"
    mentions 1
    aliases "QA"
    description "Question Answering, a natural language processing task."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 330
    label "coreference resolution"
    type "task"
    documents "longformer"
    mentions 1
    aliases "coreference resolution"
    description "The task of determining when different expressions refer to the same entity."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 331
    label "LED"
    type "model"
    documents "longformer"
    mentions 1
    aliases "LED"
    description "Longformer-Encoder-Decoder, a variant of Longformer for sequence-to-sequence learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 332
    label "BP-Transformer"
    type "model"
    documents "longformer"
    mentions 1
    aliases "BP-Transformer"
    description "A transformer model evaluated on machine translation tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 333
    label "CPC loss"
    type "metric"
    documents "longformer"
    mentions 1
    aliases "CPC loss"
    description "Contrastive Predictive Coding loss, an additional training objective."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 334
    label "BigBird"
    type "model"
    documents "longformer"
    mentions 1
    aliases "BigBird"
    description "An extension of ETC for long document tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 335
    label "ETC"
    type "model"
    documents "longformer"
    mentions 1
    aliases "ETC"
    description "A transformer model that uses local + global attention."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 336
    label "SQuAD"
    type "dataset"
    documents "longformer"
    mentions 1
    aliases "SQuAD"
    description "Stanford Question Answering Dataset, typically fits within the 512 limit."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 337
    label "MRQA"
    type "dataset"
    documents "longformer"
    mentions 1
    aliases "MRQA"
    description "Machine Reading for Question Answering, constructed by dropping long-document examples."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 338
    label "dilated CNNs"
    type "method"
    documents "longformer"
    mentions 1
    aliases "dilated CNNs"
    description "Convolutional neural networks that use dilated convolutions."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 339
    label "Sutskever et al. (2014)"
    type "publication"
    documents "longformer"
    mentions 1
    aliases "Sutskever et al. (2014)"
    description "The paper introducing sequence-to-sequence learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 340
    label "Xie et al. (2019)"
    type "publication"
    documents "longformer"
    mentions 1
    aliases "Xie et al. (2019)"
    description "Research on truncating documents for classification."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 341
    label "Clark and Gardner (2017)"
    type "publication"
    documents "longformer"
    mentions 1
    aliases "Clark and Gardner (2017)"
    description "Research on two-stage models for open domain QA."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 342
    label "Chen et al. (2017)"
    type "publication"
    documents "longformer"
    mentions 1
    aliases "Chen et al. (2017)"
    description "Research related to answer extraction in QA."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 343
    label "Gupta and Berant (2020)"
    type "publication"
    documents "longformer"
    mentions 1
    aliases "Gupta and Berant (2020)"
    description "Research on using global memory in models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 344
    label "Kovaleva et al. (2019)"
    type "publication"
    documents "longformer"
    mentions 1
    aliases "Kovaleva et al. (2019)"
    description "Research on the importance of local context."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 345
    label "Josh et al. (2019)"
    type "publication"
    documents "longformer"
    mentions 1
    aliases "Josh et al. (2019)"
    description "Research on processing document chunks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 346
    label "Wu et al. (2019)"
    type "publication"
    documents "longformer"
    mentions 1
    aliases "Wu et al. (2019)"
    description "Research on CNNs and their representation capabilities."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 347
    label "vandenOord et al. (2016)"
    type "publication"
    documents "longformer"
    mentions 1
    aliases "vandenOord et al. (2016)"
    description "Research on dilated convolutions."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 348
    label "Ye et al. (2019)"
    type "publication"
    documents "longformer"
    mentions 1
    aliases "Ye et al. (2019)"
    description "Research on evaluating transformer models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 349
    label "BERT"
    type "model"
    documents "longformer,palm,reformer"
    mentions 3
    aliases "BERT"
    description "A state-of-the-art model for natural language processing tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 350
    label "Global Attention"
    type "method"
    documents "longformer"
    mentions 1
    aliases "Global Attention"
    description "An attention mechanism that allows certain tokens to attend to all tokens in the sequence."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 351
    label "Masked Language Modeling (MLM)"
    type "task"
    documents "longformer"
    mentions 1
    aliases "Masked Language Modeling (MLM)"
    description "A task where the model predicts masked words in a sequence."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 352
    label "Question Answering (QA)"
    type "task"
    documents "longformer"
    mentions 1
    aliases "Question Answering (QA)"
    description "A task where the model answers questions based on a given document."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 353
    label "Adaptive Span"
    type "model"
    documents "longformer"
    mentions 1
    aliases "Adaptive Span"
    description "A model that adapts the attention span based on the input."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 354
    label "Compressive Transformer"
    type "model"
    documents "longformer"
    mentions 1
    aliases "Compressive Transformer"
    description "A transformer model that compresses information to handle longer sequences."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 355
    label "Reformer"
    type "model"
    documents "longformer"
    mentions 1
    aliases "Reformer"
    description "A transformer model that uses reversible layers to reduce memory usage."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 356
    label "Dataset text8"
    type "dataset"
    documents "longformer"
    mentions 1
    aliases "Dataset text8"
    description "A dataset used for training language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 357
    label "Dataset enwik8"
    type "dataset"
    documents "longformer"
    mentions 1
    aliases "Dataset enwik8"
    description "A dataset used for evaluating language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 358
    label "TVM"
    type "technology"
    documents "longformer"
    mentions 1
    aliases "TVM"
    description "An open-source deep learning compiler stack."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 359
    label "PyTorch"
    type "library"
    documents "longformer"
    mentions 1
    aliases "PyTorch"
    description "An open-source machine learning library used for deep learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 360
    label "Sukhbaatar et al. (2019)"
    type "publication"
    documents "longformer"
    mentions 1
    aliases "Sukhbaatar et al. (2019)"
    description "A reference to a paper that discusses adaptive attention spans."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 361
    label "Child et al. (2019)"
    type "publication"
    documents "longformer"
    mentions 1
    aliases "Child et al. (2019)"
    description "A reference to a paper that discusses sparse transformers."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 362
    label "Al-Rfou et al. (2018)"
    type "publication"
    documents "longformer,transformer_xl"
    mentions 2
    aliases "Al-Rfou et al. (2018)"
    description "A reference to a paper that discusses the T12 dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 363
    label "MLM"
    type "Method"
    documents "longformer"
    mentions 1
    aliases "MLM"
    description "Masked Language Modeling, a pretraining objective for language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 364
    label "Attention Pattern"
    type "Method"
    documents "longformer"
    mentions 1
    aliases "Attention Pattern"
    description "A technique for configuring attention mechanisms in transformer models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 365
    label "Gradient Updates"
    type "Metric"
    documents "longformer"
    mentions 1
    aliases "Gradient Updates"
    description "The number of updates applied during model training."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 366
    label "HotpotQA"
    type "Dataset"
    documents "longformer"
    mentions 1
    aliases "HotpotQA"
    description "A multi-hop question answering dataset that requires evidence extraction."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 367
    label "fairseq"
    type "Framework"
    documents "longformer"
    mentions 1
    aliases "fairseq"
    description "A sequence-to-sequence learning toolkit for training models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 368
    label "Clark and Gardner"
    type "People"
    documents "longformer"
    mentions 1
    aliases "Clark and Gardner"
    description "Researchers who proposed a loss function for question answering."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 369
    label "Ott et al."
    type "People"
    documents "longformer"
    mentions 1
    aliases "Ott et al."
    description "Researchers who contributed to the fairseq framework."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 370
    label "Devlin et al."
    type "People"
    documents "longformer"
    mentions 1
    aliases "Devlin et al."
    description "Researchers who developed the BERT model."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 371
    label "Liu et al."
    type "People"
    documents "longformer"
    mentions 1
    aliases "Liu et al."
    description "Researchers who introduced the RoBERTa model."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 372
    label "Rae et al."
    type "People"
    documents "longformer"
    mentions 1
    aliases "Rae et al."
    description "Researchers who discussed configurations for transformer models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 373
    label "Clark et al."
    type "People"
    documents "longformer"
    mentions 1
    aliases "Clark et al."
    description "Researchers who analyzed BERT's attention heads."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 374
    label "RoBERTa-large"
    type "Model"
    documents "longformer"
    mentions 1
    aliases "RoBERTa-large"
    description "A transformer-based model for natural language processing."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 375
    label "Longformer-large"
    type "Model"
    documents "longformer"
    mentions 1
    aliases "Longformer-large"
    description "A transformer model designed for long document processing."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 376
    label "Frozen RoBERTa Weights"
    type "Method"
    documents "longformer"
    mentions 1
    aliases "Frozen RoBERTa Weights"
    description "A technique where the weights of the RoBERTa model are kept constant during training."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 377
    label "OntoNotes"
    type "Dataset"
    documents "longformer"
    mentions 1
    aliases "OntoNotes"
    description "A dataset used for coreference resolution."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 378
    label "IMDB"
    type "Dataset"
    documents "longformer"
    mentions 1
    aliases "IMDB"
    description "A dataset for sentiment classification based on movie reviews."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 379
    label "Hyperpartisan"
    type "Dataset"
    documents "longformer"
    mentions 1
    aliases "Hyperpartisan"
    description "A dataset for detecting hyperpartisan news."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 380
    label "BPC"
    type "Metric"
    documents "longformer"
    mentions 1
    aliases "BPC"
    description "Bits per character, a measure of model performance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 381
    label "GNN"
    type "Method"
    documents "longformer"
    mentions 1
    aliases "GNN"
    description "Graph Neural Networks, used for reasoning over entities."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 382
    label "Joshi et al. (2019)"
    type "Publication"
    documents "longformer"
    mentions 1
    aliases "Joshi et al. (2019)"
    description "A paper that presents a model for coreference resolution."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 383
    label "BART"
    type "Model"
    documents "longformer"
    mentions 1
    aliases "BART"
    description "A pre-trained encoder-decoder model for sequence-to-sequence tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 384
    label "T5"
    type "Model"
    documents "longformer,palm"
    mentions 2
    aliases "T5"
    description "A text-to-text transfer transformer model."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 385
    label "Lee et al. (2018)"
    type "Publication"
    documents "longformer"
    mentions 1
    aliases "Lee et al. (2018)"
    description "A paper that discusses replacing ELMo with BERT."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 386
    label "Fang et al. (2020)"
    type "Publication"
    documents "longformer"
    mentions 1
    aliases "Fang et al. (2020)"
    description "A paper that presents a state-of-the-art model for HotpotQA."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 387
    label "Tu et al. (2019)"
    type "Publication"
    documents "longformer"
    mentions 1
    aliases "Tu et al. (2019)"
    description "A paper that discusses a model for question answering."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 388
    label "Shao et al. (2020)"
    type "Publication"
    documents "longformer"
    mentions 1
    aliases "Shao et al. (2020)"
    description "A paper that presents a model for question answering."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 389
    label "Kipf and Welling (2017)"
    type "Publication"
    documents "longformer"
    mentions 1
    aliases "Kipf and Welling (2017)"
    description "A paper that discusses Graph Neural Networks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 390
    label "Gla&#223; et al. (2019)"
    type "Publication"
    documents "longformer"
    mentions 1
    aliases "Gla&#223; et al. (2019)"
    description "A paper that presents a non-GNN method for question answering."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 391
    label "Groeneveld et al. (2020)"
    type "Publication"
    documents "longformer"
    mentions 1
    aliases "Groeneveld et al. (2020)"
    description "A paper that discusses a model for question answering."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 392
    label "Pathways"
    type "System"
    documents "palm"
    mentions 1
    aliases "Pathways"
    description "A new ML system enabling efficient training across multiple TPU Pods."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 393
    label "TPUv4"
    type "Hardware"
    documents "palm"
    mentions 1
    aliases "TPUv4"
    description "Tensor Processing Unit version 4 used for training the model."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 394
    label "BIG-bench"
    type "Benchmark"
    documents "palm"
    mentions 1
    aliases "BIG-bench"
    description "A benchmark suite for evaluating language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 395
    label "Aakanksha Chowdhery"
    type "Person"
    documents "palm"
    mentions 1
    aliases "Aakanksha Chowdhery"
    description "One of the authors of the paper."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 396
    label "Sharan Narang"
    type "Person"
    documents "palm"
    mentions 1
    aliases "Sharan Narang"
    description "One of the authors of the paper."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 397
    label "Jacob Devlin"
    type "Person"
    documents "palm"
    mentions 1
    aliases "Jacob Devlin"
    description "One of the authors of the paper."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 398
    label "Sanjay Ghemawat"
    type "Person"
    documents "palm"
    mentions 1
    aliases "Sanjay Ghemawat"
    description "One of the authors of the paper."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 399
    label "Ethical Considerations"
    type "Topic"
    documents "palm"
    mentions 1
    aliases "Ethical Considerations"
    description "Discussion on the ethical implications of large language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 400
    label "Bias and Toxicity"
    type "Analysis"
    documents "palm"
    mentions 1
    aliases "Bias and Toxicity"
    description "Analysis of bias and toxicity in model outputs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 401
    label "Language Models (LMs)"
    type "Technology"
    documents "palm"
    mentions 1
    aliases "Language Models (LMs)"
    description "Models used for few-shot predictions based on natural language task descriptions."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 402
    label "Few-shot predictions"
    type "Method"
    documents "palm"
    mentions 1
    aliases "Few-shot predictions"
    description "A prediction method where the model is given a task description and a few exemplars."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 403
    label "GLaM"
    type "Model"
    documents "palm"
    mentions 1
    aliases "GLaM"
    description "A post-GPT-3 language model that achieved few-shot state-of-the-art results."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 404
    label "Megatron&#8211;Turing NLG"
    type "Model"
    documents "palm,palm"
    mentions 2
    aliases "Megatron-Turing NLG 530B,Megatron&#8211;Turing NLG"
    description "A post-GPT-3 language model developed by Smith et al. in 2022."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 405
    label "Transformer architecture"
    type "Architecture"
    documents "palm,swin_transformer"
    mentions 2
    aliases "Transformer architecture"
    description "The architecture used in GPT-3 and its variants."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 406
    label "TPU v4 Pods"
    type "Hardware"
    documents "palm"
    mentions 1
    aliases "TPU v4 Pods"
    description "A type of hardware used for training large models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 407
    label "FLOPs utilization"
    type "Metric"
    documents "palm"
    mentions 1
    aliases "FLOPs utilization"
    description "A measure of efficiency in model and hardware performance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 408
    label "Wei et al. (2022b)"
    type "Person"
    documents "palm"
    mentions 1
    aliases "Wei et al. (2022b)"
    description "Researchers who contributed to chain-of-thought prompting."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 409
    label "Du et al. (2021)"
    type "Person"
    documents "palm"
    mentions 1
    aliases "Du et al. (2021)"
    description "Researchers who developed GLaM."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 410
    label "Smith et al. (2022)"
    type "Person"
    documents "palm"
    mentions 1
    aliases "Smith et al. (2022)"
    description "Researchers who developed Megatron&#8211;Turing NLG."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 411
    label "Thoppilan et al. (2022)"
    type "Person"
    documents "palm"
    mentions 1
    aliases "Thoppilan et al. (2022)"
    description "Researchers who developed LaMDA."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 412
    label "Brown et al. (2020)"
    type "Person"
    documents "palm"
    mentions 1
    aliases "Brown et al. (2020)"
    description "Researchers who developed GPT-3."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 413
    label "RoPE"
    type "embedding"
    documents "palm"
    mentions 1
    aliases "RoPE"
    description "Rotary Position Embeddings used for better performance on long sequence lengths."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 414
    label "SentencePiece"
    type "tokenization method"
    documents "palm"
    mentions 1
    aliases "SentencePiece"
    description "A method used for generating a vocabulary of tokens from the training data."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 415
    label "Kaplan et al., 2020"
    type "publication"
    documents "palm"
    mentions 1
    aliases "Kaplan et al., 2020"
    description "A reference discussing the power law in neural network scaling."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 416
    label "Shazeer, 2020"
    type "publication"
    documents "palm,palm"
    mentions 2
    aliases "Shazeer, 2020,Shazeer, 2019"
    description "A reference discussing the effectiveness of SwiGLU activations."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 417
    label "Wang &#38; Komatsuzaki, 2021"
    type "publication"
    documents "palm"
    mentions 1
    aliases "Wang &#38; Komatsuzaki, 2021"
    description "A reference discussing the parallel formulation in Transformer blocks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 418
    label "Kudo &#38; Richardson, 2018a"
    type "publication"
    documents "palm"
    mentions 1
    aliases "Kudo &#38; Richardson, 2018a"
    description "A reference discussing the SentencePiece vocabulary generation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 419
    label "540B parameters"
    type "Model Scale"
    documents "palm"
    mentions 1
    aliases "540B parameters"
    description "The largest model scale in the comparison."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 420
    label "62B parameters"
    type "Model Scale"
    documents "palm"
    mentions 1
    aliases "62B parameters"
    description "The medium model scale in the comparison."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 421
    label "8B parameters"
    type "Model Scale"
    documents "palm"
    mentions 1
    aliases "8B parameters"
    description "The smallest model scale in the comparison."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 422
    label "FLOPs"
    type "Metric"
    documents "palm,swin_transformer"
    mentions 2
    aliases "FLOPs"
    description "Floating Point Operations per second, approximately equal to the number of parameters."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 423
    label "Transformers"
    type "Architecture"
    documents "palm,vision_transformer"
    mentions 2
    aliases "Transformers"
    description "A type of model architecture used for natural language processing."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 424
    label "JAX"
    type "Framework"
    documents "palm"
    mentions 1
    aliases "JAX"
    description "A framework used for training and evaluation codebase."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 425
    label "T5X"
    type "Framework"
    documents "palm"
    mentions 1
    aliases "T5X"
    description "A framework used for training and evaluation codebase."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 426
    label "780 billion tokens"
    type "Dataset Size"
    documents "palm"
    mentions 1
    aliases "780 billion tokens"
    description "The total size of the pretraining dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 427
    label "Filtered webpages"
    type "Data Source"
    documents "palm"
    mentions 1
    aliases "Filtered webpages"
    description "One of the sources used in the training dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 428
    label "GitHub"
    type "Data Source"
    documents "palm"
    mentions 1
    aliases "GitHub"
    description "Source of code included in the training dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 429
    label "Social media conversations"
    type "Data Source"
    documents "palm"
    mentions 1
    aliases "Social media conversations"
    description "One of the sources used in the training dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 430
    label "News articles"
    type "Data Source"
    documents "palm"
    mentions 1
    aliases "News articles"
    description "One of the sources used in the training dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 431
    label "Levenshtein distance"
    type "Metric"
    documents "palm"
    mentions 1
    aliases "Levenshtein distance"
    description "A method used to remove duplicate files in the dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 432
    label "Mitchell et al., 2019"
    type "Publication"
    documents "palm"
    mentions 1
    aliases "Mitchell et al., 2019"
    description "Authors of the Model Card for PaLM."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 433
    label "Thoppilan et al., 2022"
    type "Publication"
    documents "palm"
    mentions 1
    aliases "Thoppilan et al., 2022"
    description "Authors of the LaMDA model."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 434
    label "Du et al., 2021"
    type "Publication"
    documents "palm"
    mentions 1
    aliases "Du et al., 2021"
    description "Authors of the GLaM model."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 435
    label "Bradbury et al., 2018"
    type "Publication"
    documents "palm"
    mentions 1
    aliases "Bradbury et al., 2018"
    description "Authors of the JAX framework."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 436
    label "Roberts et al., 2022"
    type "Publication"
    documents "palm"
    mentions 1
    aliases "Roberts et al., 2022"
    description "Authors of the T5X framework."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 437
    label "Jouppi et al., 2020"
    type "Publication"
    documents "palm"
    mentions 1
    aliases "Jouppi et al., 2020"
    description "Authors of the TPU v4 Pods."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 438
    label "Xu et al., 2021"
    type "Publication"
    documents "palm"
    mentions 1
    aliases "Xu et al., 2021"
    description "Authors discussing model and data parallelism."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 439
    label "Huang et al., 2019"
    type "Publication"
    documents "palm"
    mentions 1
    aliases "Huang et al., 2019"
    description "Authors discussing pipeline parallelism."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 440
    label "Lopes et al., 2017"
    type "Publication"
    documents "palm"
    mentions 1
    aliases "Lopes et al., 2017"
    description "Authors discussing duplicate files in source code."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 441
    label "Allamanis, 2019"
    type "Publication"
    documents "palm"
    mentions 1
    aliases "Allamanis, 2019"
    description "Authors discussing duplicate files in source code."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 442
    label "Gebru et al., 2021"
    type "Publication"
    documents "palm"
    mentions 1
    aliases "Gebru et al., 2021"
    description "Authors of the datasheet providing additional information."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 443
    label "Pathways system"
    type "system"
    documents "palm"
    mentions 1
    aliases "Pathways system"
    description "A system designed to scale training across TPU pods using two-way data parallelism."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 444
    label "TPU v4"
    type "hardware"
    documents "palm"
    mentions 1
    aliases "TPU v4"
    description "A type of Tensor Processing Unit used for accelerating machine learning workloads."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 445
    label "JAX/XLA"
    type "software"
    documents "palm"
    mentions 1
    aliases "JAX/XLA"
    description "A framework for high-performance numerical computing and machine learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 446
    label "Python client"
    type "software"
    documents "palm"
    mentions 1
    aliases "Python client"
    description "A client that constructs a sharded dataflow program for executing computations."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 447
    label "Gradient transfer"
    type "method"
    documents "palm"
    mentions 1
    aliases "Gradient transfer"
    description "The process of transferring computed gradients between TPU pods."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 448
    label "Model FLOPs utilization (MFU)"
    type "metric"
    documents "palm"
    mentions 1
    aliases "Model FLOPs utilization (MFU)"
    description "A metric for measuring training efficiency based on observed throughput relative to theoretical maximum throughput."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 449
    label "Hardware FLOPs utilization (HFU)"
    type "metric"
    documents "palm"
    mentions 1
    aliases "Hardware FLOPs utilization (HFU)"
    description "A metric reflecting the ratio of FLOPs observed on a device to its theoretical peak FLOPs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 450
    label "Rematerialization"
    type "method"
    documents "palm"
    mentions 1
    aliases "Rematerialization"
    description "A technique to trade off memory usage with compute by recomputing certain operations."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 451
    label "Megatron-Turing NLG"
    type "model"
    documents "palm"
    mentions 1
    aliases "Megatron-Turing NLG"
    description "A large language model with 530 billion parameters."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 452
    label "Google datacenter network"
    type "infrastructure"
    documents "palm"
    mentions 1
    aliases "Google datacenter network"
    description "The network infrastructure connecting TPU pods for data transfer."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 453
    label "Barham et al., 2022"
    type "publication"
    documents "palm"
    mentions 1
    aliases "Barham et al., 2022"
    description "A reference for the Pathways system and its design."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 454
    label "Singh et al., 2015"
    type "publication"
    documents "palm"
    mentions 1
    aliases "Singh et al., 2015"
    description "A reference for the Google datacenter network."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 455
    label "Narayanan et al., 2021b"
    type "publication"
    documents "palm"
    mentions 1
    aliases "Narayanan et al., 2021b"
    description "A reference for analytical accounting of hardware FLOPs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 456
    label "Appendix B"
    type "document section"
    documents "palm"
    mentions 1
    aliases "Appendix B"
    description "Section detailing the mathematical formula to compute MFU."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 457
    label "Classification Token"
    type "Model Component"
    documents "reformer"
    mentions 1
    aliases "Classification Token"
    description "A learnable embedding added to the input sequence for classification tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 458
    label "2D image topology"
    type "concept"
    documents "reformer"
    mentions 1
    aliases "2D image topology"
    description "The spatial arrangement of pixels in a two-dimensional image."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 459
    label "masked patch prediction"
    type "method"
    documents "reformer,vision_transformer"
    mentions 2
    aliases "masked patch prediction"
    description "A self-supervised learning task that involves predicting missing parts of an image."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 460
    label "LLaVA"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "LLaVA"
    description "Large Language and Vision Assistant, an end-to-end trained large multimodal model."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 461
    label "Vicuna"
    type "model"
    documents "segment_anything,segment_anything"
    mentions 2
    aliases "Vicuna,Vicuna-v0"
    description "Language decoder connected to the visual encoder in LLaVA."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 462
    label "Science QA"
    type "dataset"
    documents "segment_anything"
    mentions 1
    aliases "Science QA"
    description "A multimodal reasoning dataset used for evaluating LLaVA."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 463
    label "LLaVA-Bench"
    type "benchmark"
    documents "segment_anything"
    mentions 1
    aliases "LLaVA-Bench"
    description "A set of two challenging benchmarks for evaluating multimodal instruction-following."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 464
    label "ChatGPT"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "ChatGPT"
    description "A conversational AI model developed by OpenAI, demonstrating the power of aligned LLMs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 465
    label "Alpaca"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "Alpaca"
    description "An open-source LLM that matches the performance of GPT-3."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 466
    label "InstructPix2Pix"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "InstructPix2Pix"
    description "An image editing model that follows human instructions."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 467
    label "Flamingo"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "Flamingo"
    description "A multimodal model known for strong performance on zero-shot task transfer."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 468
    label "BLIP-2"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "BLIP-2"
    description "A model trained on image-text pairs for multimodal tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 469
    label "FROMAGe"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "FROMAGe"
    description "A model for multimodal tasks, trained on image-text pairs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 470
    label "KOSMOS-1"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "KOSMOS-1"
    description "A multimodal model trained on image-text pairs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 471
    label "PaLM-E"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "PaLM-E"
    description "A large multimodal model for embodied AI."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 472
    label "OpenFlamingo"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "OpenFlamingo"
    description "An open-source effort enabling LLaMA to use image inputs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 473
    label "LangChain"
    type "framework"
    documents "segment_anything"
    mentions 1
    aliases "LangChain"
    description "A system that coordinates various models via LLMs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 474
    label "Visual ChatGPT"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "Visual ChatGPT"
    description "A multimodal model that integrates visual and language capabilities."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 475
    label "X-GPT"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "X-GPT"
    description "A multimodal model that integrates visual and language capabilities."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 476
    label "MM-REACT"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "MM-REACT"
    description "A multimodal model that integrates visual and language capabilities."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 477
    label "VisProg"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "VisProg"
    description "A multimodal model that integrates visual and language capabilities."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 478
    label "ViperGPT"
    type "model"
    documents "segment_anything"
    mentions 1
    aliases "ViperGPT"
    description "A multimodal model that integrates visual and language capabilities."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 479
    label "LMM"
    type "Technology"
    documents "segment_anything"
    mentions 1
    aliases "LMM"
    description "Large Multimodal Model used for zero-shot task transfer and in-context learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 480
    label "LLaMA-Adapter"
    type "Model"
    documents "segment_anything"
    mentions 1
    aliases "LLaMA-Adapter"
    description "An open-source adaptation of LLaMA for image inputs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 481
    label "visual instruction tuning"
    type "Method"
    documents "segment_anything"
    mentions 1
    aliases "visual instruction tuning"
    description "A method aimed at improving model instruction-following abilities."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 482
    label "visual prompt tuning"
    type "Method"
    documents "segment_anything"
    mentions 1
    aliases "visual prompt tuning"
    description "A method aimed at improving parameter efficiency in model adaptation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 483
    label "COCO"
    type "Dataset"
    documents "segment_anything,swin_transformer"
    mentions 2
    aliases "COCO"
    description "A dataset used for generating instruction-following data."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 484
    label "CC"
    type "Dataset"
    documents "segment_anything"
    mentions 1
    aliases "CC"
    description "A public multimodal dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 485
    label "LAION"
    type "Dataset"
    documents "segment_anything"
    mentions 1
    aliases "LAION"
    description "Another public multimodal dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 486
    label "image-text pairs"
    type "Data Type"
    documents "segment_anything"
    mentions 1
    aliases "image-text pairs"
    description "Data consisting of images and their corresponding textual descriptions."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 487
    label "visual feature Z"
    type "data"
    documents "segment_anything"
    mentions 1
    aliases "visual feature Z"
    description "The output feature representation from the visual encoder."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 488
    label "language embedding tokens H"
    type "data"
    documents "segment_anything"
    mentions 1
    aliases "language embedding tokens H"
    description "Tokens representing language embeddings in the model."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 489
    label "projection matrix W"
    type "method"
    documents "segment_anything,segment_anything"
    mentions 2
    aliases "projection matrix W,projection matrix"
    description "A trainable matrix used to convert visual features into language embedding tokens."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 490
    label "CC3M"
    type "dataset"
    documents "segment_anything"
    mentions 1
    aliases "CC3M"
    description "A dataset containing image-text pairs used for training."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 491
    label "multi-turn conversation data"
    type "data"
    documents "segment_anything"
    mentions 1
    aliases "multi-turn conversation data"
    description "Data format used for training the model with multiple conversational turns."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 492
    label "instruction tokens X"
    type "data"
    documents "segment_anything"
    mentions 1
    aliases "instruction tokens X"
    description "Tokens representing instructions given to the model."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 493
    label "assistant answers X"
    type "data"
    documents "segment_anything"
    mentions 1
    aliases "assistant answers X"
    description "Tokens representing the responses generated by the assistant."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 494
    label "LLM"
    type "technology"
    documents "segment_anything"
    mentions 1
    aliases "LLM"
    description "Large Language Model used in conjunction with visual encoders."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 495
    label "visual encoder"
    type "architecture"
    documents "segment_anything"
    mentions 1
    aliases "visual encoder"
    description "A component that processes visual inputs."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 496
    label "ScienceQA"
    type "dataset"
    documents "segment_anything"
    mentions 1
    aliases "ScienceQA"
    description "A large-scale multimodal science question dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 497
    label "LLaVA-Instruct-158K"
    type "dataset"
    documents "segment_anything"
    mentions 1
    aliases "LLaVA-Instruct-158K"
    description "A dataset used for fine-tuning LLaVA."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 498
    label "A100"
    type "hardware"
    documents "segment_anything"
    mentions 1
    aliases "A100"
    description "NVIDIA A100 GPUs used for training the models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 499
    label "instruction-following capability"
    type "metric"
    documents "segment_anything"
    mentions 1
    aliases "instruction-following capability"
    description "A measure of how well the model follows user instructions."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 500
    label "training data"
    type "method"
    documents "segment_anything"
    mentions 1
    aliases "training data"
    description "Data organized as single-turn conversations for training."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 501
    label "evaluation metric"
    type "metric"
    documents "segment_anything"
    mentions 1
    aliases "evaluation metric"
    description "A quantitative measure to assess model performance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 502
    label "COCO-Val-2014"
    type "dataset"
    documents "segment_anything"
    mentions 1
    aliases "COCO-Val-2014"
    description "A dataset used to generate questions for evaluating models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 503
    label "MM-CoT"
    type "method"
    documents "segment_anything"
    mentions 1
    aliases "MM-CoT"
    description "Multimodal chain-of-thought method used as a state-of-the-art approach on the ScienceQA dataset."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 504
    label "mean&#177;std"
    type "metric"
    documents "segment_anything"
    mentions 1
    aliases "mean&#177;std"
    description "Statistical representation of model performance results."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 505
    label "Swin Transformer"
    type "architecture"
    documents "swin_transformer"
    mentions 1
    aliases "Swin Transformer"
    description "A hierarchical vision transformer designed for computer vision tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 506
    label "Microsoft Research Asia"
    type "organization"
    documents "swin_transformer"
    mentions 1
    aliases "Microsoft Research Asia"
    description "The organization where the authors of the paper are affiliated."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 507
    label "Ze Liu"
    type "person"
    documents "swin_transformer"
    mentions 1
    aliases "Ze Liu"
    description "One of the authors of the paper."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 508
    label "Yutong Lin"
    type "person"
    documents "swin_transformer"
    mentions 1
    aliases "Yutong Lin"
    description "One of the authors of the paper."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 509
    label "Yue Cao"
    type "person"
    documents "swin_transformer"
    mentions 1
    aliases "Yue Cao"
    description "One of the authors of the paper."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 510
    label "Han Hu"
    type "person"
    documents "swin_transformer"
    mentions 1
    aliases "Han Hu"
    description "One of the authors of the paper."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 511
    label "Yixuan Wei"
    type "person"
    documents "swin_transformer"
    mentions 1
    aliases "Yixuan Wei"
    description "One of the authors of the paper."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 512
    label "Zheng Zhang"
    type "person"
    documents "swin_transformer"
    mentions 1
    aliases "Zheng Zhang"
    description "One of the authors of the paper."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 513
    label "Stephen Lin"
    type "person"
    documents "swin_transformer"
    mentions 1
    aliases "Stephen Lin"
    description "One of the authors of the paper."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 514
    label "Baining Guo"
    type "person"
    documents "swin_transformer"
    mentions 1
    aliases "Baining Guo"
    description "One of the authors of the paper."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 515
    label "ADE20K"
    type "dataset"
    documents "swin_transformer"
    mentions 1
    aliases "ADE20K"
    description "A dataset used for semantic segmentation tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 516
    label "feature pyramid networks (FPN)"
    type "method"
    documents "swin_transformer"
    mentions 1
    aliases "feature pyramid networks (FPN)"
    description "A technique for dense predictions in computer vision."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 517
    label "U-Net"
    type "method"
    documents "swin_transformer"
    mentions 1
    aliases "U-Net"
    description "A convolutional network architecture for semantic segmentation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 518
    label "ViT/DeiT"
    type "architecture"
    documents "swin_transformer"
    mentions 1
    aliases "ViT/DeiT"
    description "Previous vision transformer architectures that Swin Transformer outperforms."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 519
    label "Copy-paste"
    type "method"
    documents "swin_transformer"
    mentions 1
    aliases "Copy-paste"
    description "A technique used in object detection that Swin Transformer improves upon."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 520
    label "DetectoRS"
    type "method"
    documents "swin_transformer"
    mentions 1
    aliases "DetectoRS"
    description "A method for object detection that Swin Transformer surpasses."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 521
    label "SETR"
    type "method"
    documents "swin_transformer"
    mentions 1
    aliases "SETR"
    description "A method for semantic segmentation that Swin Transformer outperforms."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 522
    label "mIoU"
    type "metric"
    documents "swin_transformer"
    mentions 1
    aliases "mIoU"
    description "Mean Intersection over Union, a metric for evaluating segmentation tasks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 523
    label "AlexNet"
    type "architecture"
    documents "swin_transformer"
    mentions 1
    aliases "AlexNet"
    description "A pioneering CNN that popularized deep learning in computer vision."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 524
    label "VGG"
    type "architecture"
    documents "swin_transformer"
    mentions 1
    aliases "VGG"
    description "A deep CNN architecture known for its simplicity and depth."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 525
    label "GoogleNet"
    type "architecture"
    documents "swin_transformer"
    mentions 1
    aliases "GoogleNet"
    description "A CNN architecture that introduced the inception module."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 526
    label "DenseNet"
    type "architecture"
    documents "swin_transformer"
    mentions 1
    aliases "DenseNet"
    description "A CNN architecture that connects each layer to every other layer."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 527
    label "HRNet"
    type "architecture"
    documents "swin_transformer"
    mentions 1
    aliases "HRNet"
    description "High-Resolution Network for maintaining high-resolution representations."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 528
    label "ViT"
    type "architecture"
    documents "swin_transformer"
    mentions 1
    aliases "ViT"
    description "Vision Transformer, a model that applies transformer architecture to image classification."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 529
    label "patch merging"
    type "method"
    documents "swin_transformer"
    mentions 1
    aliases "patch merging"
    description "A technique used in Swin Transformer to reduce the number of tokens."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 530
    label "linear embedding"
    type "method"
    documents "swin_transformer"
    mentions 1
    aliases "linear embedding"
    description "A process to project raw pixel values into an arbitrary dimension."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 531
    label "DeiT"
    type "architecture"
    documents "swin_transformer"
    mentions 1
    aliases "DeiT"
    description "Data-efficient image Transformers, which introduces training strategies for ViT."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 532
    label "MLP"
    type "method"
    documents "swin_transformer"
    mentions 1
    aliases "MLP"
    description "Multi-layer perceptron, a type of neural network."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 533
    label "W-MSA"
    type "module"
    documents "swin_transformer"
    mentions 1
    aliases "W-MSA"
    description "Window-based multi-head self-attention module."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 534
    label "SW-MSA"
    type "module"
    documents "swin_transformer"
    mentions 1
    aliases "SW-MSA"
    description "Shifted window-based multi-head self-attention module."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 535
    label "Stage 1"
    type "process"
    documents "swin_transformer,swin_transformer,swin_transformer,swin_transformer"
    mentions 4
    aliases "Stage 3,Stage 2,Stage 1,Stage 4"
    description "The first stage of the Swin Transformer architecture."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 536
    label "RegNet"
    type "architecture"
    documents "swin_transformer"
    mentions 1
    aliases "RegNet"
    description "A family of convolutional neural networks optimized through architecture search."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 537
    label "Relative Position Bias"
    type "method"
    documents "swin_transformer"
    mentions 1
    aliases "Relative Position Bias"
    description "A technique used in self-attention mechanisms to incorporate positional information."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 538
    label "Top-1 Accuracy"
    type "metric"
    documents "swin_transformer"
    mentions 1
    aliases "Top-1 Accuracy"
    description "A metric used to evaluate the performance of classification models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 539
    label "Batch Size"
    type "parameter"
    documents "swin_transformer"
    mentions 1
    aliases "Batch Size"
    description "The number of training examples utilized in one iteration."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 540
    label "Cyclic Shifting"
    type "method"
    documents "swin_transformer"
    mentions 1
    aliases "Cyclic Shifting"
    description "A technique proposed to improve batch computation efficiency in window partitioning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 541
    label "Swin-T"
    type "model variant"
    documents "swin_transformer,swin_transformer,swin_transformer,swin_transformer"
    mentions 4
    aliases "Swin-T,Swin-B,Swin-S,Swin-L"
    description "A variant of the Swin Transformer with specific hyperparameters."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 542
    label "Cascade Mask R-CNN"
    type "framework"
    documents "swin_transformer"
    mentions 1
    aliases "Cascade Mask R-CNN"
    description "An object detection framework used for instance segmentation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 543
    label "ATSS"
    type "framework"
    documents "swin_transformer"
    mentions 1
    aliases "ATSS"
    description "An object detection framework used for instance segmentation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 544
    label "RepPoints v2"
    type "framework"
    documents "swin_transformer"
    mentions 1
    aliases "RepPoints v2"
    description "An object detection framework used for instance segmentation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 545
    label "Sparse RCNN"
    type "framework"
    documents "swin_transformer"
    mentions 1
    aliases "Sparse RCNN"
    description "An object detection framework used for instance segmentation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 546
    label "HTC++"
    type "Framework"
    documents "swin_transformer"
    mentions 1
    aliases "HTC++"
    description "An improved version of the HTC framework for object detection."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 547
    label "APbox"
    type "Metric"
    documents "swin_transformer"
    mentions 1
    aliases "APbox"
    description "Average Precision for bounding box detection."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 548
    label "APmask"
    type "Metric"
    documents "swin_transformer"
    mentions 1
    aliases "APmask"
    description "Average Precision for mask prediction in instance segmentation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 549
    label "DeiT-S"
    type "Model"
    documents "swin_transformer"
    mentions 1
    aliases "DeiT-S"
    description "Data-efficient image Transformers, a model architecture for image classification."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 550
    label "EfficientDet-D7"
    type "Model"
    documents "swin_transformer"
    mentions 1
    aliases "EfficientDet-D7"
    description "A model architecture for object detection that balances accuracy and efficiency."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 551
    label "LSTM"
    type "architecture"
    documents "transformer_xl"
    mentions 1
    aliases "LSTM"
    description "Long Short-Term Memory networks, a standard solution for language modeling."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 552
    label "RNN"
    type "architecture"
    documents "transformer_xl"
    mentions 1
    aliases "RNN"
    description "Recurrent Neural Networks, a type of neural network for sequential data."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 553
    label "Carnegie Mellon University"
    type "organization"
    documents "transformer_xl"
    mentions 1
    aliases "Carnegie Mellon University"
    description "An academic institution where some authors are affiliated."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 554
    label "WikiText-103"
    type "dataset"
    documents "transformer_xl"
    mentions 1
    aliases "WikiText-103"
    description "A dataset used for language modeling."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 555
    label "One Billion Word"
    type "dataset"
    documents "transformer_xl"
    mentions 1
    aliases "One Billion Word"
    description "A large dataset for language modeling."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 556
    label "context fragmentation"
    type "problem"
    documents "transformer_xl"
    mentions 1
    aliases "context fragmentation"
    description "The issue of losing contextual information due to fixed-length segments."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 557
    label "gradient vanishing"
    type "problem"
    documents "transformer_xl"
    mentions 1
    aliases "gradient vanishing"
    description "A common issue in training RNNs that affects optimization."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 558
    label "gradient explosion"
    type "problem"
    documents "transformer_xl"
    mentions 1
    aliases "gradient explosion"
    description "A common issue in training RNNs that affects optimization."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 559
    label "Softmax function"
    type "function"
    documents "transformer_xl"
    mentions 1
    aliases "Softmax function"
    description "A function that converts logits into a categorical probability distribution."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 560
    label "Bengio et al. (2003)"
    type "publication"
    documents "transformer_xl"
    mentions 1
    aliases "Bengio et al. (2003)"
    description "A foundational paper in language modeling."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 561
    label "Mikolov et al. (2010)"
    type "publication"
    documents "transformer_xl"
    mentions 1
    aliases "Mikolov et al. (2010)"
    description "A significant work on RNNs and language modeling."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 562
    label "Merity et al. (2016)"
    type "publication"
    documents "transformer_xl"
    mentions 1
    aliases "Merity et al. (2016)"
    description "Research on language modeling techniques."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 563
    label "Galand Ghahramani (2016)"
    type "publication"
    documents "transformer_xl"
    mentions 1
    aliases "Galand Ghahramani (2016)"
    description "Work on improving optimization algorithms."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 564
    label "Grave et al. (2016a)"
    type "publication"
    documents "transformer_xl"
    mentions 1
    aliases "Grave et al. (2016a)"
    description "Research on speeding up Softmax computation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 565
    label "Yang et al. (2017)"
    type "publication"
    documents "transformer_xl"
    mentions 1
    aliases "Yang et al. (2017)"
    description "Work on enriching output distribution families."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 566
    label "Peters et al. (2018)"
    type "publication"
    documents "transformer_xl"
    mentions 1
    aliases "Peters et al. (2018)"
    description "Research on efficiency in language modeling."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 567
    label "Devlin et al. (2018)"
    type "publication"
    documents "transformer_xl"
    mentions 1
    aliases "Devlin et al. (2018)"
    description "Contributions to language modeling techniques."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 568
    label "SG function"
    type "function"
    documents "transformer_xl"
    mentions 1
    aliases "SG function"
    description "Stop-gradient function used to prevent gradient flow."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 569
    label "positional encodings"
    type "concept"
    documents "transformer_xl"
    mentions 1
    aliases "positional encodings"
    description "Encodings that provide sequence order information in Transformers."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 570
    label "hidden state"
    type "concept"
    documents "transformer_xl,transformer_xl"
    mentions 2
    aliases "hidden states,hidden state"
    description "The internal state representation in neural networks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 571
    label "logits"
    type "concept"
    documents "transformer_xl"
    mentions 1
    aliases "logits"
    description "Raw output scores from the model before applying Softmax."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 572
    label "long-term dependency"
    type "concept"
    documents "transformer_xl"
    mentions 1
    aliases "long-term dependency"
    description "The ability to model dependencies over long sequences."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 573
    label "BPTT"
    type "method"
    documents "transformer_xl"
    mentions 1
    aliases "BPTT"
    description "Backpropagation Through Time, a technique for training recurrent neural networks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 574
    label "enwiki8"
    type "dataset"
    documents "transformer_xl"
    mentions 1
    aliases "enwiki8"
    description "A dataset used for evaluating language models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 575
    label "GPU memory"
    type "resource"
    documents "transformer_xl"
    mentions 1
    aliases "GPU memory"
    description "Graphics Processing Unit memory used for storing data during model training and evaluation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 576
    label "memory augmented neural networks"
    type "architecture"
    documents "transformer_xl"
    mentions 1
    aliases "memory augmented neural networks"
    description "Neural networks that utilize external memory to enhance learning."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 577
    label "attention score"
    type "metric"
    documents "transformer_xl"
    mentions 1
    aliases "attention score"
    description "A score that determines the importance of different elements in a sequence."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 578
    label "query vector"
    type "concept"
    documents "transformer_xl"
    mentions 1
    aliases "query vector"
    description "A vector representing the current input in the attention mechanism."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 579
    label "key vector"
    type "concept"
    documents "transformer_xl"
    mentions 1
    aliases "key vector"
    description "A vector used in the attention mechanism to determine relevance."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 580
    label "content-based addressing"
    type "method"
    documents "transformer_xl"
    mentions 1
    aliases "content-based addressing"
    description "A method of addressing memory based on the content of the input."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 581
    label "location-based key vectors"
    type "concept"
    documents "transformer_xl"
    mentions 1
    aliases "location-based key vectors"
    description "Key vectors that are influenced by the position of the input."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 582
    label "Shaw et al. (2018)"
    type "publication"
    documents "transformer_xl"
    mentions 1
    aliases "Shaw et al. (2018)"
    description "A paper that explored relative positional encodings in machine translation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 583
    label "Huang et al. (2018)"
    type "publication"
    documents "transformer_xl"
    mentions 1
    aliases "Huang et al. (2018)"
    description "A paper that applied relative positional encodings in music generation."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 584
    label "Masked-Softmax"
    type "method"
    documents "transformer_xl"
    mentions 1
    aliases "Masked-Softmax"
    description "A variant of the softmax function used in attention mechanisms."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 585
    label "LayerNorm"
    type "method"
    documents "transformer_xl"
    mentions 1
    aliases "LayerNorm"
    description "A normalization technique applied to layers in neural networks."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 586
    label "Positionwise-Feed-Forward"
    type "method"
    documents "transformer_xl"
    mentions 1
    aliases "Positionwise-Feed-Forward"
    description "A feed-forward neural network applied independently to each position in the input."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 587
    label "absolute positional embedding"
    type "concept"
    documents "transformer_xl,transformer_xl"
    mentions 2
    aliases "absolute positional embedding,relative positional embedding"
    description "A method for encoding the position of tokens in a sequence."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 588
    label "u"
    type "parameter"
    documents "transformer_xl"
    mentions 1
    aliases "u"
    description "A trainable parameter introduced to replace the query vector in the attention mechanism."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 589
    label "v"
    type "parameter"
    documents "transformer_xl"
    mentions 1
    aliases "v"
    description "A trainable parameter added to substitute the query vector in the attention mechanism."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 590
    label "bits per character (bpc)"
    type "metric"
    documents "transformer_xl"
    mentions 1
    aliases "bits per character (bpc)"
    description "A metric used to evaluate language models based on the number of bits needed to encode characters."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 591
    label "Baevski and Auli"
    type "people"
    documents "transformer_xl"
    mentions 1
    aliases "Baevski and Auli"
    description "Researchers who contributed to the development of adaptive input representations."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 592
    label "Grave et al. (2016)"
    type "citation"
    documents "transformer_xl"
    mentions 1
    aliases "Grave et al. (2016)"
    description "Authors of a paper discussing neural cache mechanisms."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 593
    label "Dauphin et al. (2016)"
    type "citation"
    documents "transformer_xl"
    mentions 1
    aliases "Dauphin et al. (2016)"
    description "Authors of a paper discussing GCNN architectures."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 594
    label "AWD-LSTM"
    type "architecture"
    documents "transformer_xl"
    mentions 1
    aliases "AWD-LSTM"
    description "A type of LSTM model that incorporates dropout and weight averaging."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 595
    label "MoS"
    type "architecture"
    documents "transformer_xl"
    mentions 1
    aliases "MoS"
    description "A method proposed by Yang et al. for fine-tuning models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 596
    label "Khandelwal et al. (2018)"
    type "person"
    documents "transformer_xl"
    mentions 1
    aliases "Khandelwal et al. (2018)"
    description "Proposed a method to evaluate Effective Context Length (ECL)."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 597
    label "Effective Context Length (ECL)"
    type "metric"
    documents "transformer_xl"
    mentions 1
    aliases "Effective Context Length (ECL)"
    description "The longest length to which increasing context span leads to performance gain."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 598
    label "Relative Effective Context Length (RECL)"
    type "metric"
    documents "transformer_xl"
    mentions 1
    aliases "Relative Effective Context Length (RECL)"
    description "A metric to measure the relative improvement of context length in models."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 599
    label "Layer Normalization (LN)"
    type "Technique"
    documents "vision_transformer"
    mentions 1
    aliases "Layer Normalization (LN)"
    description "A technique applied before every block in the Transformer encoder."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 600
    label "Residual Connections"
    type "Technique"
    documents "vision_transformer"
    mentions 1
    aliases "Residual Connections"
    description "Connections added after every block in the Transformer encoder."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 601
    label "Self-Supervision"
    type "Learning Method"
    documents "vision_transformer"
    mentions 1
    aliases "Self-Supervision"
    description "A method explored for training the Vision Transformer."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 602
    label "R50x1"
    type "model"
    documents "vision_transformer,vision_transformer"
    mentions 2
    aliases "R50x1,R50x2"
    description "ResNet model variant"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 603
    label "R101x1"
    type "model"
    documents "vision_transformer"
    mentions 1
    aliases "R101x1"
    description "ResNet model variant"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 604
    label "R152x1"
    type "model"
    documents "vision_transformer,vision_transformer"
    mentions 2
    aliases "R152x1,R152x2"
    description "ResNet model variant"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 605
    label "R200x3"
    type "model"
    documents "vision_transformer"
    mentions 1
    aliases "R200x3"
    description "ResNet model variant"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 606
    label "hybrids"
    type "architecture"
    documents "vision_transformer"
    mentions 1
    aliases "hybrids"
    description "Combination of ResNet and Vision Transformer architectures"
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 607
    label "position embeddings"
    type "concept"
    documents "vision_transformer"
    mentions 1
    aliases "position embeddings"
    description "Learned representations that encode the spatial information of image patches."
    confidence 0
    pagerank 0
    centrality 0
  ]
  node [
    id 608
    label "Google"
    type "organization"
    documents "vision_transformer"
    mentions 1
    aliases "Google"
    description "The organization where the research was conducted."
    confidence 0
    pagerank 0
    centrality 0
  ]
  edge [
    source 0
    target 1
    relations "based_on"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 0
    target 2
    relations "improves"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 0.9
  ]
  edge [
    source 0
    target 3
    relations "evaluated_on"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 0
    target 4
    relations "evaluated_on"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 0
    target 31
    relations "is_based_on"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 0.95
  ]
  edge [
    source 5
    target 7
    relations "uses"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 5
    target 8
    relations "uses"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 5
    target 9
    relations "uses"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 5
    target 10
    relations "uses"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 5
    target 11
    relations "uses"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 5
    target 12
    relations "uses"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 5
    target 13
    relations "uses"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 5
    target 14
    relations "uses"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 6
    target 103
    relations "authored"
    mentions 2
    sources "deit,vision_transformer"
    confidence 0.95
  ]
  edge [
    source 6
    target 255
    relations "developed"
    mentions 1
    sources "palm"
    confidence 0.9
  ]
  edge [
    source 10
    target 103
    relations "is a co-author of"
    mentions 1
    sources "deit"
    confidence 0.95
  ]
  edge [
    source 15
    target 17
    relations "uses"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 16
    target 17
    relations "uses"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 17
    target 24
    relations "is_a"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 18
    target 24
    relations "is_a"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 19
    target 15
    relations "is_used_in"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 19
    target 16
    relations "is_used_in"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 20
    target 15
    relations "is_used_in"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 20
    target 16
    relations "is_used_in"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 21
    target 15
    relations "is_used_in"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 21
    target 16
    relations "is_used_in"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 23
    target 16
    relations "is_used_in"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 1.0
  ]
  edge [
    source 31
    target 0
    relations "is_used_in"
    mentions 1
    sources "reformer"
    confidence 0.9
  ]
  edge [
    source 34
    target 0
    relations "is_used_in"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 0.95
  ]
  edge [
    source 34
    target 322
    relations "is used in"
    mentions 1
    sources "transformer_xl"
    confidence 0.9
  ]
  edge [
    source 34
    target 34
    relations "extends"
    mentions 1
    sources "transformer_xl"
    confidence 0.9
  ]
  edge [
    source 46
    target 47
    relations "contains"
    mentions 1
    sources "attention_is_all_you_need"
    confidence 0.9
  ]
  edge [
    source 65
    target 80
    relations "achieves"
    mentions 1
    sources "clip"
    confidence 0.9
  ]
  edge [
    source 65
    target 93
    relations "uses"
    mentions 1
    sources "clip"
    confidence 0.9
  ]
  edge [
    source 65
    target 107
    relations "uses"
    mentions 1
    sources "clip"
    confidence 0.9
  ]
  edge [
    source 65
    target 105
    relations "is_trained_with"
    mentions 1
    sources "clip"
    confidence 0.9
  ]
  edge [
    source 65
    target 67
    relations "improves"
    mentions 1
    sources "clip"
    confidence 0.9
  ]
  edge [
    source 65
    target 69
    relations "matches_performance_of"
    mentions 1
    sources "clip"
    confidence 0.8
  ]
  edge [
    source 65
    target 115
    relations "outperforms"
    mentions 1
    sources "clip"
    confidence 0.9
  ]
  edge [
    source 65
    target 68
    relations "trained_on"
    mentions 1
    sources "clip"
    confidence 0.8
  ]
  edge [
    source 65
    target 126
    relations "reduces_errors_on"
    mentions 1
    sources "clip"
    confidence 0.9
  ]
  edge [
    source 65
    target 125
    relations "doubles_accuracy_on"
    mentions 1
    sources "clip"
    confidence 0.85
  ]
  edge [
    source 65
    target 487
    relations "provides"
    mentions 1
    sources "segment_anything"
    confidence 0.9
  ]
  edge [
    source 66
    target 75
    relations "developed_by"
    mentions 2
    sources "gpt3_language_models,gpt3"
    confidence 1.0
  ]
  edge [
    source 66
    target 198
    relations "applies_to"
    mentions 2
    sources "gpt3_language_models,gpt3"
    confidence 1.0
  ]
  edge [
    source 66
    target 202
    relations "achieves_performance_on"
    mentions 2
    sources "gpt3_language_models,gpt3"
    confidence 0.9
  ]
  edge [
    source 66
    target 203
    relations "achieves_performance_on"
    mentions 2
    sources "gpt3_language_models,gpt3"
    confidence 0.9
  ]
  edge [
    source 66
    target 204
    relations "achieves_performance_on"
    mentions 2
    sources "gpt3_language_models,gpt3"
    confidence 0.9
  ]
  edge [
    source 66
    target 213
    relations "evaluated_on"
    mentions 2
    sources "gpt3_language_models,gpt3"
    confidence 0.9
  ]
  edge [
    source 66
    target 214
    relations "evaluated_on"
    mentions 2
    sources "gpt3_language_models,gpt3"
    confidence 0.9
  ]
  edge [
    source 66
    target 215
    relations "evaluated_on"
    mentions 2
    sources "gpt3_language_models,gpt3"
    confidence 0.9
  ]
  edge [
    source 66
    target 211
    relations "uses"
    mentions 1
    sources "gpt3_language_models"
    confidence 0.95
  ]
  edge [
    source 66
    target 109
    relations "uses"
    mentions 2
    sources "gpt3_language_models,gpt3"
    confidence 0.9
  ]
  edge [
    source 66
    target 249
    relations "requires"
    mentions 1
    sources "gpt3"
    confidence 0.8
  ]
  edge [
    source 66
    target 231
    relations "is trained on"
    mentions 1
    sources "gpt3"
    confidence 0.8
  ]
  edge [
    source 66
    target 206
    relations "uses"
    mentions 1
    sources "gpt3"
    confidence 0.9
  ]
  edge [
    source 66
    target 96
    relations "uses"
    mentions 1
    sources "gpt3"
    confidence 0.85
  ]
  edge [
    source 66
    target 234
    relations "uses"
    mentions 2
    sources "gpt3,gpt3"
    confidence 0.85
  ]
  edge [
    source 66
    target 235
    relations "uses"
    mentions 1
    sources "gpt3"
    confidence 0.85
  ]
  edge [
    source 66
    target 253
    relations "is_compared_with"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 67
    target 139
    relations "is_a_subset_of"
    mentions 2
    sources "reformer,vision_transformer"
    confidence 0.85
  ]
  edge [
    source 67
    target 200
    relations "used_for"
    mentions 1
    sources "vision_transformer"
    confidence 0.9
  ]
  edge [
    source 69
    target 65
    relations "matches accuracy of"
    mentions 1
    sources "clip"
    confidence 0.85
  ]
  edge [
    source 75
    target 65
    relations "developed"
    mentions 1
    sources "clip"
    confidence 0.9
  ]
  edge [
    source 75
    target 208
    relations "associated_with"
    mentions 1
    sources "gpt3"
    confidence 0.7
  ]
  edge [
    source 75
    target 66
    relations "developed"
    mentions 1
    sources "gpt3"
    confidence 0.9
  ]
  edge [
    source 80
    target 212
    relations "is_a"
    mentions 1
    sources "gpt3_language_models"
    confidence 0.9
  ]
  edge [
    source 95
    target 102
    relations "is_related_to"
    mentions 1
    sources "clip"
    confidence 0.6
  ]
  edge [
    source 96
    target 206
    relations "augments"
    mentions 1
    sources "gpt3_language_models"
    confidence 0.85
  ]
  edge [
    source 102
    target 103
    relations "is compared_with,is_compared_with"
    mentions 2
    sources "deit,reformer"
    confidence 0.9
  ]
  edge [
    source 102
    target 528
    relations "is_used_as_baseline_for"
    mentions 1
    sources "reformer"
    confidence 0.8
  ]
  edge [
    source 102
    target 0
    relations "applies_before"
    mentions 1
    sources "vision_transformer"
    confidence 0.7
  ]
  edge [
    source 103
    target 0
    relations "is based_on,is_based_on"
    mentions 2
    sources "deit,reformer"
    confidence 0.95
  ]
  edge [
    source 103
    target 139
    relations "is trained_on,is_pretrained_on"
    mentions 3
    sources "deit,reformer,vision_transformer"
    confidence 0.85
  ]
  edge [
    source 103
    target 81
    relations "is trained_on,is_pretrained_on"
    mentions 3
    sources "deit,reformer,vision_transformer"
    confidence 0.85
  ]
  edge [
    source 103
    target 67
    relations "is evaluated_on"
    mentions 2
    sources "deit,vision_transformer"
    confidence 0.9
  ]
  edge [
    source 103
    target 112
    relations "is evaluated_on"
    mentions 2
    sources "deit,vision_transformer"
    confidence 0.9
  ]
  edge [
    source 103
    target 127
    relations "is evaluated_on"
    mentions 2
    sources "deit,vision_transformer"
    confidence 0.9
  ]
  edge [
    source 103
    target 141
    relations "is_based_on"
    mentions 3
    sources "deit,reformer,vision_transformer"
    confidence 0.9
  ]
  edge [
    source 103
    target 140
    relations "uses"
    mentions 3
    sources "deit,reformer,vision_transformer"
    confidence 0.9
  ]
  edge [
    source 103
    target 102
    relations "is_compared_with"
    mentions 1
    sources "deit"
    confidence 0.8
  ]
  edge [
    source 103
    target 178
    relations "uses"
    mentions 3
    sources "deit,reformer,vision_transformer"
    confidence 0.9
  ]
  edge [
    source 103
    target 423
    relations "is based_on"
    mentions 1
    sources "vision_transformer"
    confidence 0.95
  ]
  edge [
    source 115
    target 65
    relations "compares_to"
    mentions 1
    sources "clip"
    confidence 0.85
  ]
  edge [
    source 115
    target 122
    relations "dates_back_to"
    mentions 1
    sources "clip"
    confidence 0.7
  ]
  edge [
    source 128
    target 103
    relations "is a co-author of"
    mentions 1
    sources "deit"
    confidence 0.95
  ]
  edge [
    source 129
    target 103
    relations "is a co-author of"
    mentions 1
    sources "deit"
    confidence 0.95
  ]
  edge [
    source 130
    target 103
    relations "is a co-author of"
    mentions 1
    sources "deit"
    confidence 0.95
  ]
  edge [
    source 131
    target 103
    relations "is a co-author of"
    mentions 1
    sources "deit"
    confidence 0.95
  ]
  edge [
    source 132
    target 103
    relations "is a co-author of"
    mentions 1
    sources "deit"
    confidence 0.95
  ]
  edge [
    source 133
    target 103
    relations "is a co-author of"
    mentions 1
    sources "deit"
    confidence 0.95
  ]
  edge [
    source 134
    target 103
    relations "is a co-author of"
    mentions 1
    sources "deit"
    confidence 0.95
  ]
  edge [
    source 135
    target 103
    relations "is a co-author of"
    mentions 1
    sources "deit"
    confidence 0.95
  ]
  edge [
    source 136
    target 103
    relations "is a co-author of"
    mentions 1
    sources "deit"
    confidence 0.95
  ]
  edge [
    source 137
    target 103
    relations "is a co-author of"
    mentions 1
    sources "deit"
    confidence 0.95
  ]
  edge [
    source 138
    target 103
    relations "is a co-author of"
    mentions 1
    sources "deit"
    confidence 0.95
  ]
  edge [
    source 139
    target 152
    relations "is_a_superset_of"
    mentions 2
    sources "deit,vision_transformer"
    confidence 0.9
  ]
  edge [
    source 139
    target 67
    relations "is_a_superset_of"
    mentions 2
    sources "reformer,vision_transformer"
    confidence 0.85
  ]
  edge [
    source 139
    target 199
    relations "used_for"
    mentions 1
    sources "swin_transformer"
    confidence 0.95
  ]
  edge [
    source 141
    target 150
    relations "is_inspired_by"
    mentions 1
    sources "reformer"
    confidence 0.9
  ]
  edge [
    source 143
    target 315
    relations "supports"
    mentions 1
    sources "longformer"
    confidence 0.85
  ]
  edge [
    source 144
    target 103
    relations "is_used_in,is_applied_to"
    mentions 2
    sources "deit,reformer"
    confidence 0.8
  ]
  edge [
    source 150
    target 405
    relations "introduces,proposed,introduced"
    mentions 5
    sources "deit,transformer_xl,transformer_xl,transformer_xl,vision_transformer"
    confidence 0.95
  ]
  edge [
    source 152
    target 139
    relations "is_a_subset_of"
    mentions 3
    sources "deit,reformer,vision_transformer"
    confidence 0.9
  ]
  edge [
    source 156
    target 349
    relations "is_based_on"
    mentions 3
    sources "deit,reformer,vision_transformer"
    confidence 0.9
  ]
  edge [
    source 157
    target 349
    relations "is_based_on"
    mentions 6
    sources "deit,deit,reformer,reformer,vision_transformer,vision_transformer"
    confidence 0.9
  ]
  edge [
    source 159
    target 200
    relations "is_used_for"
    mentions 2
    sources "deit,reformer"
    confidence 0.95
  ]
  edge [
    source 160
    target 168
    relations "is_compared_with,is_compared_to"
    mentions 2
    sources "reformer,vision_transformer"
    confidence 0.85
  ]
  edge [
    source 161
    target 168
    relations "is_compared_with,is_compared_to"
    mentions 2
    sources "reformer,vision_transformer"
    confidence 0.85
  ]
  edge [
    source 163
    target 161
    relations "compares_to"
    mentions 1
    sources "deit"
    confidence 0.9
  ]
  edge [
    source 163
    target 139
    relations "pre_trained_on,is_pretrained_on"
    mentions 4
    sources "deit,reformer,vision_transformer,vision_transformer"
    confidence 0.9
  ]
  edge [
    source 163
    target 164
    relations "trained_using"
    mentions 2
    sources "deit,reformer"
    confidence 0.8
  ]
  edge [
    source 163
    target 81
    relations "is_pretrained_on"
    mentions 1
    sources "vision_transformer"
    confidence 0.8
  ]
  edge [
    source 163
    target 127
    relations "evaluated_on"
    mentions 1
    sources "vision_transformer"
    confidence 0.8
  ]
  edge [
    source 165
    target 528
    relations "compared_to"
    mentions 2
    sources "reformer,vision_transformer"
    confidence 0.75
  ]
  edge [
    source 168
    target 160
    relations "compares_to"
    mentions 1
    sources "deit"
    confidence 0.9
  ]
  edge [
    source 168
    target 165
    relations "outperforms"
    mentions 1
    sources "reformer"
    confidence 0.9
  ]
  edge [
    source 174
    target 528
    relations "outperform"
    mentions 1
    sources "deit"
    confidence 0.6
  ]
  edge [
    source 178
    target 505
    relations "is_used_in"
    mentions 1
    sources "swin_transformer"
    confidence 1.0
  ]
  edge [
    source 179
    target 103
    relations "is_compared_with"
    mentions 1
    sources "reformer"
    confidence 0.8
  ]
  edge [
    source 181
    target 252
    relations "improves"
    mentions 1
    sources "vision_transformer"
    confidence 0.85
  ]
  edge [
    source 197
    target 201
    relations "contains"
    mentions 1
    sources "gpt3_language_models"
    confidence 0.9
  ]
  edge [
    source 197
    target 198
    relations "contains"
    mentions 1
    sources "gpt3"
    confidence 1.0
  ]
  edge [
    source 198
    target 212
    relations "is_a"
    mentions 2
    sources "gpt3_language_models,gpt3_language_models"
    confidence 0.9
  ]
  edge [
    source 199
    target 200
    relations "followed_by"
    mentions 1
    sources "gpt3_language_models"
    confidence 0.9
  ]
  edge [
    source 199
    target 103
    relations "is_applied_to"
    mentions 1
    sources "reformer"
    confidence 0.85
  ]
  edge [
    source 200
    target 103
    relations "is_applied_to"
    mentions 1
    sources "reformer"
    confidence 0.85
  ]
  edge [
    source 206
    target 66
    relations "used_for_training"
    mentions 1
    sources "gpt3_language_models"
    confidence 0.95
  ]
  edge [
    source 210
    target 66
    relations "discussed_in"
    mentions 1
    sources "gpt3_language_models"
    confidence 0.9
  ]
  edge [
    source 211
    target 212
    relations "is_a"
    mentions 2
    sources "gpt3_language_models,gpt3"
    confidence 0.95
  ]
  edge [
    source 217
    target 211
    relations "discusses"
    mentions 1
    sources "gpt3_language_models"
    confidence 0.8
  ]
  edge [
    source 234
    target 206
    relations "augments"
    mentions 2
    sources "gpt3_language_models,gpt3_language_models"
    confidence 0.85
  ]
  edge [
    source 235
    target 206
    relations "augments"
    mentions 1
    sources "gpt3_language_models"
    confidence 0.85
  ]
  edge [
    source 236
    target 405
    relations "extends"
    mentions 1
    sources "gpt3_language_models"
    confidence 0.8
  ]
  edge [
    source 237
    target 66
    relations "is_measured_for"
    mentions 1
    sources "gpt3"
    confidence 0.9
  ]
  edge [
    source 246
    target 198
    relations "is_used_in"
    mentions 1
    sources "gpt3"
    confidence 0.8
  ]
  edge [
    source 253
    target 66
    relations "outperforms,compares_with"
    mentions 2
    sources "llama,llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 254
    relations "is_competitive_with,compares_with"
    mentions 2
    sources "llama,llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 255
    relations "is_competitive_with,compares_with"
    mentions 2
    sources "llama,llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 231
    relations "trained_on"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 258
    relations "trained_on"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 259
    relations "trained_on"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 235
    relations "trained_on"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 260
    relations "trained_on"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 261
    relations "trained_on"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 262
    relations "trained_on"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 263
    relations "uses"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 264
    relations "evaluated_by"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 277
    relations "compares_with"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 279
    relations "compares_with"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 280
    relations "compares_with"
    mentions 1
    sources "llama"
    confidence 0.8
  ]
  edge [
    source 253
    target 295
    relations "compares_with"
    mentions 1
    sources "llama"
    confidence 0.8
  ]
  edge [
    source 253
    target 213
    relations "evaluates_on"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 215
    relations "evaluates_on"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 283
    relations "evaluates_on"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 284
    relations "evaluates_on"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 229
    relations "evaluates_on"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 285
    relations "evaluates_on"
    mentions 1
    sources "llama"
    confidence 0.8
  ]
  edge [
    source 253
    target 286
    relations "evaluates_on"
    mentions 1
    sources "llama"
    confidence 0.8
  ]
  edge [
    source 253
    target 290
    relations "achieves_performance"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 253
    target 293
    relations "achieves_performance"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 254
    target 253
    relations "is_compared_with"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 255
    target 253
    relations "is_compared_with"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 255
    target 0
    relations "is_based_on,based_on"
    mentions 2
    sources "palm,palm"
    confidence 0.95
  ]
  edge [
    source 255
    target 392
    relations "uses,is based_on"
    mentions 2
    sources "palm,palm"
    confidence 0.9
  ]
  edge [
    source 255
    target 393
    relations "trained_on"
    mentions 1
    sources "palm"
    confidence 0.9
  ]
  edge [
    source 255
    target 66
    relations "outperforms"
    mentions 1
    sources "palm"
    confidence 0.8
  ]
  edge [
    source 255
    target 394
    relations "evaluated_on"
    mentions 1
    sources "palm"
    confidence 0.9
  ]
  edge [
    source 255
    target 273
    relations "uses"
    mentions 1
    sources "palm"
    confidence 0.9
  ]
  edge [
    source 255
    target 413
    relations "uses"
    mentions 1
    sources "palm"
    confidence 0.9
  ]
  edge [
    source 255
    target 414
    relations "uses"
    mentions 1
    sources "palm"
    confidence 0.85
  ]
  edge [
    source 255
    target 307
    relations "evaluates"
    mentions 1
    sources "palm"
    confidence 0.8
  ]
  edge [
    source 255
    target 419
    relations "has_model_scale"
    mentions 1
    sources "palm"
    confidence 1.0
  ]
  edge [
    source 255
    target 420
    relations "has_model_scale"
    mentions 1
    sources "palm"
    confidence 1.0
  ]
  edge [
    source 255
    target 421
    relations "has_model_scale"
    mentions 1
    sources "palm"
    confidence 1.0
  ]
  edge [
    source 255
    target 426
    relations "trained_on"
    mentions 1
    sources "palm"
    confidence 1.0
  ]
  edge [
    source 255
    target 424
    relations "trained_using"
    mentions 1
    sources "palm"
    confidence 1.0
  ]
  edge [
    source 255
    target 425
    relations "trained_using"
    mentions 1
    sources "palm"
    confidence 1.0
  ]
  edge [
    source 263
    target 150
    relations "is_based_on"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 277
    target 253
    relations "is_compared_with"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 277
    target 66
    relations "outperforms"
    mentions 1
    sources "llama"
    confidence 0.85
  ]
  edge [
    source 296
    target 254
    relations "outperforms"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 296
    target 255
    relations "outperforms"
    mentions 1
    sources "llama"
    confidence 0.9
  ]
  edge [
    source 296
    target 301
    relations "evaluated_on"
    mentions 1
    sources "llama"
    confidence 0.7
  ]
  edge [
    source 306
    target 257
    relations "cites"
    mentions 1
    sources "llama"
    confidence 0.8
  ]
  edge [
    source 313
    target 322
    relations "is reduced by"
    mentions 1
    sources "transformer_xl"
    confidence 0.9
  ]
  edge [
    source 315
    target 178
    relations "improves"
    mentions 1
    sources "longformer"
    confidence 0.9
  ]
  edge [
    source 315
    target 321
    relations "outperforms,improves,is_based_on"
    mentions 3
    sources "longformer,longformer,longformer"
    confidence 0.95
  ]
  edge [
    source 315
    target 317
    relations "evaluated_on"
    mentions 1
    sources "longformer"
    confidence 0.9
  ]
  edge [
    source 315
    target 318
    relations "evaluated_on"
    mentions 1
    sources "longformer"
    confidence 0.9
  ]
  edge [
    source 315
    target 319
    relations "evaluated_on"
    mentions 1
    sources "longformer"
    confidence 0.85
  ]
  edge [
    source 315
    target 215
    relations "evaluated_on"
    mentions 1
    sources "longformer"
    confidence 0.85
  ]
  edge [
    source 315
    target 331
    relations "used_in"
    mentions 1
    sources "longformer"
    confidence 0.8
  ]
  edge [
    source 315
    target 405
    relations "based_on"
    mentions 1
    sources "longformer"
    confidence 0.9
  ]
  edge [
    source 315
    target 236
    relations "compared_to"
    mentions 1
    sources "longformer"
    confidence 0.8
  ]
  edge [
    source 315
    target 0
    relations "is_based_on"
    mentions 1
    sources "longformer"
    confidence 0.95
  ]
  edge [
    source 315
    target 364
    relations "uses"
    mentions 1
    sources "longformer"
    confidence 0.85
  ]
  edge [
    source 315
    target 143
    relations "uses"
    mentions 1
    sources "longformer"
    confidence 0.85
  ]
  edge [
    source 315
    target 363
    relations "is_pretrained_with"
    mentions 1
    sources "longformer"
    confidence 0.9
  ]
  edge [
    source 315
    target 349
    relations "compared_with"
    mentions 1
    sources "longformer"
    confidence 0.85
  ]
  edge [
    source 318
    target 317
    relations "is compared with"
    mentions 1
    sources "transformer_xl"
    confidence 0.7
  ]
  edge [
    source 322
    target 315
    relations "compared_to"
    mentions 1
    sources "longformer"
    confidence 0.75
  ]
  edge [
    source 322
    target 572
    relations "improves"
    mentions 1
    sources "transformer_xl"
    confidence 0.9
  ]
  edge [
    source 322
    target 556
    relations "resolves"
    mentions 1
    sources "transformer_xl"
    confidence 0.85
  ]
  edge [
    source 322
    target 34
    relations "uses"
    mentions 1
    sources "transformer_xl"
    confidence 0.95
  ]
  edge [
    source 322
    target 313
    relations "improves"
    mentions 1
    sources "transformer_xl"
    confidence 0.9
  ]
  edge [
    source 322
    target 594
    relations "compared_with"
    mentions 1
    sources "transformer_xl"
    confidence 0.85
  ]
  edge [
    source 322
    target 555
    relations "evaluated_on"
    mentions 1
    sources "transformer_xl"
    confidence 0.8
  ]
  edge [
    source 322
    target 554
    relations "evaluated_on"
    mentions 1
    sources "transformer_xl"
    confidence 0.8
  ]
  edge [
    source 326
    target 328
    relations "is_designed_for"
    mentions 1
    sources "longformer"
    confidence 0.8
  ]
  edge [
    source 331
    target 315
    relations "is_a_variant_of"
    mentions 1
    sources "longformer"
    confidence 0.95
  ]
  edge [
    source 333
    target 199
    relations "is_used_for"
    mentions 1
    sources "longformer"
    confidence 0.85
  ]
  edge [
    source 334
    target 335
    relations "is_an_extension_of"
    mentions 1
    sources "longformer"
    confidence 0.9
  ]
  edge [
    source 348
    target 332
    relations "discusses"
    mentions 1
    sources "longformer"
    confidence 0.9
  ]
  edge [
    source 349
    target 384
    relations "is_related_to"
    mentions 1
    sources "palm"
    confidence 0.7
  ]
  edge [
    source 353
    target 315
    relations "compared_to"
    mentions 1
    sources "longformer"
    confidence 0.7
  ]
  edge [
    source 354
    target 315
    relations "compared_to"
    mentions 1
    sources "longformer"
    confidence 0.7
  ]
  edge [
    source 369
    target 367
    relations "developed"
    mentions 1
    sources "longformer"
    confidence 0.9
  ]
  edge [
    source 370
    target 349
    relations "developed"
    mentions 1
    sources "longformer"
    confidence 0.9
  ]
  edge [
    source 371
    target 321
    relations "developed"
    mentions 1
    sources "longformer"
    confidence 0.9
  ]
  edge [
    source 372
    target 354
    relations "discussed"
    mentions 1
    sources "longformer"
    confidence 0.8
  ]
  edge [
    source 375
    target 374
    relations "improves"
    mentions 1
    sources "longformer"
    confidence 0.9
  ]
  edge [
    source 375
    target 319
    relations "evaluated_on"
    mentions 1
    sources "longformer"
    confidence 0.95
  ]
  edge [
    source 375
    target 215
    relations "evaluated_on"
    mentions 1
    sources "longformer"
    confidence 0.95
  ]
  edge [
    source 375
    target 366
    relations "evaluated_on"
    mentions 1
    sources "longformer"
    confidence 0.95
  ]
  edge [
    source 375
    target 330
    relations "used_for"
    mentions 1
    sources "longformer"
    confidence 0.85
  ]
  edge [
    source 377
    target 330
    relations "used_for"
    mentions 1
    sources "longformer"
    confidence 0.9
  ]
  edge [
    source 405
    target 66
    relations "is used in"
    mentions 1
    sources "palm"
    confidence 0.95
  ]
  edge [
    source 426
    target 428
    relations "composed_of"
    mentions 1
    sources "palm"
    confidence 1.0
  ]
  edge [
    source 426
    target 235
    relations "composed_of"
    mentions 1
    sources "palm"
    confidence 1.0
  ]
  edge [
    source 443
    target 444
    relations "uses"
    mentions 1
    sources "palm"
    confidence 0.9
  ]
  edge [
    source 443
    target 445
    relations "executes"
    mentions 1
    sources "palm"
    confidence 0.9
  ]
  edge [
    source 460
    target 66
    relations "is_based_on,compared_to,is evaluated by"
    mentions 3
    sources "segment_anything,segment_anything,segment_anything"
    confidence 1.0
  ]
  edge [
    source 460
    target 65
    relations "connects,uses"
    mentions 2
    sources "segment_anything,segment_anything"
    confidence 0.9
  ]
  edge [
    source 460
    target 461
    relations "connects,is based on"
    mentions 2
    sources "segment_anything,segment_anything"
    confidence 0.8
  ]
  edge [
    source 460
    target 462
    relations "is_evaluated_on,is_fine_tuned_on"
    mentions 2
    sources "segment_anything,segment_anything"
    confidence 0.9
  ]
  edge [
    source 460
    target 491
    relations "is trained on"
    mentions 1
    sources "segment_anything"
    confidence 0.9
  ]
  edge [
    source 460
    target 467
    relations "compares to"
    mentions 1
    sources "segment_anything"
    confidence 0.6
  ]
  edge [
    source 460
    target 468
    relations "compares to,compared_to,compares_with"
    mentions 3
    sources "segment_anything,segment_anything,segment_anything"
    confidence 1.0
  ]
  edge [
    source 460
    target 472
    relations "compared_to,compares_with"
    mentions 2
    sources "segment_anything,segment_anything"
    confidence 1.0
  ]
  edge [
    source 460
    target 463
    relations "evaluated_on"
    mentions 1
    sources "segment_anything"
    confidence 0.95
  ]
  edge [
    source 460
    target 499
    relations "improves"
    mentions 1
    sources "segment_anything"
    confidence 0.9
  ]
  edge [
    source 463
    target 502
    relations "uses"
    mentions 1
    sources "segment_anything"
    confidence 0.9
  ]
  edge [
    source 468
    target 479
    relations "is_a"
    mentions 1
    sources "segment_anything"
    confidence 0.9
  ]
  edge [
    source 469
    target 479
    relations "is_a"
    mentions 1
    sources "segment_anything"
    confidence 0.9
  ]
  edge [
    source 470
    target 479
    relations "is_a"
    mentions 1
    sources "segment_anything"
    confidence 0.9
  ]
  edge [
    source 471
    target 479
    relations "is_a"
    mentions 1
    sources "segment_anything"
    confidence 0.9
  ]
  edge [
    source 472
    target 253
    relations "is_based_on"
    mentions 1
    sources "segment_anything"
    confidence 0.8
  ]
  edge [
    source 480
    target 253
    relations "is_based_on"
    mentions 1
    sources "segment_anything"
    confidence 0.8
  ]
  edge [
    source 487
    target 488
    relations "is converted to"
    mentions 1
    sources "segment_anything"
    confidence 0.8
  ]
  edge [
    source 489
    target 487
    relations "connects"
    mentions 1
    sources "segment_anything"
    confidence 0.85
  ]
  edge [
    source 491
    target 492
    relations "contains"
    mentions 1
    sources "segment_anything"
    confidence 0.8
  ]
  edge [
    source 491
    target 493
    relations "contains"
    mentions 1
    sources "segment_anything"
    confidence 0.8
  ]
  edge [
    source 501
    target 499
    relations "measures"
    mentions 1
    sources "segment_anything"
    confidence 1.0
  ]
  edge [
    source 505
    target 518
    relations "outperforms"
    mentions 1
    sources "swin_transformer"
    confidence 0.9
  ]
  edge [
    source 505
    target 520
    relations "outperforms"
    mentions 1
    sources "swin_transformer"
    confidence 0.9
  ]
  edge [
    source 505
    target 521
    relations "outperforms"
    mentions 1
    sources "swin_transformer"
    confidence 0.9
  ]
  edge [
    source 505
    target 69
    relations "is similar to"
    mentions 1
    sources "swin_transformer"
    confidence 0.75
  ]
  edge [
    source 505
    target 102
    relations "is similar to"
    mentions 1
    sources "swin_transformer"
    confidence 0.75
  ]
  edge [
    source 505
    target 139
    relations "evaluated_on"
    mentions 1
    sources "swin_transformer"
    confidence 0.9
  ]
  edge [
    source 505
    target 531
    relations "compared_with"
    mentions 1
    sources "swin_transformer"
    confidence 0.9
  ]
  edge [
    source 505
    target 95
    relations "compared_with"
    mentions 1
    sources "swin_transformer"
    confidence 0.8
  ]
  edge [
    source 505
    target 536
    relations "compared_with"
    mentions 1
    sources "swin_transformer"
    confidence 0.8
  ]
  edge [
    source 505
    target 275
    relations "uses"
    mentions 1
    sources "swin_transformer"
    confidence 0.9
  ]
  edge [
    source 505
    target 537
    relations "contains"
    mentions 1
    sources "swin_transformer"
    confidence 0.85
  ]
  edge [
    source 505
    target 538
    relations "achieves"
    mentions 1
    sources "swin_transformer"
    confidence 0.9
  ]
  edge [
    source 505
    target 422
    relations "has"
    mentions 1
    sources "swin_transformer"
    confidence 0.9
  ]
  edge [
    source 505
    target 546
    relations "uses"
    mentions 1
    sources "swin_transformer"
    confidence 0.9
  ]
  edge [
    source 506
    target 507
    relations "affiliated_with"
    mentions 1
    sources "swin_transformer"
    confidence 1.0
  ]
  edge [
    source 506
    target 508
    relations "affiliated_with"
    mentions 1
    sources "swin_transformer"
    confidence 1.0
  ]
  edge [
    source 506
    target 509
    relations "affiliated_with"
    mentions 1
    sources "swin_transformer"
    confidence 1.0
  ]
  edge [
    source 506
    target 510
    relations "affiliated_with"
    mentions 1
    sources "swin_transformer"
    confidence 1.0
  ]
  edge [
    source 506
    target 511
    relations "affiliated_with"
    mentions 1
    sources "swin_transformer"
    confidence 1.0
  ]
  edge [
    source 506
    target 512
    relations "affiliated_with"
    mentions 1
    sources "swin_transformer"
    confidence 1.0
  ]
  edge [
    source 506
    target 513
    relations "affiliated_with"
    mentions 1
    sources "swin_transformer"
    confidence 1.0
  ]
  edge [
    source 506
    target 514
    relations "affiliated_with"
    mentions 1
    sources "swin_transformer"
    confidence 1.0
  ]
  edge [
    source 516
    target 505
    relations "is_used_in"
    mentions 1
    sources "swin_transformer"
    confidence 0.8
  ]
  edge [
    source 517
    target 505
    relations "is_used_in"
    mentions 1
    sources "swin_transformer"
    confidence 0.8
  ]
  edge [
    source 528
    target 405
    relations "is based on"
    mentions 1
    sources "deit"
    confidence 0.95
  ]
  edge [
    source 528
    target 81
    relations "pre_trained_on,requires"
    mentions 3
    sources "reformer,swin_transformer,vision_transformer"
    confidence 0.9
  ]
  edge [
    source 528
    target 169
    relations "optimized_with"
    mentions 2
    sources "reformer,vision_transformer"
    confidence 0.7
  ]
  edge [
    source 528
    target 170
    relations "optimized_with"
    mentions 2
    sources "reformer,vision_transformer"
    confidence 0.7
  ]
  edge [
    source 528
    target 171
    relations "optimized_with"
    mentions 2
    sources "reformer,vision_transformer"
    confidence 0.7
  ]
  edge [
    source 535
    target 535
    relations "is followed by"
    mentions 3
    sources "swin_transformer,swin_transformer,swin_transformer"
    confidence 0.95
  ]
  edge [
    source 541
    target 139
    relations "fine-tuned_on"
    mentions 1
    sources "swin_transformer"
    confidence 0.9
  ]
  edge [
    source 541
    target 528
    relations "compared_with"
    mentions 1
    sources "swin_transformer"
    confidence 0.8
  ]
  edge [
    source 541
    target 549
    relations "compared_with"
    mentions 1
    sources "swin_transformer"
    confidence 0.8
  ]
  edge [
    source 542
    target 541
    relations "used_with"
    mentions 1
    sources "swin_transformer"
    confidence 0.85
  ]
  edge [
    source 551
    target 322
    relations "is compared to"
    mentions 1
    sources "transformer_xl"
    confidence 0.8
  ]
  edge [
    source 552
    target 322
    relations "is compared to,compared_to"
    mentions 2
    sources "transformer_xl,transformer_xl"
    confidence 0.8
  ]
  edge [
    source 568
    target 322
    relations "is used in"
    mentions 1
    sources "transformer_xl"
    confidence 0.85
  ]
  edge [
    source 570
    target 322
    relations "are_cached_in"
    mentions 1
    sources "transformer_xl"
    confidence 0.9
  ]
  edge [
    source 572
    target 322
    relations "is modeled by"
    mentions 1
    sources "transformer_xl"
    confidence 0.8
  ]
  edge [
    source 573
    target 552
    relations "is_based_on"
    mentions 1
    sources "transformer_xl"
    confidence 0.85
  ]
  edge [
    source 578
    target 579
    relations "attends_on"
    mentions 1
    sources "transformer_xl"
    confidence 0.85
  ]
  edge [
    source 582
    target 322
    relations "compares_with"
    mentions 1
    sources "transformer_xl"
    confidence 0.7
  ]
  edge [
    source 583
    target 34
    relations "uses"
    mentions 1
    sources "transformer_xl"
    confidence 0.75
  ]
  edge [
    source 587
    target 587
    relations "is replaced by"
    mentions 1
    sources "transformer_xl"
    confidence 0.8
  ]
  edge [
    source 588
    target 578
    relations "replaces"
    mentions 1
    sources "transformer_xl"
    confidence 0.85
  ]
  edge [
    source 589
    target 578
    relations "substitutes"
    mentions 1
    sources "transformer_xl"
    confidence 0.85
  ]
  edge [
    source 596
    target 597
    relations "proposed"
    mentions 1
    sources "transformer_xl"
    confidence 0.9
  ]
  edge [
    source 601
    target 94
    relations "is_explored_for"
    mentions 1
    sources "vision_transformer"
    confidence 0.8
  ]
  edge [
    source 606
    target 528
    relations "outperform"
    mentions 2
    sources "reformer,vision_transformer"
    confidence 0.6
  ]
  edge [
    source 607
    target 458
    relations "represent"
    mentions 1
    sources "vision_transformer"
    confidence 0.8
  ]
]
