{
  "nodes": [
    {
      "id": "Transformer",
      "type": "architecture",
      "documents": [
        "attention_is_all_you_need",
        "deit",
        "gpt3_language_models",
        "gpt3",
        "palm",
        "reformer"
      ],
      "mentions": 6,
      "aliases": [
        "transformer",
        "Transformer"
      ],
      "description": "A new network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Attention Mechanism",
      "type": "method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Attention Mechanism"
      ],
      "description": "A mechanism that allows modeling of dependencies without regard to their distance in input or output sequences.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BLEU",
      "type": "metric",
      "documents": [
        "attention_is_all_you_need",
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 3,
      "aliases": [
        "BLEU"
      ],
      "description": "A metric for evaluating the quality of machine translation by comparing a machine's output with a reference output.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "WMT 2014 English-to-German",
      "type": "dataset",
      "documents": [
        "attention_is_all_you_need",
        "attention_is_all_you_need"
      ],
      "mentions": 2,
      "aliases": [
        "WMT 2014 English-to-German",
        "WMT 2014 English-German dataset"
      ],
      "description": "A dataset used for evaluating machine translation performance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "WMT 2014 English-to-French",
      "type": "dataset",
      "documents": [
        "attention_is_all_you_need",
        "attention_is_all_you_need"
      ],
      "mentions": 2,
      "aliases": [
        "WMT 2014 English-to-French",
        "WMT 2014 English-French dataset"
      ],
      "description": "A dataset used for evaluating machine translation performance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Google Brain",
      "type": "organization",
      "documents": [
        "attention_is_all_you_need",
        "transformer_xl"
      ],
      "mentions": 2,
      "aliases": [
        "Google Brain"
      ],
      "description": "A deep learning research team at Google.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Google Research",
      "type": "organization",
      "documents": [
        "attention_is_all_you_need",
        "deit",
        "palm",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 5,
      "aliases": [
        "Google Research"
      ],
      "description": "A research division of Google focusing on various scientific and technological advancements.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Ashish Vaswani",
      "type": "person",
      "documents": [
        "attention_is_all_you_need",
        "deit",
        "reformer"
      ],
      "mentions": 3,
      "aliases": [
        "Ashish Vaswani"
      ],
      "description": "One of the authors who designed and implemented the first Transformer models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Noam Shazeer",
      "type": "person",
      "documents": [
        "attention_is_all_you_need",
        "deit",
        "reformer"
      ],
      "mentions": 3,
      "aliases": [
        "Noam Shazeer"
      ],
      "description": "One of the authors who proposed scaled dot-product attention and multi-head attention.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Niki Parmar",
      "type": "person",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Niki Parmar"
      ],
      "description": "One of the authors involved in the design and implementation of the Transformer.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Jakob Uszkoreit",
      "type": "person",
      "documents": [
        "attention_is_all_you_need",
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 4,
      "aliases": [
        "Jakob Uszkoreit"
      ],
      "description": "One of the authors who proposed replacing RNNs with self-attention.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Llion Jones",
      "type": "person",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Llion Jones"
      ],
      "description": "One of the authors responsible for the initial codebase and efficient inference.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Aidan N. Gomez",
      "type": "person",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Aidan N. Gomez"
      ],
      "description": "One of the authors involved in designing various parts of the Tensor2Tensor framework.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Łukasz Kaiser",
      "type": "person",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Łukasz Kaiser"
      ],
      "description": "One of the authors who contributed to the design and implementation of Tensor2Tensor.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Illia Polosukhin",
      "type": "person",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Illia Polosukhin"
      ],
      "description": "One of the authors who contributed to the design and implementation of the Transformer.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Encoder",
      "type": "Architecture",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Encoder"
      ],
      "description": "A component of the model composed of a stack of identical layers with multi-head self-attention and feed-forward networks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Decoder",
      "type": "Architecture",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Decoder"
      ],
      "description": "A component of the model that generates output sequences, incorporating attention mechanisms over encoder outputs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Multi-Head Attention",
      "type": "Method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Multi-Head Attention"
      ],
      "description": "An attention mechanism that allows the model to jointly attend to information from different representation subspaces.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Scaled Dot-Product Attention",
      "type": "Method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Scaled Dot-Product Attention"
      ],
      "description": "An attention function that computes a weighted sum of values based on the compatibility of queries and keys.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Residual Connection",
      "type": "Method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Residual Connection"
      ],
      "description": "A technique used to facilitate training by allowing gradients to flow through the network more easily.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Layer Normalization",
      "type": "Method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Layer Normalization"
      ],
      "description": "A normalization technique applied to the outputs of sub-layers to stabilize and accelerate training.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Feed-Forward Network",
      "type": "Method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Feed-Forward Network"
      ],
      "description": "A fully connected network applied to each position separately in the encoder and decoder.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Embedding Layer",
      "type": "Architecture",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Embedding Layer"
      ],
      "description": "A layer that converts input tokens and output tokens into vector representations.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Softmax Function",
      "type": "Method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Softmax Function"
      ],
      "description": "A function used to convert decoder outputs into predicted next-token probabilities.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Attention Function",
      "type": "Method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Attention Function"
      ],
      "description": "A function that maps queries and key-value pairs to an output.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ReLU Activation",
      "type": "Method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "ReLU Activation"
      ],
      "description": "An activation function used in feed-forward networks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Attention(Q, K, V)",
      "type": "Function",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Attention(Q, K, V)"
      ],
      "description": "The mathematical representation of the attention mechanism.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "d_model",
      "type": "Metric",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "d_model"
      ],
      "description": "The dimensionality of the model's representations.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "n",
      "type": "Metric",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "n"
      ],
      "description": "The sequence length.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "k",
      "type": "Metric",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "k"
      ],
      "description": "The kernel size of convolutions.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "r",
      "type": "Metric",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "r"
      ],
      "description": "The size of the neighborhood in restricted self-attention.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Self-Attention",
      "type": "method",
      "documents": [
        "attention_is_all_you_need",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "Self-Attention",
        "Self-attention"
      ],
      "description": "A mechanism that allows the model to weigh the importance of different tokens in a sequence.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Recurrent Neural Network (RNN)",
      "type": "architecture",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Recurrent Neural Network (RNN)"
      ],
      "description": "A type of neural network designed for sequential data processing.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Convolutional Neural Network (CNN)",
      "type": "architecture",
      "documents": [
        "attention_is_all_you_need",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "CNN (Convolutional Neural Network)",
        "Convolutional Neural Network (CNN)"
      ],
      "description": "A type of neural network primarily used for processing grid-like data such as images.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Positional Encoding",
      "type": "method",
      "documents": [
        "attention_is_all_you_need",
        "transformer_xl",
        "transformer_xl"
      ],
      "mentions": 3,
      "aliases": [
        "Positional Encoding",
        "relative positional encoding",
        "positional encoding"
      ],
      "description": "A technique used to inject information about the position of tokens in a sequence.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Adam Optimizer",
      "type": "method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Adam Optimizer"
      ],
      "description": "An optimization algorithm used for training machine learning models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BLEU Score",
      "type": "metric",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "BLEU Score"
      ],
      "description": "A metric for evaluating the quality of text which has been machine-translated.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Byte-Pair Encoding",
      "type": "method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Byte-Pair Encoding"
      ],
      "description": "A data compression technique used for encoding text.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Word-Piece Vocabulary",
      "type": "method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Word-Piece Vocabulary"
      ],
      "description": "A subword tokenization method used in natural language processing.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Residual Dropout",
      "type": "method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Residual Dropout"
      ],
      "description": "A regularization technique applied to neural networks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Label Smoothing",
      "type": "method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Label Smoothing"
      ],
      "description": "A technique used during training to prevent overfitting by softening the target labels.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Separable Convolutions",
      "type": "method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Separable Convolutions"
      ],
      "description": "A type of convolution that reduces the computational complexity of standard convolutions.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "NVIDIA P100 GPU",
      "type": "hardware",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "NVIDIA P100 GPU"
      ],
      "description": "A type of graphics processing unit used for training deep learning models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ConvS2SEnsemble",
      "type": "model",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "ConvS2SEnsemble"
      ],
      "description": "An ensemble model used for machine translation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "WMT2014",
      "type": "dataset",
      "documents": [
        "attention_is_all_you_need",
        "attention_is_all_you_need"
      ],
      "mentions": 2,
      "aliases": [
        "WMT2014",
        "WMT 2014"
      ],
      "description": "A benchmark dataset for machine translation tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "P100 GPUs",
      "type": "hardware",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "P100 GPUs"
      ],
      "description": "A type of GPU used for training the models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Penn Treebank",
      "type": "dataset",
      "documents": [
        "attention_is_all_you_need",
        "transformer_xl"
      ],
      "mentions": 2,
      "aliases": [
        "Penn Treebank"
      ],
      "description": "A dataset used for English constituency parsing.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Wall Street Journal",
      "type": "dataset",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Wall Street Journal"
      ],
      "description": "A portion of the Penn Treebank used for training.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Beam Search",
      "type": "method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Beam Search"
      ],
      "description": "A search algorithm used during inference to generate translations.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Attention Heads",
      "type": "architecture component",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Attention Heads"
      ],
      "description": "Components of the Transformer that allow it to focus on different parts of the input.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Semi-supervised Setting",
      "type": "training method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Semi-supervised Setting"
      ],
      "description": "A training approach that uses both labeled and unlabeled data.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Vinyals & Kaiser (2014)",
      "type": "publication",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Vinyals & Kaiser (2014)"
      ],
      "description": "A reference for previous work in English constituency parsing.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Dyer et al. (2016)",
      "type": "publication",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Dyer et al. (2016)"
      ],
      "description": "A reference for previous work in English constituency parsing.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Zhu et al. (2013)",
      "type": "publication",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Zhu et al. (2013)"
      ],
      "description": "A reference for previous work in English constituency parsing.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Huang & Harper (2009)",
      "type": "publication",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Huang & Harper (2009)"
      ],
      "description": "A reference for previous work in English constituency parsing.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "McClosky et al. (2006)",
      "type": "publication",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "McClosky et al. (2006)"
      ],
      "description": "A reference for previous work in English constituency parsing.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Luong et al. (2015)",
      "type": "publication",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Luong et al. (2015)"
      ],
      "description": "A reference for previous work in English constituency parsing.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "attention-based models",
      "type": "method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "attention-based models"
      ],
      "description": "Models that use attention mechanisms to improve performance in tasks like translation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "images",
      "type": "data type",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "images"
      ],
      "description": "Visual data type that the authors plan to apply their models to.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "audio",
      "type": "data type",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "audio"
      ],
      "description": "Sound data type that the authors plan to apply their models to.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "video",
      "type": "data type",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "video"
      ],
      "description": "Moving visual data type that the authors plan to apply their models to.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "local, restricted attention mechanisms",
      "type": "method",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "local, restricted attention mechanisms"
      ],
      "description": "Attention mechanisms designed to efficiently handle large inputs and outputs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "code repository",
      "type": "resource",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "code repository"
      ],
      "description": "GitHub repository for the code used to train and evaluate models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Nal Kalchbrenner",
      "type": "person",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Nal Kalchbrenner"
      ],
      "description": "Researcher acknowledged for comments and inspiration.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Stephan Gouws",
      "type": "person",
      "documents": [
        "attention_is_all_you_need"
      ],
      "mentions": 1,
      "aliases": [
        "Stephan Gouws"
      ],
      "description": "Researcher acknowledged for comments and inspiration.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "CLIP",
      "type": "model",
      "documents": [
        "clip",
        "segment_anything"
      ],
      "mentions": 2,
      "aliases": [
        "CLIP"
      ],
      "description": "A model that jointly trains an image encoder and a text encoder to predict correct pairings of image and text.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "GPT-3",
      "type": "model",
      "documents": [
        "clip",
        "gpt3_language_models",
        "gpt3",
        "llama",
        "palm",
        "segment_anything"
      ],
      "mentions": 6,
      "aliases": [
        "GPT-3",
        "GPT-4"
      ],
      "description": "A state-of-the-art language model that is competitive across many tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ImageNet",
      "type": "dataset",
      "documents": [
        "clip",
        "deit",
        "reformer",
        "vision_transformer",
        "vision_transformer"
      ],
      "mentions": 5,
      "aliases": [
        "ImageNet",
        "ImageNet ReaL"
      ],
      "description": "A large dataset used for image classification tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "YFCC100M",
      "type": "dataset",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "YFCC100M"
      ],
      "description": "A dataset containing images and associated metadata used for training models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ResNet-50",
      "type": "model",
      "documents": [
        "clip",
        "swin_transformer"
      ],
      "mentions": 2,
      "aliases": [
        "ResNet-50"
      ],
      "description": "A convolutional neural network architecture used for image classification.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "VirTex",
      "type": "model",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "VirTex"
      ],
      "description": "A model that uses natural language supervision for image representation learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ICMLM",
      "type": "model",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "ICMLM"
      ],
      "description": "A model that employs masked language modeling for learning image representations.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ConVIRT",
      "type": "model",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "ConVIRT"
      ],
      "description": "A model that uses contrastive objectives to learn image representations from text.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Dai & Le",
      "type": "people",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Dai & Le"
      ],
      "description": "Researchers who contributed to advancements in pre-training methods in NLP.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Peters et al.",
      "type": "people",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Peters et al."
      ],
      "description": "Researchers who contributed to advancements in pre-training methods in NLP.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "OpenAI",
      "type": "organization",
      "documents": [
        "clip",
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 3,
      "aliases": [
        "OpenAI"
      ],
      "description": "The organization behind the development of CLIP and other AI models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "400 million (image, text) pairs",
      "type": "dataset",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "400 million (image, text) pairs"
      ],
      "description": "A dataset used for training the model, consisting of image and text pairs collected from the internet.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "OCR",
      "type": "task",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "OCR"
      ],
      "description": "Optical Character Recognition, a task in computer vision.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "geo-localization",
      "type": "task",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "geo-localization"
      ],
      "description": "A task in computer vision that involves determining the geographic location of an image.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "fine-grained object classification",
      "type": "task",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "fine-grained object classification"
      ],
      "description": "A task in computer vision that involves classifying objects into very specific categories.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "zero-shot transfer",
      "type": "method",
      "documents": [
        "clip",
        "gpt3_language_models"
      ],
      "mentions": 2,
      "aliases": [
        "zero-shot transfer"
      ],
      "description": "A method that allows a model to perform tasks without specific training on those tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "JFT-300M",
      "type": "dataset",
      "documents": [
        "clip",
        "deit",
        "reformer",
        "swin_transformer",
        "vision_transformer"
      ],
      "mentions": 5,
      "aliases": [
        "JFT-300M"
      ],
      "description": "A dataset with noisy labels used for training models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MS-COCO",
      "type": "dataset",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "MS-COCO"
      ],
      "description": "A high-quality crowd-labeled dataset for image captioning and object detection.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Visual Genome",
      "type": "dataset",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Visual Genome"
      ],
      "description": "A dataset containing images and their associated descriptions.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "GPT",
      "type": "architecture",
      "documents": [
        "clip",
        "clip"
      ],
      "mentions": 2,
      "aliases": [
        "GPT-1",
        "GPT"
      ],
      "description": "Generative Pre-trained Transformer, a family of language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Li et al. (2017)",
      "type": "person",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Li et al. (2017)"
      ],
      "description": "Researchers who achieved 11.5% accuracy on ImageNet in a zero-shot setting.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Xie et al. (2020)",
      "type": "person",
      "documents": [
        "clip",
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 4,
      "aliases": [
        "Xie et al. (2020)"
      ],
      "description": "Researchers who established the current state of the art with 88.4% accuracy.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Mahajan et al. (2018)",
      "type": "person",
      "documents": [
        "clip",
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 4,
      "aliases": [
        "Mahajan et al. (2018)"
      ],
      "description": "Researchers who demonstrated the effectiveness of predicting hashtags on Instagram images.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Kolesnikov et al. (2019)",
      "type": "person",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Kolesnikov et al. (2019)"
      ],
      "description": "Researchers who showed large gains on transfer benchmarks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Dosovitskiy et al. (2020)",
      "type": "person",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Dosovitskiy et al. (2020)"
      ],
      "description": "Researchers who contributed to the understanding of transfer performance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Hestness et al. (2017)",
      "type": "person",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Hestness et al. (2017)"
      ],
      "description": "Researchers who studied the relationship between compute and transfer performance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Kaplan et al. (2020)",
      "type": "person",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Kaplan et al. (2020)"
      ],
      "description": "Researchers who analyzed the predictability of transfer performance based on compute.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "McCann et al. (2017)",
      "type": "person",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "McCann et al. (2017)"
      ],
      "description": "Researchers who discussed improvements in deep contextual representation learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "WIT",
      "type": "dataset",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "WIT"
      ],
      "description": "WebImageText dataset used for training CLIP, consisting of image-text pairs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Vision Transformer",
      "type": "architecture",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Vision Transformer"
      ],
      "description": "An architecture used for image encoding, based on transformer models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "EfficientNet",
      "type": "architecture",
      "documents": [
        "clip",
        "swin_transformer"
      ],
      "mentions": 2,
      "aliases": [
        "EfficientNet"
      ],
      "description": "A family of convolutional neural networks that optimize accuracy and efficiency.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "WebText",
      "type": "dataset",
      "documents": [
        "clip",
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 3,
      "aliases": [
        "WebText"
      ],
      "description": "A dataset used to train the GPT-2 model.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Zhang et al. (2020)",
      "type": "person",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Zhang et al. (2020)"
      ],
      "description": "Researchers who adapted contrastive representation learning for medical imaging.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Oord et al. (2018)",
      "type": "person",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Oord et al. (2018)"
      ],
      "description": "Researchers who popularized the InfoNCE loss for contrastive representation learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Chen et al. (2020)",
      "type": "person",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Chen et al. (2020)"
      ],
      "description": "Researchers who explored generative models and contrastive models in representation learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Sohn (2016)",
      "type": "person",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Sohn (2016)"
      ],
      "description": "Introduced the multi-class N-pair loss in deep metric learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Tian et al. (2019)",
      "type": "person",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Tian et al. (2019)"
      ],
      "description": "Researchers who found that contrastive objectives can learn better representations.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ResNet-101",
      "type": "architecture",
      "documents": [
        "clip",
        "deit",
        "reformer",
        "swin_transformer",
        "vision_transformer"
      ],
      "mentions": 5,
      "aliases": [
        "ResNet-101",
        "ResNet"
      ],
      "description": "A deeper version of ResNet-50 with 101 layers.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Vision Transformer (ViT)",
      "type": "architecture",
      "documents": [
        "clip",
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 4,
      "aliases": [
        "Vision Transformer (ViT)"
      ],
      "description": "A transformer-based model for image classification.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Adam optimizer",
      "type": "algorithm",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Adam optimizer"
      ],
      "description": "An optimization algorithm that computes adaptive learning rates for each parameter.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "cross_entropy_loss",
      "type": "metric",
      "documents": [
        "clip",
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 3,
      "aliases": [
        "cross_entropy_loss",
        "cross-entropy loss"
      ],
      "description": "A loss function used for classification tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MOTIVATION",
      "type": "section",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "MOTIVATION"
      ],
      "description": "A section discussing the rationale behind zero-shot transfer.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "zero-shot learning",
      "type": "method",
      "documents": [
        "clip",
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 3,
      "aliases": [
        "zero-shot learning",
        "Zero-Shot Learning"
      ],
      "description": "A method that generalizes to unseen object categories without additional training.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "temperature parameter (τ)",
      "type": "parameter",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "temperature parameter (τ)"
      ],
      "description": "A parameter used to scale logits in the softmax function.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "V100 GPU",
      "type": "hardware",
      "documents": [
        "clip",
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 3,
      "aliases": [
        "V100 GPU"
      ],
      "description": "A type of GPU used for high-performance computing.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "mixed-precision training",
      "type": "method",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "mixed-precision training"
      ],
      "description": "A training technique that uses both 16-bit and 32-bit floating-point types.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "gradient checkpointing",
      "type": "method",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "gradient checkpointing"
      ],
      "description": "A technique to save memory during training by storing only a subset of activations.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "CIFAR-10",
      "type": "dataset",
      "documents": [
        "clip",
        "deit",
        "deit",
        "reformer",
        "reformer",
        "vision_transformer",
        "vision_transformer"
      ],
      "mentions": 7,
      "aliases": [
        "CIFAR-10",
        "CIFAR-100"
      ],
      "description": "A dataset commonly used for image classification tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "TinyImages",
      "type": "dataset",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "TinyImages"
      ],
      "description": "A dataset from which CIFAR-10 is derived.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "SVHN",
      "type": "dataset",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "SVHN"
      ],
      "description": "A dataset for street number transcription from Google Street View images.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Visual N-Grams",
      "type": "method",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Visual N-Grams"
      ],
      "description": "A method for zero-shot transfer in image classification.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "hypernetwork",
      "type": "architecture",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "hypernetwork"
      ],
      "description": "A network that generates weights for another network based on input.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Inception-V4",
      "type": "architecture",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Inception-V4"
      ],
      "description": "A deep learning model for image classification.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Jelinek-Mercer smoothing",
      "type": "method",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Jelinek-Mercer smoothing"
      ],
      "description": "A technique used to optimize probabilities in language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Szegedy et al. (2016)",
      "type": "people",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Szegedy et al. (2016)"
      ],
      "description": "Researchers who contributed to the development of Inception-V4.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Liu et al. (2018)",
      "type": "people",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Liu et al. (2018)"
      ],
      "description": "Researchers who identified task learning as a side-effect in language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Lei Ba et al. (2015)",
      "type": "people",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Lei Ba et al. (2015)"
      ],
      "description": "Researchers who introduced a zero-shot image classifier.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Elhoseiny et al. (2013)",
      "type": "people",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Elhoseiny et al. (2013)"
      ],
      "description": "Researchers associated with early work on zero-shot learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Flowers102",
      "type": "dataset",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Flowers102"
      ],
      "description": "An image classification dataset focused on flower species.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "GTSRB",
      "type": "dataset",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "GTSRB"
      ],
      "description": "German Traffic Sign Recognition Benchmark dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "SUN",
      "type": "dataset",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "SUN"
      ],
      "description": "A dataset used for scene recognition.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Yahoo",
      "type": "dataset",
      "documents": [
        "clip"
      ],
      "mentions": 1,
      "aliases": [
        "Yahoo"
      ],
      "description": "A dataset used for image classification.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "VTAB",
      "type": "dataset",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "VTAB"
      ],
      "description": "A suite of 19 tasks for evaluating transfer learning in vision.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Alexey Dosovitskiy",
      "type": "person",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Alexey Dosovitskiy"
      ],
      "description": "One of the authors of the paper and a researcher at Google Research.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Lucas Beyer",
      "type": "person",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Lucas Beyer"
      ],
      "description": "One of the authors of the paper and a researcher at Google Research.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Alexander Kolesnikov",
      "type": "person",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Alexander Kolesnikov"
      ],
      "description": "One of the authors of the paper and a researcher at Google Research.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Dirk Weissenborn",
      "type": "person",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Dirk Weissenborn"
      ],
      "description": "One of the authors of the paper and a researcher at Google Research.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Xiaohua Zhai",
      "type": "person",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Xiaohua Zhai"
      ],
      "description": "One of the authors of the paper and a researcher at Google Research.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Thomas Unterthiner",
      "type": "person",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Thomas Unterthiner"
      ],
      "description": "One of the authors of the paper and a researcher at Google Research.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Mostafa Dehghani",
      "type": "person",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Mostafa Dehghani"
      ],
      "description": "One of the authors of the paper and a researcher at Google Research.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Matthias Minderer",
      "type": "person",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Matthias Minderer"
      ],
      "description": "One of the authors of the paper and a researcher at Google Research.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Georg Heigold",
      "type": "person",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Georg Heigold"
      ],
      "description": "One of the authors of the paper and a researcher at Google Research.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Sylvain Gelly",
      "type": "person",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Sylvain Gelly"
      ],
      "description": "One of the authors of the paper and a researcher at Google Research.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Neil Houlsby",
      "type": "person",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Neil Houlsby"
      ],
      "description": "One of the authors of the paper and a researcher at Google Research.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ImageNet-21k",
      "type": "dataset",
      "documents": [
        "deit",
        "reformer",
        "swin_transformer",
        "swin_transformer",
        "vision_transformer"
      ],
      "mentions": 5,
      "aliases": [
        "ImageNet-21k",
        "ImageNet-1K",
        "ImageNet-22K"
      ],
      "description": "A large dataset used for pre-training the Vision Transformer.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MLP Head",
      "type": "Architecture Component",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "MLP Head"
      ],
      "description": "A multi-layer perceptron used as a classification head in the ViT.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Transformer Encoder",
      "type": "Architecture Component",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Transformer Encoder"
      ],
      "description": "A component of the ViT that processes input sequences using self-attention.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Multi-Head Self-Attention (MSA)",
      "type": "Architecture Component",
      "documents": [
        "deit",
        "vision_transformer"
      ],
      "mentions": 2,
      "aliases": [
        "Multi-Head Self-Attention (MSA)"
      ],
      "description": "A mechanism in transformers that allows the model to focus on different parts of the input.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Position Embeddings",
      "type": "Architecture Component",
      "documents": [
        "deit",
        "longformer",
        "reformer"
      ],
      "mentions": 3,
      "aliases": [
        "Position Embeddings"
      ],
      "description": "Learnable embeddings added to retain positional information in the input sequence.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Self-Supervised Learning",
      "type": "Learning Method",
      "documents": [
        "deit",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "Self-Supervised Learning"
      ],
      "description": "A method of training models using unlabeled data.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ICLR 2021",
      "type": "Conference",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "ICLR 2021"
      ],
      "description": "The conference where the paper was published.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Touvron et al. (2019)",
      "type": "Citation",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Touvron et al. (2019)"
      ],
      "description": "A referenced work discussing fine-tuning and higher resolution.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Sun et al. (2017)",
      "type": "Citation",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Sun et al. (2017)"
      ],
      "description": "A referenced work studying CNN performance scaling.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Kolesnikov et al. (2020)",
      "type": "Citation",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Kolesnikov et al. (2020)"
      ],
      "description": "A referenced work performing empirical exploration of CNN transfer learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Djolonga et al. (2020)",
      "type": "Citation",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Djolonga et al. (2020)"
      ],
      "description": "A referenced work related to CNN transfer learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Vaswani et al. (2017)",
      "type": "Citation",
      "documents": [
        "deit",
        "longformer",
        "reformer",
        "transformer_xl",
        "vision_transformer"
      ],
      "mentions": 5,
      "aliases": [
        "Vaswani et al. (2017)"
      ],
      "description": "The original paper introducing the Transformer architecture.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "GELU",
      "type": "Activation Function",
      "documents": [
        "deit",
        "reformer",
        "swin_transformer",
        "vision_transformer"
      ],
      "mentions": 4,
      "aliases": [
        "GELU"
      ],
      "description": "An activation function used in the MLP layers.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ILSVRC-2012 ImageNet",
      "type": "dataset",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "ILSVRC-2012 ImageNet"
      ],
      "description": "A dataset with 1k classes and 1.3M images used for image classification.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "JFT",
      "type": "dataset",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "JFT"
      ],
      "description": "A dataset with 18k classes and 303M high-resolution images.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Oxford-IIIT Pets",
      "type": "dataset",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Oxford-IIIT Pets"
      ],
      "description": "A dataset containing images of pets for classification.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Oxford Flowers-102",
      "type": "dataset",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Oxford Flowers-102"
      ],
      "description": "A dataset containing images of flowers for classification.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ViT-Base",
      "type": "model",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "ViT-Base"
      ],
      "description": "A Vision Transformer model variant with 12 layers and 86M parameters.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ViT-Large",
      "type": "model",
      "documents": [
        "deit",
        "deit",
        "reformer",
        "reformer",
        "vision_transformer",
        "vision_transformer"
      ],
      "mentions": 6,
      "aliases": [
        "ViT-Huge",
        "ViT-Large"
      ],
      "description": "A Vision Transformer model variant with 24 layers and 307M parameters.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Adam",
      "type": "optimizer",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Adam"
      ],
      "description": "An optimization algorithm used for training models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "SGD",
      "type": "optimizer",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "SGD"
      ],
      "description": "Stochastic Gradient Descent, an optimization algorithm used for fine-tuning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Noisy Student",
      "type": "model",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Noisy Student"
      ],
      "description": "A large EfficientNet trained using semi-supervised learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Big Transfer (BiT)",
      "type": "model",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Big Transfer (BiT)"
      ],
      "description": "A method for supervised transfer learning with large ResNets.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Polyak & Juditsky (1992)",
      "type": "publication",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Polyak & Juditsky (1992)"
      ],
      "description": "A paper discussing averaging techniques used in model training.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ViT-L/16",
      "type": "model",
      "documents": [
        "deit",
        "deit",
        "reformer",
        "segment_anything",
        "vision_transformer",
        "vision_transformer"
      ],
      "mentions": 6,
      "aliases": [
        "ViT-L/16",
        "ViT-B/16",
        "ViT-L/14"
      ],
      "description": "Vision Transformer model pre-trained on ImageNet-21k",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "TPUv3",
      "type": "hardware",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "TPUv3"
      ],
      "description": "Cloud TPU version 3 used for training",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BiT",
      "type": "method",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "BiT"
      ],
      "description": "State-of-the-art method based on ResNet co-trained on ImageNet and YouTube",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "VIVI",
      "type": "method",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "VIVI"
      ],
      "description": "ResNet co-trained on ImageNet and YouTube",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "S4L",
      "type": "method",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "S4L"
      ],
      "description": "Supervised plus semi-supervised learning method on ImageNet",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ViT-H/14",
      "type": "model",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "ViT-H/14"
      ],
      "description": "Vision Transformer model that outperforms BiT-R152x4 on Natural and Structured tasks",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "weight decay",
      "type": "hyperparameter",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "weight decay"
      ],
      "description": "Regularization parameter used to optimize model performance",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "dropout",
      "type": "hyperparameter",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "dropout"
      ],
      "description": "Regularization technique used to prevent overfitting",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "label smoothing",
      "type": "hyperparameter",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "label smoothing"
      ],
      "description": "Regularization technique used to improve model generalization",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ViT-B/32",
      "type": "model",
      "documents": [
        "deit",
        "deit",
        "vision_transformer",
        "vision_transformer"
      ],
      "mentions": 4,
      "aliases": [
        "ViT-B/32",
        "ViT-L/32"
      ],
      "description": "Vision Transformer model with specific architecture",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ViT-B",
      "type": "model",
      "documents": [
        "deit",
        "vision_transformer"
      ],
      "mentions": 2,
      "aliases": [
        "ViT-B"
      ],
      "description": "Vision Transformer model with all hidden dimensions halved",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Hybrid models",
      "type": "architecture",
      "documents": [
        "deit"
      ],
      "mentions": 1,
      "aliases": [
        "Hybrid models"
      ],
      "description": "Models combining ResNet and Vision Transformer architectures",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ICLR2021",
      "type": "conference",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "ICLR2021"
      ],
      "description": "Conference where the paper was published",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Attention",
      "type": "mechanism",
      "documents": [
        "deit"
      ],
      "mentions": 1,
      "aliases": [
        "Attention"
      ],
      "description": "Mechanism used in Vision Transformers to integrate information across the image",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Principal components",
      "type": "concept",
      "documents": [
        "deit"
      ],
      "mentions": 1,
      "aliases": [
        "Principal components"
      ],
      "description": "Statistical method used to analyze learned embeddings",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "self-attention",
      "type": "method",
      "documents": [
        "deit",
        "longformer",
        "swin_transformer",
        "transformer_xl",
        "vision_transformer"
      ],
      "mentions": 5,
      "aliases": [
        "self-attention"
      ],
      "description": "A mechanism that allows the model to weigh the importance of different parts of the input data.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "CNN",
      "type": "architecture",
      "documents": [
        "deit",
        "reformer",
        "swin_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "CNN"
      ],
      "description": "Convolutional Neural Networks, commonly used for image processing tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "masked language modeling",
      "type": "method",
      "documents": [
        "deit"
      ],
      "mentions": 1,
      "aliases": [
        "masked language modeling"
      ],
      "description": "A self-supervised learning task used in models like BERT.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "self-supervised pre-training",
      "type": "method",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "self-supervised pre-training"
      ],
      "description": "A training approach where the model learns from unlabeled data.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "attention distance",
      "type": "metric",
      "documents": [
        "deit",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "attention distance"
      ],
      "description": "A measure of how far information is integrated across the image based on attention weights.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Andreas Steiner",
      "type": "person",
      "documents": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "Andreas Steiner"
      ],
      "description": "A colleague at Google who contributed to the infrastructure.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Joan Puigcerver",
      "type": "person",
      "documents": [
        "deit",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "Joan Puigcerver"
      ],
      "description": "A colleague at Google who assisted with large-scale training infrastructure.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Maxim Neumann",
      "type": "person",
      "documents": [
        "deit",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "Maxim Neumann"
      ],
      "description": "A colleague at Google who helped with large-scale training infrastructure.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Dmitry Lepikhin",
      "type": "person",
      "documents": [
        "deit",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "Dmitry Lepikhin"
      ],
      "description": "A colleague at Google involved in discussions related to the work.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Aravindh Mahendran",
      "type": "person",
      "documents": [
        "deit",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "Aravindh Mahendran"
      ],
      "description": "A colleague at Google involved in discussions related to the work.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Daniel Keysers",
      "type": "person",
      "documents": [
        "deit",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "Daniel Keysers"
      ],
      "description": "A colleague at Google involved in discussions related to the work.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Mario Lucic",
      "type": "person",
      "documents": [
        "deit",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "Mario Lucic"
      ],
      "description": "A colleague at Google involved in discussions related to the work.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Colin Raffel",
      "type": "person",
      "documents": [
        "deit",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "Colin Raffel"
      ],
      "description": "A colleague at Google involved in discussions related to the work.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Devlin et al. (2019)",
      "type": "reference",
      "documents": [
        "deit",
        "longformer",
        "reformer"
      ],
      "mentions": 3,
      "aliases": [
        "Devlin et al. (2019)"
      ],
      "description": "Authors of the BERT paper, which introduced masked language modeling.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Chen et al. (2020b)",
      "type": "reference",
      "documents": [
        "deit",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "Chen et al. (2020b)"
      ],
      "description": "Authors of a paper on contrastive pre-training.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "He et al. (2020)",
      "type": "reference",
      "documents": [
        "deit",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "He et al. (2020)"
      ],
      "description": "Authors of a paper on unsupervised visual representation learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Bachman et al. (2019)",
      "type": "reference",
      "documents": [
        "deit",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "Bachman et al. (2019)"
      ],
      "description": "Authors of a paper on maximizing mutual information across views.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Hénaff et al. (2020)",
      "type": "reference",
      "documents": [
        "deit"
      ],
      "mentions": 1,
      "aliases": [
        "Hénaff et al. (2020)"
      ],
      "description": "Authors of a paper on contrastive learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Carion et al. (2020)",
      "type": "reference",
      "documents": [
        "deit",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "Carion et al. (2020)"
      ],
      "description": "Authors of a paper on end-to-end object detection with transformers.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "NLP",
      "type": "field",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "NLP"
      ],
      "description": "Natural Language Processing, a field of AI focused on the interaction between computers and human language.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "few-shot learning",
      "type": "method",
      "documents": [
        "gpt3_language_models",
        "gpt3_language_models",
        "gpt3",
        "gpt3",
        "palm"
      ],
      "mentions": 5,
      "aliases": [
        "one-shot learning",
        "few-shot learning"
      ],
      "description": "A learning paradigm where a model learns to perform a task with very few examples.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "pre-training",
      "type": "method",
      "documents": [
        "gpt3_language_models",
        "reformer"
      ],
      "mentions": 2,
      "aliases": [
        "Pre-training",
        "pre-training"
      ],
      "description": "The initial training phase of a model on a large corpus of text.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "fine-tuning",
      "type": "method",
      "documents": [
        "gpt3_language_models",
        "gpt3",
        "reformer"
      ],
      "mentions": 3,
      "aliases": [
        "Fine-tuning",
        "fine-tuning"
      ],
      "description": "The process of adapting a pre-trained model to a specific task using a smaller dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "language tasks",
      "type": "concept",
      "documents": [
        "gpt3_language_models"
      ],
      "mentions": 1,
      "aliases": [
        "language tasks"
      ],
      "description": "Various tasks that involve understanding or generating human language.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "translation",
      "type": "task",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "translation"
      ],
      "description": "The task of converting text from one language to another.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "question-answering",
      "type": "task",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "question-answering"
      ],
      "description": "The task of providing answers to questions based on a given context.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "cloze tasks",
      "type": "task",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "cloze tasks"
      ],
      "description": "Tasks that involve filling in the blanks in a sentence.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "3-digit arithmetic",
      "type": "task",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "3-digit arithmetic"
      ],
      "description": "A task that involves performing arithmetic operations with three-digit numbers.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Common Crawl",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3",
        "llama"
      ],
      "mentions": 3,
      "aliases": [
        "Common Crawl"
      ],
      "description": "A dataset used for training language models, consisting of web-crawled data.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "SuperGLUE",
      "type": "benchmark",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "SuperGLUE"
      ],
      "description": "A benchmark for evaluating the performance of NLP models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Johns Hopkins University",
      "type": "organization",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "Johns Hopkins University"
      ],
      "description": "An academic institution associated with one of the authors.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "parameters",
      "type": "metric",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "parameters"
      ],
      "description": "The number of adjustable weights in a neural network model.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "societal impacts",
      "type": "concept",
      "documents": [
        "gpt3_language_models"
      ],
      "mentions": 1,
      "aliases": [
        "societal impacts"
      ],
      "description": "The broader implications of language models like GPT-3 on society.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "in-context learning",
      "type": "method",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "in-context learning"
      ],
      "description": "A meta-learning approach where a model uses contextual information to adapt to tasks without gradient updates.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "meta-learning",
      "type": "method",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "meta-learning"
      ],
      "description": "A learning paradigm where models develop a broad set of skills during training to adapt quickly to new tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Natural Questions",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3",
        "llama"
      ],
      "mentions": 3,
      "aliases": [
        "Natural Questions"
      ],
      "description": "A benchmark dataset used to evaluate question answering systems.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "CoQA",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "CoQA"
      ],
      "description": "A conversational question answering dataset used to evaluate models on dialogue-based tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "TriviaQA",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3",
        "llama",
        "longformer"
      ],
      "mentions": 4,
      "aliases": [
        "TriviaQA"
      ],
      "description": "A dataset for question answering that includes trivia questions.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "log loss",
      "type": "metric",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "log loss"
      ],
      "description": "A performance metric that correlates well with many downstream NLP tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "RWC+19",
      "type": "reference",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "RWC+19"
      ],
      "description": "A citation for a paper discussing in-context learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "YdC+19",
      "type": "reference",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "YdC+19"
      ],
      "description": "A citation for a paper discussing generalization in models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MPL19",
      "type": "reference",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "MPL19"
      ],
      "description": "A citation for a paper related to model performance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "GSL+18",
      "type": "reference",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "GSL+18"
      ],
      "description": "A citation for a paper discussing the performance of fine-tuned models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "NK19",
      "type": "reference",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "NK19"
      ],
      "description": "A citation for a paper related to model evaluation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "KMH+20",
      "type": "reference",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "KMH+20"
      ],
      "description": "A citation for a paper discussing the correlation of log loss with model performance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "RNSS18",
      "type": "reference",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "RNSS18"
      ],
      "description": "A citation for a paper discussing the early transformer models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "DCLT18",
      "type": "reference",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "DCLT18"
      ],
      "description": "A citation for a paper discussing the scaling of transformer models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "SPP+19",
      "type": "reference",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "SPP+19"
      ],
      "description": "A citation for a paper discussing improvements in transformer models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "RSR+19",
      "type": "reference",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "RSR+19"
      ],
      "description": "A citation for a paper discussing the scaling of language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Tur20",
      "type": "reference",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "Tur20"
      ],
      "description": "A citation for a paper discussing the latest advancements in transformer models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ANLI",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "ANLI"
      ],
      "description": "A natural language inference dataset used to evaluate model performance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "RACE",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3",
        "llama"
      ],
      "mentions": 3,
      "aliases": [
        "RACE"
      ],
      "description": "A reading comprehension dataset for evaluating language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "QuAC",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "QuAC"
      ],
      "description": "A dataset for question answering in a conversational context.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "CommonCrawl",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3",
        "llama"
      ],
      "mentions": 3,
      "aliases": [
        "CommonCrawl"
      ],
      "description": "A web corpus used for training language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Data Contamination",
      "type": "concept",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "Data Contamination",
        "data contamination"
      ],
      "description": "The issue of training models on datasets that may include content from test datasets.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Bias and Fairness",
      "type": "concept",
      "documents": [
        "gpt3_language_models"
      ],
      "mentions": 1,
      "aliases": [
        "Bias and Fairness"
      ],
      "description": "Concerns regarding the ethical implications and societal impacts of AI models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Books1",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3_language_models",
        "gpt3",
        "gpt3"
      ],
      "mentions": 4,
      "aliases": [
        "Books2",
        "Books1"
      ],
      "description": "An internet-based corpus used in training language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Wikipedia",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3",
        "llama",
        "palm"
      ],
      "mentions": 4,
      "aliases": [
        "Wikipedia"
      ],
      "description": "An English-language encyclopedia used in training language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Sparse Transformer",
      "type": "architecture",
      "documents": [
        "gpt3_language_models",
        "gpt3",
        "longformer"
      ],
      "mentions": 3,
      "aliases": [
        "Sparse Transformer"
      ],
      "description": "An architecture that uses alternating dense and locally banded sparse attention patterns.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Validation loss",
      "type": "metric",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "Validation loss"
      ],
      "description": "A measure used to evaluate the performance of models during training.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Scaling Laws for Neural Language Models",
      "type": "research",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "Scaling Laws for Neural Language Models"
      ],
      "description": "A study that analyzes the relationship between model size and performance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Microsoft",
      "type": "organization",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "Microsoft"
      ],
      "description": "Provider of high-bandwidth cluster for training.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LAMBADA",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "LAMBADA"
      ],
      "description": "A dataset testing long-range dependencies in text.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Storycloze",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "Storycloze"
      ],
      "description": "A dataset used for evaluating story completion tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Winograd",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "Winograd"
      ],
      "description": "A dataset for evaluating commonsense reasoning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ARC",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "ARC"
      ],
      "description": "A dataset for evaluating reasoning capabilities.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "OpenBookQA",
      "type": "dataset",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "OpenBookQA"
      ],
      "description": "A dataset for evaluating question answering.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "F1 similarity score",
      "type": "metric",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "F1 similarity score"
      ],
      "description": "A metric for evaluating model performance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "K",
      "type": "parameter",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "K"
      ],
      "description": "The number of examples drawn from the training set for few-shot learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "model parallelism",
      "type": "method",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "model parallelism"
      ],
      "description": "A technique used to distribute model training across multiple GPUs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "gradient noise scaling",
      "type": "method",
      "documents": [
        "gpt3_language_models",
        "gpt3"
      ],
      "mentions": 2,
      "aliases": [
        "gradient noise scaling"
      ],
      "description": "A technique used to guide the choice of batch size during training.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "task-specific fine-tuning",
      "type": "Method",
      "documents": [
        "gpt3"
      ],
      "mentions": 1,
      "aliases": [
        "task-specific fine-tuning"
      ],
      "description": "The process of adapting a pre-trained model to a specific task using a labeled dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "human evaluators",
      "type": "People",
      "documents": [
        "gpt3"
      ],
      "mentions": 1,
      "aliases": [
        "human evaluators"
      ],
      "description": "Individuals who assess the quality of generated text.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "F1 Score",
      "type": "metric",
      "documents": [
        "gpt3",
        "longformer"
      ],
      "mentions": 2,
      "aliases": [
        "F1 Score"
      ],
      "description": "A measure of a model's accuracy on a dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "accuracy",
      "type": "metric",
      "documents": [
        "gpt3",
        "segment_anything",
        "vision_transformer"
      ],
      "mentions": 3,
      "aliases": [
        "accuracy"
      ],
      "description": "The ratio of correctly predicted instances to the total instances.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LLaMA-I",
      "type": "Language Model",
      "documents": [
        "llama",
        "llama",
        "segment_anything"
      ],
      "mentions": 3,
      "aliases": [
        "LLaMA",
        "LLaMA-I"
      ],
      "description": "A collection of foundation language models ranging from 7B to 65B parameters.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Chinchilla",
      "type": "Language Model",
      "documents": [
        "llama",
        "palm"
      ],
      "mentions": 2,
      "aliases": [
        "Chinchilla"
      ],
      "description": "A large language model with 70B parameters, used for performance comparison.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "PaLM",
      "type": "Language Model",
      "documents": [
        "llama",
        "palm"
      ],
      "mentions": 2,
      "aliases": [
        "PaLM"
      ],
      "description": "A large language model with 540B parameters, used for performance comparison.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MetaAI",
      "type": "Organization",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "MetaAI"
      ],
      "description": "The organization behind the development of LLaMA.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Hoffmann et al. (2022)",
      "type": "Research Paper",
      "documents": [
        "llama",
        "palm"
      ],
      "mentions": 2,
      "aliases": [
        "Hoffmann et al. (2022)"
      ],
      "description": "A study that discusses scaling laws for language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "C4",
      "type": "Dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "C4"
      ],
      "description": "A dataset used for training, consisting of web data filtered for quality.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Github",
      "type": "Dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Github"
      ],
      "description": "A dataset containing public GitHub repositories.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Books",
      "type": "Dataset",
      "documents": [
        "llama",
        "palm"
      ],
      "mentions": 2,
      "aliases": [
        "Books"
      ],
      "description": "A dataset containing public domain books.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ArXiv",
      "type": "Dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "ArXiv"
      ],
      "description": "A dataset containing scientific papers from arXiv.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "StackExchange",
      "type": "Dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "StackExchange"
      ],
      "description": "A dataset containing questions and answers from Stack Exchange.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Transformer Architecture",
      "type": "Architecture",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Transformer Architecture"
      ],
      "description": "The neural network architecture used for training LLaMA.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Performance Metrics",
      "type": "Metric",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Performance Metrics"
      ],
      "description": "Benchmarks used to evaluate the performance of language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "CCNet",
      "type": "dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "CCNet"
      ],
      "description": "A dataset used for increasing consistency across papers.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Stack Exchange",
      "type": "website",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Stack Exchange"
      ],
      "description": "A platform for high-quality questions and answers across various domains.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Google BigQuery",
      "type": "service",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Google BigQuery"
      ],
      "description": "A cloud-based data warehouse for querying large datasets.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Apache License",
      "type": "license",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Apache License"
      ],
      "description": "A permissive free software license.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BSD License",
      "type": "license",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "BSD License"
      ],
      "description": "A family of permissive free software licenses.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MIT License",
      "type": "license",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "MIT License"
      ],
      "description": "A permissive free software license.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Byte-Pair Encoding (BPE)",
      "type": "algorithm",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Byte-Pair Encoding (BPE)"
      ],
      "description": "A tokenization algorithm used for processing text.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "RMSNorm",
      "type": "normalization function",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "RMSNorm"
      ],
      "description": "A normalization function used to improve training stability.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "SwiGLU",
      "type": "activation function",
      "documents": [
        "llama",
        "palm"
      ],
      "mentions": 2,
      "aliases": [
        "SwiGLU"
      ],
      "description": "An activation function used to improve performance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Rotary Positional Embeddings (RoPE)",
      "type": "embedding technique",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Rotary Positional Embeddings (RoPE)"
      ],
      "description": "A technique for adding positional information to transformer models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "AdamW",
      "type": "optimizer",
      "documents": [
        "llama",
        "swin_transformer"
      ],
      "mentions": 2,
      "aliases": [
        "AdamW"
      ],
      "description": "An optimization algorithm used for training models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "CommonSense Reasoning Tasks",
      "type": "task",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "CommonSense Reasoning Tasks"
      ],
      "description": "A set of tasks for evaluating models on common sense reasoning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Gopher",
      "type": "model",
      "documents": [
        "llama",
        "palm"
      ],
      "mentions": 2,
      "aliases": [
        "Gopher"
      ],
      "description": "A large language model developed by DeepMind.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Table 2",
      "type": "table",
      "documents": [
        "llama",
        "llama"
      ],
      "mentions": 2,
      "aliases": [
        "Table 3",
        "Table 2"
      ],
      "description": "A table containing model sizes, architectures, and optimization hyper-parameters.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "OPT",
      "type": "model",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "OPT"
      ],
      "description": "Open-sourced language models compared with LLaMA.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "OPT-IML",
      "type": "model",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "OPT-IML"
      ],
      "description": "An instruction-tuned model compared with LLaMA.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "HumanEval",
      "type": "dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "HumanEval"
      ],
      "description": "A benchmark for evaluating code generation from natural language.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MBPP",
      "type": "dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "MBPP"
      ],
      "description": "A benchmark for evaluating code generation from natural language.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MATH",
      "type": "dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "MATH"
      ],
      "description": "A dataset of mathematical problems for evaluation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "GSM8k",
      "type": "dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "GSM8k"
      ],
      "description": "A dataset of middle school mathematical problems.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BoolQ",
      "type": "dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "BoolQ"
      ],
      "description": "A common sense reasoning benchmark.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Flan-PaLM",
      "type": "dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Flan-PaLM"
      ],
      "description": "An instruction-tuned model benchmark.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "WinoGrande",
      "type": "dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "WinoGrande"
      ],
      "description": "A common sense reasoning benchmark.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ARCeasy",
      "type": "dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "ARCeasy"
      ],
      "description": "A common sense reasoning benchmark.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ARChallenge",
      "type": "dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "ARChallenge"
      ],
      "description": "A common sense reasoning benchmark.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Exact Match",
      "type": "metric",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Exact Match"
      ],
      "description": "A performance metric for evaluating question answering.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Zero-shot",
      "type": "evaluation setting",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Zero-shot"
      ],
      "description": "An evaluation setting where models are tested without prior examples.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Few-shot",
      "type": "evaluation setting",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Few-shot"
      ],
      "description": "An evaluation setting where models are tested with a few examples.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "pass@",
      "type": "metric",
      "documents": [
        "llama",
        "llama"
      ],
      "mentions": 2,
      "aliases": [
        "pass@",
        "pass@1"
      ],
      "description": "A performance metric for evaluating code generation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MMLU",
      "type": "benchmark",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "MMLU"
      ],
      "description": "Massive multitask language understanding benchmark.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LaMDA",
      "type": "model",
      "documents": [
        "llama",
        "palm"
      ],
      "mentions": 2,
      "aliases": [
        "LaMDA"
      ],
      "description": "A language model developed by Google, compared with LLaMA.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LLaMA-65B",
      "type": "model",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "LLaMA-65B"
      ],
      "description": "A large language model with 65 billion parameters.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Gutenberg",
      "type": "dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Gutenberg"
      ],
      "description": "A digital library of free eBooks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Books3",
      "type": "dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Books3"
      ],
      "description": "A dataset used in training language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "pass@100",
      "type": "metric",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "pass@100"
      ],
      "description": "A metric indicating the percentage of correct answers within 100 attempts.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "pass@80",
      "type": "metric",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "pass@80"
      ],
      "description": "A metric indicating the percentage of correct answers within 80 attempts.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "RealToxicityPrompts",
      "type": "benchmark",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "RealToxicityPrompts"
      ],
      "description": "A benchmark for evaluating the toxicity of language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "PerspectiveAPI",
      "type": "API",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "PerspectiveAPI"
      ],
      "description": "An API used to evaluate the toxicity of generated text.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Chen et al. (2021)",
      "type": "citation",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Chen et al. (2021)"
      ],
      "description": "A reference to a paper discussing methods for unbiased estimates.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Chowdhery et al. (2022)",
      "type": "citation",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Chowdhery et al. (2022)"
      ],
      "description": "A reference to a paper discussing the PaLM-Coder model.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Iyer et al. (2022)",
      "type": "citation",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Iyer et al. (2022)"
      ],
      "description": "A reference to a paper discussing instruction-tuned models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Zhang et al. (2022)",
      "type": "citation",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Zhang et al. (2022)"
      ],
      "description": "A reference to a paper discussing toxic content generation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "WinoGender",
      "type": "dataset",
      "documents": [
        "llama",
        "palm"
      ],
      "mentions": 2,
      "aliases": [
        "Winogender",
        "WinoGender"
      ],
      "description": "A dataset for evaluating co-reference resolution and biases related to gender.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "CrowS-Pairs",
      "type": "dataset",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "CrowS-Pairs"
      ],
      "description": "A dataset used to measure biases in various categories including gender and religion.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "TruthfulQA",
      "type": "benchmark",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "TruthfulQA"
      ],
      "description": "A benchmark for measuring the truthfulness of language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Rae et al. (2021)",
      "type": "publication",
      "documents": [
        "llama",
        "longformer",
        "palm"
      ],
      "mentions": 3,
      "aliases": [
        "Rae et al. (2020)",
        "Rae et al. (2021)"
      ],
      "description": "A reference to previous work on gender bias in models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "API",
      "type": "technology",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "API"
      ],
      "description": "Application Programming Interface used for model interaction.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Carbon Emission",
      "type": "metric",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Carbon Emission"
      ],
      "description": "A measure of the carbon footprint associated with model training.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Perplexity",
      "type": "metric",
      "documents": [
        "llama",
        "transformer_xl",
        "transformer_xl"
      ],
      "mentions": 3,
      "aliases": [
        "perplexity (PPL)",
        "perplexity",
        "Perplexity"
      ],
      "description": "A measure used to evaluate the performance of language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Co-reference resolution",
      "type": "method",
      "documents": [
        "llama"
      ],
      "mentions": 1,
      "aliases": [
        "Co-reference resolution"
      ],
      "description": "A task in natural language processing to determine which words refer to the same entity.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Longformer",
      "type": "architecture",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Longformer"
      ],
      "description": "A modified Transformer architecture with a self-attention operation that scales linearly with sequence length.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Allen Institute for Artificial Intelligence",
      "type": "organization",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Allen Institute for Artificial Intelligence"
      ],
      "description": "The organization where the authors of the paper are affiliated.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "text8",
      "type": "dataset",
      "documents": [
        "longformer",
        "transformer_xl"
      ],
      "mentions": 2,
      "aliases": [
        "text8"
      ],
      "description": "A benchmark dataset used for evaluating language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "enwik8",
      "type": "dataset",
      "documents": [
        "longformer",
        "transformer_xl"
      ],
      "mentions": 2,
      "aliases": [
        "enwik8"
      ],
      "description": "Another benchmark dataset used for evaluating language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "WikiHop",
      "type": "dataset",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "WikiHop"
      ],
      "description": "A dataset used for evaluating long document tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Longformer-Encoder-Decoder (LED)",
      "type": "architecture",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Longformer-Encoder-Decoder (LED)"
      ],
      "description": "A variant of Longformer designed for long document generative sequence-to-sequence tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "RoBERTa",
      "type": "architecture",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "RoBERTa"
      ],
      "description": "A pre-trained Transformer model that Longformer outperforms on long document tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Transformer-XL",
      "type": "architecture",
      "documents": [
        "longformer",
        "transformer_xl"
      ],
      "mentions": 2,
      "aliases": [
        "Transformer-XL"
      ],
      "description": "A model that addresses the computational efficiency of Transformers on long sequences.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Dai et al. (2019)",
      "type": "reference",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Dai et al. (2019)"
      ],
      "description": "A reference to prior work on generative language modeling.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Radford et al. (2019)",
      "type": "reference",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Radford et al. (2019)"
      ],
      "description": "A reference to prior work on generative language modeling.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Cohan et al. (2018)",
      "type": "reference",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Cohan et al. (2018)"
      ],
      "description": "A reference to prior work on summarization datasets.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BlockSparse",
      "type": "method",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "BlockSparse"
      ],
      "description": "A method implemented in C++ for specific versions of TensorFlow.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "CUDA",
      "type": "technology",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "CUDA"
      ],
      "description": "A parallel computing platform and application programming interface model created by NVIDIA.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "TensorFlow",
      "type": "framework",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "TensorFlow"
      ],
      "description": "An open-source machine learning framework.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "QA",
      "type": "task",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "QA"
      ],
      "description": "Question Answering, a natural language processing task.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "coreference resolution",
      "type": "task",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "coreference resolution"
      ],
      "description": "The task of determining when different expressions refer to the same entity.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LED",
      "type": "model",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "LED"
      ],
      "description": "Longformer-Encoder-Decoder, a variant of Longformer for sequence-to-sequence learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BP-Transformer",
      "type": "model",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "BP-Transformer"
      ],
      "description": "A transformer model evaluated on machine translation tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "CPC loss",
      "type": "metric",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "CPC loss"
      ],
      "description": "Contrastive Predictive Coding loss, an additional training objective.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BigBird",
      "type": "model",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "BigBird"
      ],
      "description": "An extension of ETC for long document tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ETC",
      "type": "model",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "ETC"
      ],
      "description": "A transformer model that uses local + global attention.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "SQuAD",
      "type": "dataset",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "SQuAD"
      ],
      "description": "Stanford Question Answering Dataset, typically fits within the 512 limit.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MRQA",
      "type": "dataset",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "MRQA"
      ],
      "description": "Machine Reading for Question Answering, constructed by dropping long-document examples.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "dilated CNNs",
      "type": "method",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "dilated CNNs"
      ],
      "description": "Convolutional neural networks that use dilated convolutions.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Sutskever et al. (2014)",
      "type": "publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Sutskever et al. (2014)"
      ],
      "description": "The paper introducing sequence-to-sequence learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Xie et al. (2019)",
      "type": "publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Xie et al. (2019)"
      ],
      "description": "Research on truncating documents for classification.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Clark and Gardner (2017)",
      "type": "publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Clark and Gardner (2017)"
      ],
      "description": "Research on two-stage models for open domain QA.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Chen et al. (2017)",
      "type": "publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Chen et al. (2017)"
      ],
      "description": "Research related to answer extraction in QA.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Gupta and Berant (2020)",
      "type": "publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Gupta and Berant (2020)"
      ],
      "description": "Research on using global memory in models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Kovaleva et al. (2019)",
      "type": "publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Kovaleva et al. (2019)"
      ],
      "description": "Research on the importance of local context.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Josh et al. (2019)",
      "type": "publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Josh et al. (2019)"
      ],
      "description": "Research on processing document chunks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Wu et al. (2019)",
      "type": "publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Wu et al. (2019)"
      ],
      "description": "Research on CNNs and their representation capabilities.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "vandenOord et al. (2016)",
      "type": "publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "vandenOord et al. (2016)"
      ],
      "description": "Research on dilated convolutions.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Ye et al. (2019)",
      "type": "publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Ye et al. (2019)"
      ],
      "description": "Research on evaluating transformer models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BERT",
      "type": "model",
      "documents": [
        "longformer",
        "palm",
        "reformer"
      ],
      "mentions": 3,
      "aliases": [
        "BERT"
      ],
      "description": "A state-of-the-art model for natural language processing tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Global Attention",
      "type": "method",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Global Attention"
      ],
      "description": "An attention mechanism that allows certain tokens to attend to all tokens in the sequence.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Masked Language Modeling (MLM)",
      "type": "task",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Masked Language Modeling (MLM)"
      ],
      "description": "A task where the model predicts masked words in a sequence.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Question Answering (QA)",
      "type": "task",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Question Answering (QA)"
      ],
      "description": "A task where the model answers questions based on a given document.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Adaptive Span",
      "type": "model",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Adaptive Span"
      ],
      "description": "A model that adapts the attention span based on the input.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Compressive Transformer",
      "type": "model",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Compressive Transformer"
      ],
      "description": "A transformer model that compresses information to handle longer sequences.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Reformer",
      "type": "model",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Reformer"
      ],
      "description": "A transformer model that uses reversible layers to reduce memory usage.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Dataset text8",
      "type": "dataset",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Dataset text8"
      ],
      "description": "A dataset used for training language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Dataset enwik8",
      "type": "dataset",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Dataset enwik8"
      ],
      "description": "A dataset used for evaluating language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "TVM",
      "type": "technology",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "TVM"
      ],
      "description": "An open-source deep learning compiler stack.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "PyTorch",
      "type": "library",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "PyTorch"
      ],
      "description": "An open-source machine learning library used for deep learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Sukhbaatar et al. (2019)",
      "type": "publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Sukhbaatar et al. (2019)"
      ],
      "description": "A reference to a paper that discusses adaptive attention spans.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Child et al. (2019)",
      "type": "publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Child et al. (2019)"
      ],
      "description": "A reference to a paper that discusses sparse transformers.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Al-Rfou et al. (2018)",
      "type": "publication",
      "documents": [
        "longformer",
        "transformer_xl"
      ],
      "mentions": 2,
      "aliases": [
        "Al-Rfou et al. (2018)"
      ],
      "description": "A reference to a paper that discusses the T12 dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MLM",
      "type": "Method",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "MLM"
      ],
      "description": "Masked Language Modeling, a pretraining objective for language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Attention Pattern",
      "type": "Method",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Attention Pattern"
      ],
      "description": "A technique for configuring attention mechanisms in transformer models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Gradient Updates",
      "type": "Metric",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Gradient Updates"
      ],
      "description": "The number of updates applied during model training.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "HotpotQA",
      "type": "Dataset",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "HotpotQA"
      ],
      "description": "A multi-hop question answering dataset that requires evidence extraction.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "fairseq",
      "type": "Framework",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "fairseq"
      ],
      "description": "A sequence-to-sequence learning toolkit for training models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Clark and Gardner",
      "type": "People",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Clark and Gardner"
      ],
      "description": "Researchers who proposed a loss function for question answering.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Ott et al.",
      "type": "People",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Ott et al."
      ],
      "description": "Researchers who contributed to the fairseq framework.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Devlin et al.",
      "type": "People",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Devlin et al."
      ],
      "description": "Researchers who developed the BERT model.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Liu et al.",
      "type": "People",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Liu et al."
      ],
      "description": "Researchers who introduced the RoBERTa model.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Rae et al.",
      "type": "People",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Rae et al."
      ],
      "description": "Researchers who discussed configurations for transformer models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Clark et al.",
      "type": "People",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Clark et al."
      ],
      "description": "Researchers who analyzed BERT's attention heads.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "RoBERTa-large",
      "type": "Model",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "RoBERTa-large"
      ],
      "description": "A transformer-based model for natural language processing.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Longformer-large",
      "type": "Model",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Longformer-large"
      ],
      "description": "A transformer model designed for long document processing.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Frozen RoBERTa Weights",
      "type": "Method",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Frozen RoBERTa Weights"
      ],
      "description": "A technique where the weights of the RoBERTa model are kept constant during training.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "OntoNotes",
      "type": "Dataset",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "OntoNotes"
      ],
      "description": "A dataset used for coreference resolution.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "IMDB",
      "type": "Dataset",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "IMDB"
      ],
      "description": "A dataset for sentiment classification based on movie reviews.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Hyperpartisan",
      "type": "Dataset",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Hyperpartisan"
      ],
      "description": "A dataset for detecting hyperpartisan news.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BPC",
      "type": "Metric",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "BPC"
      ],
      "description": "Bits per character, a measure of model performance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "GNN",
      "type": "Method",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "GNN"
      ],
      "description": "Graph Neural Networks, used for reasoning over entities.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Joshi et al. (2019)",
      "type": "Publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Joshi et al. (2019)"
      ],
      "description": "A paper that presents a model for coreference resolution.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BART",
      "type": "Model",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "BART"
      ],
      "description": "A pre-trained encoder-decoder model for sequence-to-sequence tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "T5",
      "type": "Model",
      "documents": [
        "longformer",
        "palm"
      ],
      "mentions": 2,
      "aliases": [
        "T5"
      ],
      "description": "A text-to-text transfer transformer model.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Lee et al. (2018)",
      "type": "Publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Lee et al. (2018)"
      ],
      "description": "A paper that discusses replacing ELMo with BERT.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Fang et al. (2020)",
      "type": "Publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Fang et al. (2020)"
      ],
      "description": "A paper that presents a state-of-the-art model for HotpotQA.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Tu et al. (2019)",
      "type": "Publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Tu et al. (2019)"
      ],
      "description": "A paper that discusses a model for question answering.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Shao et al. (2020)",
      "type": "Publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Shao et al. (2020)"
      ],
      "description": "A paper that presents a model for question answering.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Kipf and Welling (2017)",
      "type": "Publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Kipf and Welling (2017)"
      ],
      "description": "A paper that discusses Graph Neural Networks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Glaß et al. (2019)",
      "type": "Publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Glaß et al. (2019)"
      ],
      "description": "A paper that presents a non-GNN method for question answering.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Groeneveld et al. (2020)",
      "type": "Publication",
      "documents": [
        "longformer"
      ],
      "mentions": 1,
      "aliases": [
        "Groeneveld et al. (2020)"
      ],
      "description": "A paper that discusses a model for question answering.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Pathways",
      "type": "System",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Pathways"
      ],
      "description": "A new ML system enabling efficient training across multiple TPU Pods.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "TPUv4",
      "type": "Hardware",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "TPUv4"
      ],
      "description": "Tensor Processing Unit version 4 used for training the model.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BIG-bench",
      "type": "Benchmark",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "BIG-bench"
      ],
      "description": "A benchmark suite for evaluating language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Aakanksha Chowdhery",
      "type": "Person",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Aakanksha Chowdhery"
      ],
      "description": "One of the authors of the paper.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Sharan Narang",
      "type": "Person",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Sharan Narang"
      ],
      "description": "One of the authors of the paper.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Jacob Devlin",
      "type": "Person",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Jacob Devlin"
      ],
      "description": "One of the authors of the paper.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Sanjay Ghemawat",
      "type": "Person",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Sanjay Ghemawat"
      ],
      "description": "One of the authors of the paper.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Ethical Considerations",
      "type": "Topic",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Ethical Considerations"
      ],
      "description": "Discussion on the ethical implications of large language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Bias and Toxicity",
      "type": "Analysis",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Bias and Toxicity"
      ],
      "description": "Analysis of bias and toxicity in model outputs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Language Models (LMs)",
      "type": "Technology",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Language Models (LMs)"
      ],
      "description": "Models used for few-shot predictions based on natural language task descriptions.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Few-shot predictions",
      "type": "Method",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Few-shot predictions"
      ],
      "description": "A prediction method where the model is given a task description and a few exemplars.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "GLaM",
      "type": "Model",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "GLaM"
      ],
      "description": "A post-GPT-3 language model that achieved few-shot state-of-the-art results.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Megatron–Turing NLG",
      "type": "Model",
      "documents": [
        "palm",
        "palm"
      ],
      "mentions": 2,
      "aliases": [
        "Megatron-Turing NLG 530B",
        "Megatron–Turing NLG"
      ],
      "description": "A post-GPT-3 language model developed by Smith et al. in 2022.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Transformer architecture",
      "type": "Architecture",
      "documents": [
        "palm",
        "swin_transformer"
      ],
      "mentions": 2,
      "aliases": [
        "Transformer architecture"
      ],
      "description": "The architecture used in GPT-3 and its variants.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "TPU v4 Pods",
      "type": "Hardware",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "TPU v4 Pods"
      ],
      "description": "A type of hardware used for training large models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "FLOPs utilization",
      "type": "Metric",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "FLOPs utilization"
      ],
      "description": "A measure of efficiency in model and hardware performance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Wei et al. (2022b)",
      "type": "Person",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Wei et al. (2022b)"
      ],
      "description": "Researchers who contributed to chain-of-thought prompting.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Du et al. (2021)",
      "type": "Person",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Du et al. (2021)"
      ],
      "description": "Researchers who developed GLaM.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Smith et al. (2022)",
      "type": "Person",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Smith et al. (2022)"
      ],
      "description": "Researchers who developed Megatron–Turing NLG.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Thoppilan et al. (2022)",
      "type": "Person",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Thoppilan et al. (2022)"
      ],
      "description": "Researchers who developed LaMDA.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Brown et al. (2020)",
      "type": "Person",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Brown et al. (2020)"
      ],
      "description": "Researchers who developed GPT-3.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "RoPE",
      "type": "embedding",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "RoPE"
      ],
      "description": "Rotary Position Embeddings used for better performance on long sequence lengths.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "SentencePiece",
      "type": "tokenization method",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "SentencePiece"
      ],
      "description": "A method used for generating a vocabulary of tokens from the training data.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Kaplan et al., 2020",
      "type": "publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Kaplan et al., 2020"
      ],
      "description": "A reference discussing the power law in neural network scaling.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Shazeer, 2020",
      "type": "publication",
      "documents": [
        "palm",
        "palm"
      ],
      "mentions": 2,
      "aliases": [
        "Shazeer, 2020",
        "Shazeer, 2019"
      ],
      "description": "A reference discussing the effectiveness of SwiGLU activations.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Wang & Komatsuzaki, 2021",
      "type": "publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Wang & Komatsuzaki, 2021"
      ],
      "description": "A reference discussing the parallel formulation in Transformer blocks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Kudo & Richardson, 2018a",
      "type": "publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Kudo & Richardson, 2018a"
      ],
      "description": "A reference discussing the SentencePiece vocabulary generation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "540B parameters",
      "type": "Model Scale",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "540B parameters"
      ],
      "description": "The largest model scale in the comparison.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "62B parameters",
      "type": "Model Scale",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "62B parameters"
      ],
      "description": "The medium model scale in the comparison.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "8B parameters",
      "type": "Model Scale",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "8B parameters"
      ],
      "description": "The smallest model scale in the comparison.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "FLOPs",
      "type": "Metric",
      "documents": [
        "palm",
        "swin_transformer"
      ],
      "mentions": 2,
      "aliases": [
        "FLOPs"
      ],
      "description": "Floating Point Operations per second, approximately equal to the number of parameters.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Transformers",
      "type": "Architecture",
      "documents": [
        "palm",
        "vision_transformer"
      ],
      "mentions": 2,
      "aliases": [
        "Transformers"
      ],
      "description": "A type of model architecture used for natural language processing.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "JAX",
      "type": "Framework",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "JAX"
      ],
      "description": "A framework used for training and evaluation codebase.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "T5X",
      "type": "Framework",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "T5X"
      ],
      "description": "A framework used for training and evaluation codebase.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "780 billion tokens",
      "type": "Dataset Size",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "780 billion tokens"
      ],
      "description": "The total size of the pretraining dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Filtered webpages",
      "type": "Data Source",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Filtered webpages"
      ],
      "description": "One of the sources used in the training dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "GitHub",
      "type": "Data Source",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "GitHub"
      ],
      "description": "Source of code included in the training dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Social media conversations",
      "type": "Data Source",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Social media conversations"
      ],
      "description": "One of the sources used in the training dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "News articles",
      "type": "Data Source",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "News articles"
      ],
      "description": "One of the sources used in the training dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Levenshtein distance",
      "type": "Metric",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Levenshtein distance"
      ],
      "description": "A method used to remove duplicate files in the dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Mitchell et al., 2019",
      "type": "Publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Mitchell et al., 2019"
      ],
      "description": "Authors of the Model Card for PaLM.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Thoppilan et al., 2022",
      "type": "Publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Thoppilan et al., 2022"
      ],
      "description": "Authors of the LaMDA model.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Du et al., 2021",
      "type": "Publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Du et al., 2021"
      ],
      "description": "Authors of the GLaM model.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Bradbury et al., 2018",
      "type": "Publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Bradbury et al., 2018"
      ],
      "description": "Authors of the JAX framework.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Roberts et al., 2022",
      "type": "Publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Roberts et al., 2022"
      ],
      "description": "Authors of the T5X framework.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Jouppi et al., 2020",
      "type": "Publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Jouppi et al., 2020"
      ],
      "description": "Authors of the TPU v4 Pods.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Xu et al., 2021",
      "type": "Publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Xu et al., 2021"
      ],
      "description": "Authors discussing model and data parallelism.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Huang et al., 2019",
      "type": "Publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Huang et al., 2019"
      ],
      "description": "Authors discussing pipeline parallelism.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Lopes et al., 2017",
      "type": "Publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Lopes et al., 2017"
      ],
      "description": "Authors discussing duplicate files in source code.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Allamanis, 2019",
      "type": "Publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Allamanis, 2019"
      ],
      "description": "Authors discussing duplicate files in source code.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Gebru et al., 2021",
      "type": "Publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Gebru et al., 2021"
      ],
      "description": "Authors of the datasheet providing additional information.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Pathways system",
      "type": "system",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Pathways system"
      ],
      "description": "A system designed to scale training across TPU pods using two-way data parallelism.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "TPU v4",
      "type": "hardware",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "TPU v4"
      ],
      "description": "A type of Tensor Processing Unit used for accelerating machine learning workloads.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "JAX/XLA",
      "type": "software",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "JAX/XLA"
      ],
      "description": "A framework for high-performance numerical computing and machine learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Python client",
      "type": "software",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Python client"
      ],
      "description": "A client that constructs a sharded dataflow program for executing computations.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Gradient transfer",
      "type": "method",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Gradient transfer"
      ],
      "description": "The process of transferring computed gradients between TPU pods.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Model FLOPs utilization (MFU)",
      "type": "metric",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Model FLOPs utilization (MFU)"
      ],
      "description": "A metric for measuring training efficiency based on observed throughput relative to theoretical maximum throughput.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Hardware FLOPs utilization (HFU)",
      "type": "metric",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Hardware FLOPs utilization (HFU)"
      ],
      "description": "A metric reflecting the ratio of FLOPs observed on a device to its theoretical peak FLOPs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Rematerialization",
      "type": "method",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Rematerialization"
      ],
      "description": "A technique to trade off memory usage with compute by recomputing certain operations.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Megatron-Turing NLG",
      "type": "model",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Megatron-Turing NLG"
      ],
      "description": "A large language model with 530 billion parameters.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Google datacenter network",
      "type": "infrastructure",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Google datacenter network"
      ],
      "description": "The network infrastructure connecting TPU pods for data transfer.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Barham et al., 2022",
      "type": "publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Barham et al., 2022"
      ],
      "description": "A reference for the Pathways system and its design.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Singh et al., 2015",
      "type": "publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Singh et al., 2015"
      ],
      "description": "A reference for the Google datacenter network.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Narayanan et al., 2021b",
      "type": "publication",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Narayanan et al., 2021b"
      ],
      "description": "A reference for analytical accounting of hardware FLOPs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Appendix B",
      "type": "document section",
      "documents": [
        "palm"
      ],
      "mentions": 1,
      "aliases": [
        "Appendix B"
      ],
      "description": "Section detailing the mathematical formula to compute MFU.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Classification Token",
      "type": "Model Component",
      "documents": [
        "reformer"
      ],
      "mentions": 1,
      "aliases": [
        "Classification Token"
      ],
      "description": "A learnable embedding added to the input sequence for classification tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "2D image topology",
      "type": "concept",
      "documents": [
        "reformer"
      ],
      "mentions": 1,
      "aliases": [
        "2D image topology"
      ],
      "description": "The spatial arrangement of pixels in a two-dimensional image.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "masked patch prediction",
      "type": "method",
      "documents": [
        "reformer",
        "vision_transformer"
      ],
      "mentions": 2,
      "aliases": [
        "masked patch prediction"
      ],
      "description": "A self-supervised learning task that involves predicting missing parts of an image.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LLaVA",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "LLaVA"
      ],
      "description": "Large Language and Vision Assistant, an end-to-end trained large multimodal model.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Vicuna",
      "type": "model",
      "documents": [
        "segment_anything",
        "segment_anything"
      ],
      "mentions": 2,
      "aliases": [
        "Vicuna",
        "Vicuna-v0"
      ],
      "description": "Language decoder connected to the visual encoder in LLaVA.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Science QA",
      "type": "dataset",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "Science QA"
      ],
      "description": "A multimodal reasoning dataset used for evaluating LLaVA.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LLaVA-Bench",
      "type": "benchmark",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "LLaVA-Bench"
      ],
      "description": "A set of two challenging benchmarks for evaluating multimodal instruction-following.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ChatGPT",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "ChatGPT"
      ],
      "description": "A conversational AI model developed by OpenAI, demonstrating the power of aligned LLMs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Alpaca",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "Alpaca"
      ],
      "description": "An open-source LLM that matches the performance of GPT-3.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "InstructPix2Pix",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "InstructPix2Pix"
      ],
      "description": "An image editing model that follows human instructions.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Flamingo",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "Flamingo"
      ],
      "description": "A multimodal model known for strong performance on zero-shot task transfer.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BLIP-2",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "BLIP-2"
      ],
      "description": "A model trained on image-text pairs for multimodal tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "FROMAGe",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "FROMAGe"
      ],
      "description": "A model for multimodal tasks, trained on image-text pairs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "KOSMOS-1",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "KOSMOS-1"
      ],
      "description": "A multimodal model trained on image-text pairs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "PaLM-E",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "PaLM-E"
      ],
      "description": "A large multimodal model for embodied AI.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "OpenFlamingo",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "OpenFlamingo"
      ],
      "description": "An open-source effort enabling LLaMA to use image inputs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LangChain",
      "type": "framework",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "LangChain"
      ],
      "description": "A system that coordinates various models via LLMs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Visual ChatGPT",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "Visual ChatGPT"
      ],
      "description": "A multimodal model that integrates visual and language capabilities.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "X-GPT",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "X-GPT"
      ],
      "description": "A multimodal model that integrates visual and language capabilities.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MM-REACT",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "MM-REACT"
      ],
      "description": "A multimodal model that integrates visual and language capabilities.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "VisProg",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "VisProg"
      ],
      "description": "A multimodal model that integrates visual and language capabilities.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ViperGPT",
      "type": "model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "ViperGPT"
      ],
      "description": "A multimodal model that integrates visual and language capabilities.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LMM",
      "type": "Technology",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "LMM"
      ],
      "description": "Large Multimodal Model used for zero-shot task transfer and in-context learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LLaMA-Adapter",
      "type": "Model",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "LLaMA-Adapter"
      ],
      "description": "An open-source adaptation of LLaMA for image inputs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "visual instruction tuning",
      "type": "Method",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "visual instruction tuning"
      ],
      "description": "A method aimed at improving model instruction-following abilities.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "visual prompt tuning",
      "type": "Method",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "visual prompt tuning"
      ],
      "description": "A method aimed at improving parameter efficiency in model adaptation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "COCO",
      "type": "Dataset",
      "documents": [
        "segment_anything",
        "swin_transformer"
      ],
      "mentions": 2,
      "aliases": [
        "COCO"
      ],
      "description": "A dataset used for generating instruction-following data.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "CC",
      "type": "Dataset",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "CC"
      ],
      "description": "A public multimodal dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LAION",
      "type": "Dataset",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "LAION"
      ],
      "description": "Another public multimodal dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "image-text pairs",
      "type": "Data Type",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "image-text pairs"
      ],
      "description": "Data consisting of images and their corresponding textual descriptions.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "visual feature Z",
      "type": "data",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "visual feature Z"
      ],
      "description": "The output feature representation from the visual encoder.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "language embedding tokens H",
      "type": "data",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "language embedding tokens H"
      ],
      "description": "Tokens representing language embeddings in the model.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "projection matrix W",
      "type": "method",
      "documents": [
        "segment_anything",
        "segment_anything"
      ],
      "mentions": 2,
      "aliases": [
        "projection matrix W",
        "projection matrix"
      ],
      "description": "A trainable matrix used to convert visual features into language embedding tokens.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "CC3M",
      "type": "dataset",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "CC3M"
      ],
      "description": "A dataset containing image-text pairs used for training.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "multi-turn conversation data",
      "type": "data",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "multi-turn conversation data"
      ],
      "description": "Data format used for training the model with multiple conversational turns.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "instruction tokens X",
      "type": "data",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "instruction tokens X"
      ],
      "description": "Tokens representing instructions given to the model.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "assistant answers X",
      "type": "data",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "assistant answers X"
      ],
      "description": "Tokens representing the responses generated by the assistant.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LLM",
      "type": "technology",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "LLM"
      ],
      "description": "Large Language Model used in conjunction with visual encoders.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "visual encoder",
      "type": "architecture",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "visual encoder"
      ],
      "description": "A component that processes visual inputs.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ScienceQA",
      "type": "dataset",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "ScienceQA"
      ],
      "description": "A large-scale multimodal science question dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LLaVA-Instruct-158K",
      "type": "dataset",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "LLaVA-Instruct-158K"
      ],
      "description": "A dataset used for fine-tuning LLaVA.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "A100",
      "type": "hardware",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "A100"
      ],
      "description": "NVIDIA A100 GPUs used for training the models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "instruction-following capability",
      "type": "metric",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "instruction-following capability"
      ],
      "description": "A measure of how well the model follows user instructions.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "training data",
      "type": "method",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "training data"
      ],
      "description": "Data organized as single-turn conversations for training.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "evaluation metric",
      "type": "metric",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "evaluation metric"
      ],
      "description": "A quantitative measure to assess model performance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "COCO-Val-2014",
      "type": "dataset",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "COCO-Val-2014"
      ],
      "description": "A dataset used to generate questions for evaluating models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MM-CoT",
      "type": "method",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "MM-CoT"
      ],
      "description": "Multimodal chain-of-thought method used as a state-of-the-art approach on the ScienceQA dataset.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "mean±std",
      "type": "metric",
      "documents": [
        "segment_anything"
      ],
      "mentions": 1,
      "aliases": [
        "mean±std"
      ],
      "description": "Statistical representation of model performance results.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Swin Transformer",
      "type": "architecture",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Swin Transformer"
      ],
      "description": "A hierarchical vision transformer designed for computer vision tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Microsoft Research Asia",
      "type": "organization",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Microsoft Research Asia"
      ],
      "description": "The organization where the authors of the paper are affiliated.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Ze Liu",
      "type": "person",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Ze Liu"
      ],
      "description": "One of the authors of the paper.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Yutong Lin",
      "type": "person",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Yutong Lin"
      ],
      "description": "One of the authors of the paper.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Yue Cao",
      "type": "person",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Yue Cao"
      ],
      "description": "One of the authors of the paper.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Han Hu",
      "type": "person",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Han Hu"
      ],
      "description": "One of the authors of the paper.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Yixuan Wei",
      "type": "person",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Yixuan Wei"
      ],
      "description": "One of the authors of the paper.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Zheng Zhang",
      "type": "person",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Zheng Zhang"
      ],
      "description": "One of the authors of the paper.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Stephen Lin",
      "type": "person",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Stephen Lin"
      ],
      "description": "One of the authors of the paper.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Baining Guo",
      "type": "person",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Baining Guo"
      ],
      "description": "One of the authors of the paper.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ADE20K",
      "type": "dataset",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "ADE20K"
      ],
      "description": "A dataset used for semantic segmentation tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "feature pyramid networks (FPN)",
      "type": "method",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "feature pyramid networks (FPN)"
      ],
      "description": "A technique for dense predictions in computer vision.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "U-Net",
      "type": "method",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "U-Net"
      ],
      "description": "A convolutional network architecture for semantic segmentation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ViT/DeiT",
      "type": "architecture",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "ViT/DeiT"
      ],
      "description": "Previous vision transformer architectures that Swin Transformer outperforms.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Copy-paste",
      "type": "method",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Copy-paste"
      ],
      "description": "A technique used in object detection that Swin Transformer improves upon.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "DetectoRS",
      "type": "method",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "DetectoRS"
      ],
      "description": "A method for object detection that Swin Transformer surpasses.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "SETR",
      "type": "method",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "SETR"
      ],
      "description": "A method for semantic segmentation that Swin Transformer outperforms.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "mIoU",
      "type": "metric",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "mIoU"
      ],
      "description": "Mean Intersection over Union, a metric for evaluating segmentation tasks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "AlexNet",
      "type": "architecture",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "AlexNet"
      ],
      "description": "A pioneering CNN that popularized deep learning in computer vision.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "VGG",
      "type": "architecture",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "VGG"
      ],
      "description": "A deep CNN architecture known for its simplicity and depth.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "GoogleNet",
      "type": "architecture",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "GoogleNet"
      ],
      "description": "A CNN architecture that introduced the inception module.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "DenseNet",
      "type": "architecture",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "DenseNet"
      ],
      "description": "A CNN architecture that connects each layer to every other layer.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "HRNet",
      "type": "architecture",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "HRNet"
      ],
      "description": "High-Resolution Network for maintaining high-resolution representations.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ViT",
      "type": "architecture",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "ViT"
      ],
      "description": "Vision Transformer, a model that applies transformer architecture to image classification.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "patch merging",
      "type": "method",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "patch merging"
      ],
      "description": "A technique used in Swin Transformer to reduce the number of tokens.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "linear embedding",
      "type": "method",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "linear embedding"
      ],
      "description": "A process to project raw pixel values into an arbitrary dimension.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "DeiT",
      "type": "architecture",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "DeiT"
      ],
      "description": "Data-efficient image Transformers, which introduces training strategies for ViT.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MLP",
      "type": "method",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "MLP"
      ],
      "description": "Multi-layer perceptron, a type of neural network.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "W-MSA",
      "type": "module",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "W-MSA"
      ],
      "description": "Window-based multi-head self-attention module.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "SW-MSA",
      "type": "module",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "SW-MSA"
      ],
      "description": "Shifted window-based multi-head self-attention module.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Stage 1",
      "type": "process",
      "documents": [
        "swin_transformer",
        "swin_transformer",
        "swin_transformer",
        "swin_transformer"
      ],
      "mentions": 4,
      "aliases": [
        "Stage 3",
        "Stage 2",
        "Stage 1",
        "Stage 4"
      ],
      "description": "The first stage of the Swin Transformer architecture.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "RegNet",
      "type": "architecture",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "RegNet"
      ],
      "description": "A family of convolutional neural networks optimized through architecture search.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Relative Position Bias",
      "type": "method",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Relative Position Bias"
      ],
      "description": "A technique used in self-attention mechanisms to incorporate positional information.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Top-1 Accuracy",
      "type": "metric",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Top-1 Accuracy"
      ],
      "description": "A metric used to evaluate the performance of classification models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Batch Size",
      "type": "parameter",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Batch Size"
      ],
      "description": "The number of training examples utilized in one iteration.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Cyclic Shifting",
      "type": "method",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Cyclic Shifting"
      ],
      "description": "A technique proposed to improve batch computation efficiency in window partitioning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Swin-T",
      "type": "model variant",
      "documents": [
        "swin_transformer",
        "swin_transformer",
        "swin_transformer",
        "swin_transformer"
      ],
      "mentions": 4,
      "aliases": [
        "Swin-T",
        "Swin-B",
        "Swin-S",
        "Swin-L"
      ],
      "description": "A variant of the Swin Transformer with specific hyperparameters.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Cascade Mask R-CNN",
      "type": "framework",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Cascade Mask R-CNN"
      ],
      "description": "An object detection framework used for instance segmentation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "ATSS",
      "type": "framework",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "ATSS"
      ],
      "description": "An object detection framework used for instance segmentation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "RepPoints v2",
      "type": "framework",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "RepPoints v2"
      ],
      "description": "An object detection framework used for instance segmentation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Sparse RCNN",
      "type": "framework",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Sparse RCNN"
      ],
      "description": "An object detection framework used for instance segmentation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "HTC++",
      "type": "Framework",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "HTC++"
      ],
      "description": "An improved version of the HTC framework for object detection.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "APbox",
      "type": "Metric",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "APbox"
      ],
      "description": "Average Precision for bounding box detection.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "APmask",
      "type": "Metric",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "APmask"
      ],
      "description": "Average Precision for mask prediction in instance segmentation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "DeiT-S",
      "type": "Model",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "DeiT-S"
      ],
      "description": "Data-efficient image Transformers, a model architecture for image classification.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "EfficientDet-D7",
      "type": "Model",
      "documents": [
        "swin_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "EfficientDet-D7"
      ],
      "description": "A model architecture for object detection that balances accuracy and efficiency.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LSTM",
      "type": "architecture",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "LSTM"
      ],
      "description": "Long Short-Term Memory networks, a standard solution for language modeling.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "RNN",
      "type": "architecture",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "RNN"
      ],
      "description": "Recurrent Neural Networks, a type of neural network for sequential data.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Carnegie Mellon University",
      "type": "organization",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Carnegie Mellon University"
      ],
      "description": "An academic institution where some authors are affiliated.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "WikiText-103",
      "type": "dataset",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "WikiText-103"
      ],
      "description": "A dataset used for language modeling.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "One Billion Word",
      "type": "dataset",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "One Billion Word"
      ],
      "description": "A large dataset for language modeling.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "context fragmentation",
      "type": "problem",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "context fragmentation"
      ],
      "description": "The issue of losing contextual information due to fixed-length segments.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "gradient vanishing",
      "type": "problem",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "gradient vanishing"
      ],
      "description": "A common issue in training RNNs that affects optimization.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "gradient explosion",
      "type": "problem",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "gradient explosion"
      ],
      "description": "A common issue in training RNNs that affects optimization.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Softmax function",
      "type": "function",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Softmax function"
      ],
      "description": "A function that converts logits into a categorical probability distribution.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Bengio et al. (2003)",
      "type": "publication",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Bengio et al. (2003)"
      ],
      "description": "A foundational paper in language modeling.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Mikolov et al. (2010)",
      "type": "publication",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Mikolov et al. (2010)"
      ],
      "description": "A significant work on RNNs and language modeling.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Merity et al. (2016)",
      "type": "publication",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Merity et al. (2016)"
      ],
      "description": "Research on language modeling techniques.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Galand Ghahramani (2016)",
      "type": "publication",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Galand Ghahramani (2016)"
      ],
      "description": "Work on improving optimization algorithms.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Grave et al. (2016a)",
      "type": "publication",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Grave et al. (2016a)"
      ],
      "description": "Research on speeding up Softmax computation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Yang et al. (2017)",
      "type": "publication",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Yang et al. (2017)"
      ],
      "description": "Work on enriching output distribution families.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Peters et al. (2018)",
      "type": "publication",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Peters et al. (2018)"
      ],
      "description": "Research on efficiency in language modeling.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Devlin et al. (2018)",
      "type": "publication",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Devlin et al. (2018)"
      ],
      "description": "Contributions to language modeling techniques.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "SG function",
      "type": "function",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "SG function"
      ],
      "description": "Stop-gradient function used to prevent gradient flow.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "positional encodings",
      "type": "concept",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "positional encodings"
      ],
      "description": "Encodings that provide sequence order information in Transformers.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "hidden state",
      "type": "concept",
      "documents": [
        "transformer_xl",
        "transformer_xl"
      ],
      "mentions": 2,
      "aliases": [
        "hidden states",
        "hidden state"
      ],
      "description": "The internal state representation in neural networks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "logits",
      "type": "concept",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "logits"
      ],
      "description": "Raw output scores from the model before applying Softmax.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "long-term dependency",
      "type": "concept",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "long-term dependency"
      ],
      "description": "The ability to model dependencies over long sequences.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "BPTT",
      "type": "method",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "BPTT"
      ],
      "description": "Backpropagation Through Time, a technique for training recurrent neural networks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "enwiki8",
      "type": "dataset",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "enwiki8"
      ],
      "description": "A dataset used for evaluating language models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "GPU memory",
      "type": "resource",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "GPU memory"
      ],
      "description": "Graphics Processing Unit memory used for storing data during model training and evaluation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "memory augmented neural networks",
      "type": "architecture",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "memory augmented neural networks"
      ],
      "description": "Neural networks that utilize external memory to enhance learning.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "attention score",
      "type": "metric",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "attention score"
      ],
      "description": "A score that determines the importance of different elements in a sequence.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "query vector",
      "type": "concept",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "query vector"
      ],
      "description": "A vector representing the current input in the attention mechanism.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "key vector",
      "type": "concept",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "key vector"
      ],
      "description": "A vector used in the attention mechanism to determine relevance.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "content-based addressing",
      "type": "method",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "content-based addressing"
      ],
      "description": "A method of addressing memory based on the content of the input.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "location-based key vectors",
      "type": "concept",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "location-based key vectors"
      ],
      "description": "Key vectors that are influenced by the position of the input.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Shaw et al. (2018)",
      "type": "publication",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Shaw et al. (2018)"
      ],
      "description": "A paper that explored relative positional encodings in machine translation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Huang et al. (2018)",
      "type": "publication",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Huang et al. (2018)"
      ],
      "description": "A paper that applied relative positional encodings in music generation.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Masked-Softmax",
      "type": "method",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Masked-Softmax"
      ],
      "description": "A variant of the softmax function used in attention mechanisms.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "LayerNorm",
      "type": "method",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "LayerNorm"
      ],
      "description": "A normalization technique applied to layers in neural networks.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Positionwise-Feed-Forward",
      "type": "method",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Positionwise-Feed-Forward"
      ],
      "description": "A feed-forward neural network applied independently to each position in the input.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "absolute positional embedding",
      "type": "concept",
      "documents": [
        "transformer_xl",
        "transformer_xl"
      ],
      "mentions": 2,
      "aliases": [
        "absolute positional embedding",
        "relative positional embedding"
      ],
      "description": "A method for encoding the position of tokens in a sequence.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "u",
      "type": "parameter",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "u"
      ],
      "description": "A trainable parameter introduced to replace the query vector in the attention mechanism.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "v",
      "type": "parameter",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "v"
      ],
      "description": "A trainable parameter added to substitute the query vector in the attention mechanism.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "bits per character (bpc)",
      "type": "metric",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "bits per character (bpc)"
      ],
      "description": "A metric used to evaluate language models based on the number of bits needed to encode characters.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Baevski and Auli",
      "type": "people",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Baevski and Auli"
      ],
      "description": "Researchers who contributed to the development of adaptive input representations.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Grave et al. (2016)",
      "type": "citation",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Grave et al. (2016)"
      ],
      "description": "Authors of a paper discussing neural cache mechanisms.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Dauphin et al. (2016)",
      "type": "citation",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Dauphin et al. (2016)"
      ],
      "description": "Authors of a paper discussing GCNN architectures.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "AWD-LSTM",
      "type": "architecture",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "AWD-LSTM"
      ],
      "description": "A type of LSTM model that incorporates dropout and weight averaging.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "MoS",
      "type": "architecture",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "MoS"
      ],
      "description": "A method proposed by Yang et al. for fine-tuning models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Khandelwal et al. (2018)",
      "type": "person",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Khandelwal et al. (2018)"
      ],
      "description": "Proposed a method to evaluate Effective Context Length (ECL).",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Effective Context Length (ECL)",
      "type": "metric",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Effective Context Length (ECL)"
      ],
      "description": "The longest length to which increasing context span leads to performance gain.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Relative Effective Context Length (RECL)",
      "type": "metric",
      "documents": [
        "transformer_xl"
      ],
      "mentions": 1,
      "aliases": [
        "Relative Effective Context Length (RECL)"
      ],
      "description": "A metric to measure the relative improvement of context length in models.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Layer Normalization (LN)",
      "type": "Technique",
      "documents": [
        "vision_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Layer Normalization (LN)"
      ],
      "description": "A technique applied before every block in the Transformer encoder.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Residual Connections",
      "type": "Technique",
      "documents": [
        "vision_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Residual Connections"
      ],
      "description": "Connections added after every block in the Transformer encoder.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Self-Supervision",
      "type": "Learning Method",
      "documents": [
        "vision_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Self-Supervision"
      ],
      "description": "A method explored for training the Vision Transformer.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "R50x1",
      "type": "model",
      "documents": [
        "vision_transformer",
        "vision_transformer"
      ],
      "mentions": 2,
      "aliases": [
        "R50x1",
        "R50x2"
      ],
      "description": "ResNet model variant",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "R101x1",
      "type": "model",
      "documents": [
        "vision_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "R101x1"
      ],
      "description": "ResNet model variant",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "R152x1",
      "type": "model",
      "documents": [
        "vision_transformer",
        "vision_transformer"
      ],
      "mentions": 2,
      "aliases": [
        "R152x1",
        "R152x2"
      ],
      "description": "ResNet model variant",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "R200x3",
      "type": "model",
      "documents": [
        "vision_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "R200x3"
      ],
      "description": "ResNet model variant",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "hybrids",
      "type": "architecture",
      "documents": [
        "vision_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "hybrids"
      ],
      "description": "Combination of ResNet and Vision Transformer architectures",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "position embeddings",
      "type": "concept",
      "documents": [
        "vision_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "position embeddings"
      ],
      "description": "Learned representations that encode the spatial information of image patches.",
      "pagerank": 0,
      "centrality": 0
    },
    {
      "id": "Google",
      "type": "organization",
      "documents": [
        "vision_transformer"
      ],
      "mentions": 1,
      "aliases": [
        "Google"
      ],
      "description": "The organization where the research was conducted.",
      "pagerank": 0,
      "centrality": 0
    }
  ],
  "edges": [
    {
      "source": "Transformer",
      "target": "Attention Mechanism",
      "relations": [
        "based_on"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Transformer",
      "target": "BLEU",
      "relations": [
        "improves"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 0.9
    },
    {
      "source": "Transformer",
      "target": "WMT 2014 English-to-German",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Transformer",
      "target": "WMT 2014 English-to-French",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Transformer",
      "target": "Self-Attention",
      "relations": [
        "is_based_on"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 0.95
    },
    {
      "source": "Google Brain",
      "target": "Ashish Vaswani",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Google Brain",
      "target": "Noam Shazeer",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Google Brain",
      "target": "Niki Parmar",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Google Brain",
      "target": "Jakob Uszkoreit",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Google Brain",
      "target": "Llion Jones",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Google Brain",
      "target": "Aidan N. Gomez",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Google Brain",
      "target": "Łukasz Kaiser",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Google Brain",
      "target": "Illia Polosukhin",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Google Research",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "authored"
      ],
      "mentions": 2,
      "sources": [
        "deit",
        "vision_transformer"
      ],
      "confidence": 0.95
    },
    {
      "source": "Google Research",
      "target": "PaLM",
      "relations": [
        "developed"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 0.9
    },
    {
      "source": "Jakob Uszkoreit",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is a co-author of"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.95
    },
    {
      "source": "Encoder",
      "target": "Multi-Head Attention",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Decoder",
      "target": "Multi-Head Attention",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Multi-Head Attention",
      "target": "Attention Function",
      "relations": [
        "is_a"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Scaled Dot-Product Attention",
      "target": "Attention Function",
      "relations": [
        "is_a"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Residual Connection",
      "target": "Encoder",
      "relations": [
        "is_used_in"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Residual Connection",
      "target": "Decoder",
      "relations": [
        "is_used_in"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Layer Normalization",
      "target": "Encoder",
      "relations": [
        "is_used_in"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Layer Normalization",
      "target": "Decoder",
      "relations": [
        "is_used_in"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Feed-Forward Network",
      "target": "Encoder",
      "relations": [
        "is_used_in"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Feed-Forward Network",
      "target": "Decoder",
      "relations": [
        "is_used_in"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Softmax Function",
      "target": "Decoder",
      "relations": [
        "is_used_in"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 1.0
    },
    {
      "source": "Self-Attention",
      "target": "Transformer",
      "relations": [
        "is_used_in"
      ],
      "mentions": 1,
      "sources": [
        "reformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Positional Encoding",
      "target": "Transformer",
      "relations": [
        "is_used_in"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 0.95
    },
    {
      "source": "Positional Encoding",
      "target": "Transformer-XL",
      "relations": [
        "is used in"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.9
    },
    {
      "source": "Positional Encoding",
      "target": "Positional Encoding",
      "relations": [
        "extends"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.9
    },
    {
      "source": "Penn Treebank",
      "target": "Wall Street Journal",
      "relations": [
        "contains"
      ],
      "mentions": 1,
      "sources": [
        "attention_is_all_you_need"
      ],
      "confidence": 0.9
    },
    {
      "source": "CLIP",
      "target": "zero-shot transfer",
      "relations": [
        "achieves"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.9
    },
    {
      "source": "CLIP",
      "target": "WIT",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.9
    },
    {
      "source": "CLIP",
      "target": "zero-shot learning",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.9
    },
    {
      "source": "CLIP",
      "target": "cross_entropy_loss",
      "relations": [
        "is_trained_with"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.9
    },
    {
      "source": "CLIP",
      "target": "ImageNet",
      "relations": [
        "improves"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.9
    },
    {
      "source": "CLIP",
      "target": "ResNet-50",
      "relations": [
        "matches_performance_of"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.8
    },
    {
      "source": "CLIP",
      "target": "Visual N-Grams",
      "relations": [
        "outperforms"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.9
    },
    {
      "source": "CLIP",
      "target": "YFCC100M",
      "relations": [
        "trained_on"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.8
    },
    {
      "source": "CLIP",
      "target": "Yahoo",
      "relations": [
        "reduces_errors_on"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.9
    },
    {
      "source": "CLIP",
      "target": "SUN",
      "relations": [
        "doubles_accuracy_on"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.85
    },
    {
      "source": "CLIP",
      "target": "visual feature Z",
      "relations": [
        "provides"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.9
    },
    {
      "source": "GPT-3",
      "target": "OpenAI",
      "relations": [
        "developed_by"
      ],
      "mentions": 2,
      "sources": [
        "gpt3_language_models",
        "gpt3"
      ],
      "confidence": 1.0
    },
    {
      "source": "GPT-3",
      "target": "few-shot learning",
      "relations": [
        "applies_to"
      ],
      "mentions": 2,
      "sources": [
        "gpt3_language_models",
        "gpt3"
      ],
      "confidence": 1.0
    },
    {
      "source": "GPT-3",
      "target": "translation",
      "relations": [
        "achieves_performance_on"
      ],
      "mentions": 2,
      "sources": [
        "gpt3_language_models",
        "gpt3"
      ],
      "confidence": 0.9
    },
    {
      "source": "GPT-3",
      "target": "question-answering",
      "relations": [
        "achieves_performance_on"
      ],
      "mentions": 2,
      "sources": [
        "gpt3_language_models",
        "gpt3"
      ],
      "confidence": 0.9
    },
    {
      "source": "GPT-3",
      "target": "cloze tasks",
      "relations": [
        "achieves_performance_on"
      ],
      "mentions": 2,
      "sources": [
        "gpt3_language_models",
        "gpt3"
      ],
      "confidence": 0.9
    },
    {
      "source": "GPT-3",
      "target": "Natural Questions",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 2,
      "sources": [
        "gpt3_language_models",
        "gpt3"
      ],
      "confidence": 0.9
    },
    {
      "source": "GPT-3",
      "target": "CoQA",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 2,
      "sources": [
        "gpt3_language_models",
        "gpt3"
      ],
      "confidence": 0.9
    },
    {
      "source": "GPT-3",
      "target": "TriviaQA",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 2,
      "sources": [
        "gpt3_language_models",
        "gpt3"
      ],
      "confidence": 0.9
    },
    {
      "source": "GPT-3",
      "target": "in-context learning",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "gpt3_language_models"
      ],
      "confidence": 0.95
    },
    {
      "source": "GPT-3",
      "target": "V100 GPU",
      "relations": [
        "uses"
      ],
      "mentions": 2,
      "sources": [
        "gpt3_language_models",
        "gpt3"
      ],
      "confidence": 0.9
    },
    {
      "source": "GPT-3",
      "target": "task-specific fine-tuning",
      "relations": [
        "requires"
      ],
      "mentions": 1,
      "sources": [
        "gpt3"
      ],
      "confidence": 0.8
    },
    {
      "source": "GPT-3",
      "target": "CommonCrawl",
      "relations": [
        "is trained on"
      ],
      "mentions": 1,
      "sources": [
        "gpt3"
      ],
      "confidence": 0.8
    },
    {
      "source": "GPT-3",
      "target": "Common Crawl",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "gpt3"
      ],
      "confidence": 0.9
    },
    {
      "source": "GPT-3",
      "target": "WebText",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "gpt3"
      ],
      "confidence": 0.85
    },
    {
      "source": "GPT-3",
      "target": "Books1",
      "relations": [
        "uses"
      ],
      "mentions": 2,
      "sources": [
        "gpt3",
        "gpt3"
      ],
      "confidence": 0.85
    },
    {
      "source": "GPT-3",
      "target": "Wikipedia",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "gpt3"
      ],
      "confidence": 0.85
    },
    {
      "source": "GPT-3",
      "target": "LLaMA-I",
      "relations": [
        "is_compared_with"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "ImageNet",
      "target": "ImageNet-21k",
      "relations": [
        "is_a_subset_of"
      ],
      "mentions": 2,
      "sources": [
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "ImageNet",
      "target": "fine-tuning",
      "relations": [
        "used_for"
      ],
      "mentions": 1,
      "sources": [
        "vision_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "ResNet-50",
      "target": "CLIP",
      "relations": [
        "matches accuracy of"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.85
    },
    {
      "source": "OpenAI",
      "target": "CLIP",
      "relations": [
        "developed"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.9
    },
    {
      "source": "OpenAI",
      "target": "Johns Hopkins University",
      "relations": [
        "associated_with"
      ],
      "mentions": 1,
      "sources": [
        "gpt3"
      ],
      "confidence": 0.7
    },
    {
      "source": "OpenAI",
      "target": "GPT-3",
      "relations": [
        "developed"
      ],
      "mentions": 1,
      "sources": [
        "gpt3"
      ],
      "confidence": 0.9
    },
    {
      "source": "zero-shot transfer",
      "target": "meta-learning",
      "relations": [
        "is_a"
      ],
      "mentions": 1,
      "sources": [
        "gpt3_language_models"
      ],
      "confidence": 0.9
    },
    {
      "source": "EfficientNet",
      "target": "ResNet-101",
      "relations": [
        "is_related_to"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.6
    },
    {
      "source": "WebText",
      "target": "Common Crawl",
      "relations": [
        "augments"
      ],
      "mentions": 1,
      "sources": [
        "gpt3_language_models"
      ],
      "confidence": 0.85
    },
    {
      "source": "ResNet-101",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is compared_with",
        "is_compared_with"
      ],
      "mentions": 2,
      "sources": [
        "deit",
        "reformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "ResNet-101",
      "target": "ViT",
      "relations": [
        "is_used_as_baseline_for"
      ],
      "mentions": 1,
      "sources": [
        "reformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "ResNet-101",
      "target": "Transformer",
      "relations": [
        "applies_before"
      ],
      "mentions": 1,
      "sources": [
        "vision_transformer"
      ],
      "confidence": 0.7
    },
    {
      "source": "Vision Transformer (ViT)",
      "target": "Transformer",
      "relations": [
        "is based_on",
        "is_based_on"
      ],
      "mentions": 2,
      "sources": [
        "deit",
        "reformer"
      ],
      "confidence": 0.95
    },
    {
      "source": "Vision Transformer (ViT)",
      "target": "ImageNet-21k",
      "relations": [
        "is trained_on",
        "is_pretrained_on"
      ],
      "mentions": 3,
      "sources": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "Vision Transformer (ViT)",
      "target": "JFT-300M",
      "relations": [
        "is trained_on",
        "is_pretrained_on"
      ],
      "mentions": 3,
      "sources": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "Vision Transformer (ViT)",
      "target": "ImageNet",
      "relations": [
        "is evaluated_on"
      ],
      "mentions": 2,
      "sources": [
        "deit",
        "vision_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Vision Transformer (ViT)",
      "target": "CIFAR-10",
      "relations": [
        "is evaluated_on"
      ],
      "mentions": 2,
      "sources": [
        "deit",
        "vision_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Vision Transformer (ViT)",
      "target": "VTAB",
      "relations": [
        "is evaluated_on"
      ],
      "mentions": 2,
      "sources": [
        "deit",
        "vision_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Vision Transformer (ViT)",
      "target": "Transformer Encoder",
      "relations": [
        "is_based_on"
      ],
      "mentions": 3,
      "sources": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Vision Transformer (ViT)",
      "target": "MLP Head",
      "relations": [
        "uses"
      ],
      "mentions": 3,
      "sources": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Vision Transformer (ViT)",
      "target": "ResNet-101",
      "relations": [
        "is_compared_with"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.8
    },
    {
      "source": "Vision Transformer (ViT)",
      "target": "self-attention",
      "relations": [
        "uses"
      ],
      "mentions": 3,
      "sources": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Vision Transformer (ViT)",
      "target": "Transformers",
      "relations": [
        "is based_on"
      ],
      "mentions": 1,
      "sources": [
        "vision_transformer"
      ],
      "confidence": 0.95
    },
    {
      "source": "Visual N-Grams",
      "target": "CLIP",
      "relations": [
        "compares_to"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.85
    },
    {
      "source": "Visual N-Grams",
      "target": "Elhoseiny et al. (2013)",
      "relations": [
        "dates_back_to"
      ],
      "mentions": 1,
      "sources": [
        "clip"
      ],
      "confidence": 0.7
    },
    {
      "source": "Alexey Dosovitskiy",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is a co-author of"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.95
    },
    {
      "source": "Lucas Beyer",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is a co-author of"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.95
    },
    {
      "source": "Alexander Kolesnikov",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is a co-author of"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.95
    },
    {
      "source": "Dirk Weissenborn",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is a co-author of"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.95
    },
    {
      "source": "Xiaohua Zhai",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is a co-author of"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.95
    },
    {
      "source": "Thomas Unterthiner",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is a co-author of"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.95
    },
    {
      "source": "Mostafa Dehghani",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is a co-author of"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.95
    },
    {
      "source": "Matthias Minderer",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is a co-author of"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.95
    },
    {
      "source": "Georg Heigold",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is a co-author of"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.95
    },
    {
      "source": "Sylvain Gelly",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is a co-author of"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.95
    },
    {
      "source": "Neil Houlsby",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is a co-author of"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.95
    },
    {
      "source": "ImageNet-21k",
      "target": "ILSVRC-2012 ImageNet",
      "relations": [
        "is_a_superset_of"
      ],
      "mentions": 2,
      "sources": [
        "deit",
        "vision_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "ImageNet-21k",
      "target": "ImageNet",
      "relations": [
        "is_a_superset_of"
      ],
      "mentions": 2,
      "sources": [
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "ImageNet-21k",
      "target": "pre-training",
      "relations": [
        "used_for"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.95
    },
    {
      "source": "Transformer Encoder",
      "target": "Vaswani et al. (2017)",
      "relations": [
        "is_inspired_by"
      ],
      "mentions": 1,
      "sources": [
        "reformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Position Embeddings",
      "target": "Longformer",
      "relations": [
        "supports"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "Self-Supervised Learning",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is_used_in",
        "is_applied_to"
      ],
      "mentions": 2,
      "sources": [
        "deit",
        "reformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "Vaswani et al. (2017)",
      "target": "Transformer architecture",
      "relations": [
        "introduces",
        "proposed",
        "introduced"
      ],
      "mentions": 5,
      "sources": [
        "deit",
        "transformer_xl",
        "transformer_xl",
        "transformer_xl",
        "vision_transformer"
      ],
      "confidence": 0.95
    },
    {
      "source": "ILSVRC-2012 ImageNet",
      "target": "ImageNet-21k",
      "relations": [
        "is_a_subset_of"
      ],
      "mentions": 3,
      "sources": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "ViT-Base",
      "target": "BERT",
      "relations": [
        "is_based_on"
      ],
      "mentions": 3,
      "sources": [
        "deit",
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "ViT-Large",
      "target": "BERT",
      "relations": [
        "is_based_on"
      ],
      "mentions": 6,
      "sources": [
        "deit",
        "deit",
        "reformer",
        "reformer",
        "vision_transformer",
        "vision_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "SGD",
      "target": "fine-tuning",
      "relations": [
        "is_used_for"
      ],
      "mentions": 2,
      "sources": [
        "deit",
        "reformer"
      ],
      "confidence": 0.95
    },
    {
      "source": "Noisy Student",
      "target": "ViT-H/14",
      "relations": [
        "is_compared_with",
        "is_compared_to"
      ],
      "mentions": 2,
      "sources": [
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "Big Transfer (BiT)",
      "target": "ViT-H/14",
      "relations": [
        "is_compared_with",
        "is_compared_to"
      ],
      "mentions": 2,
      "sources": [
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "ViT-L/16",
      "target": "Big Transfer (BiT)",
      "relations": [
        "compares_to"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.9
    },
    {
      "source": "ViT-L/16",
      "target": "ImageNet-21k",
      "relations": [
        "pre_trained_on",
        "is_pretrained_on"
      ],
      "mentions": 4,
      "sources": [
        "deit",
        "reformer",
        "vision_transformer",
        "vision_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "ViT-L/16",
      "target": "TPUv3",
      "relations": [
        "trained_using"
      ],
      "mentions": 2,
      "sources": [
        "deit",
        "reformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "ViT-L/16",
      "target": "JFT-300M",
      "relations": [
        "is_pretrained_on"
      ],
      "mentions": 1,
      "sources": [
        "vision_transformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "ViT-L/16",
      "target": "VTAB",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "vision_transformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "BiT",
      "target": "ViT",
      "relations": [
        "compared_to"
      ],
      "mentions": 2,
      "sources": [
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.75
    },
    {
      "source": "ViT-H/14",
      "target": "Noisy Student",
      "relations": [
        "compares_to"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.9
    },
    {
      "source": "ViT-H/14",
      "target": "BiT",
      "relations": [
        "outperforms"
      ],
      "mentions": 1,
      "sources": [
        "reformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Hybrid models",
      "target": "ViT",
      "relations": [
        "outperform"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.6
    },
    {
      "source": "self-attention",
      "target": "Swin Transformer",
      "relations": [
        "is_used_in"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 1.0
    },
    {
      "source": "CNN",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is_compared_with"
      ],
      "mentions": 1,
      "sources": [
        "reformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "self-supervised pre-training",
      "target": "accuracy",
      "relations": [
        "improves"
      ],
      "mentions": 1,
      "sources": [
        "vision_transformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "NLP",
      "target": "language tasks",
      "relations": [
        "contains"
      ],
      "mentions": 1,
      "sources": [
        "gpt3_language_models"
      ],
      "confidence": 0.9
    },
    {
      "source": "NLP",
      "target": "few-shot learning",
      "relations": [
        "contains"
      ],
      "mentions": 1,
      "sources": [
        "gpt3"
      ],
      "confidence": 1.0
    },
    {
      "source": "few-shot learning",
      "target": "meta-learning",
      "relations": [
        "is_a"
      ],
      "mentions": 2,
      "sources": [
        "gpt3_language_models",
        "gpt3_language_models"
      ],
      "confidence": 0.9
    },
    {
      "source": "pre-training",
      "target": "fine-tuning",
      "relations": [
        "followed_by"
      ],
      "mentions": 1,
      "sources": [
        "gpt3_language_models"
      ],
      "confidence": 0.9
    },
    {
      "source": "pre-training",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is_applied_to"
      ],
      "mentions": 1,
      "sources": [
        "reformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "fine-tuning",
      "target": "Vision Transformer (ViT)",
      "relations": [
        "is_applied_to"
      ],
      "mentions": 1,
      "sources": [
        "reformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "Common Crawl",
      "target": "GPT-3",
      "relations": [
        "used_for_training"
      ],
      "mentions": 1,
      "sources": [
        "gpt3_language_models"
      ],
      "confidence": 0.95
    },
    {
      "source": "societal impacts",
      "target": "GPT-3",
      "relations": [
        "discussed_in"
      ],
      "mentions": 1,
      "sources": [
        "gpt3_language_models"
      ],
      "confidence": 0.9
    },
    {
      "source": "in-context learning",
      "target": "meta-learning",
      "relations": [
        "is_a"
      ],
      "mentions": 2,
      "sources": [
        "gpt3_language_models",
        "gpt3"
      ],
      "confidence": 0.95
    },
    {
      "source": "RWC+19",
      "target": "in-context learning",
      "relations": [
        "discusses"
      ],
      "mentions": 1,
      "sources": [
        "gpt3_language_models"
      ],
      "confidence": 0.8
    },
    {
      "source": "Books1",
      "target": "Common Crawl",
      "relations": [
        "augments"
      ],
      "mentions": 2,
      "sources": [
        "gpt3_language_models",
        "gpt3_language_models"
      ],
      "confidence": 0.85
    },
    {
      "source": "Wikipedia",
      "target": "Common Crawl",
      "relations": [
        "augments"
      ],
      "mentions": 1,
      "sources": [
        "gpt3_language_models"
      ],
      "confidence": 0.85
    },
    {
      "source": "Sparse Transformer",
      "target": "Transformer architecture",
      "relations": [
        "extends"
      ],
      "mentions": 1,
      "sources": [
        "gpt3_language_models"
      ],
      "confidence": 0.8
    },
    {
      "source": "Validation loss",
      "target": "GPT-3",
      "relations": [
        "is_measured_for"
      ],
      "mentions": 1,
      "sources": [
        "gpt3"
      ],
      "confidence": 0.9
    },
    {
      "source": "K",
      "target": "few-shot learning",
      "relations": [
        "is_used_in"
      ],
      "mentions": 1,
      "sources": [
        "gpt3"
      ],
      "confidence": 0.8
    },
    {
      "source": "LLaMA-I",
      "target": "GPT-3",
      "relations": [
        "outperforms",
        "compares_with"
      ],
      "mentions": 2,
      "sources": [
        "llama",
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "Chinchilla",
      "relations": [
        "is_competitive_with",
        "compares_with"
      ],
      "mentions": 2,
      "sources": [
        "llama",
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "PaLM",
      "relations": [
        "is_competitive_with",
        "compares_with"
      ],
      "mentions": 2,
      "sources": [
        "llama",
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "CommonCrawl",
      "relations": [
        "trained_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "C4",
      "relations": [
        "trained_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "Github",
      "relations": [
        "trained_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "Wikipedia",
      "relations": [
        "trained_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "Books",
      "relations": [
        "trained_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "ArXiv",
      "relations": [
        "trained_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "StackExchange",
      "relations": [
        "trained_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "Transformer Architecture",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "Performance Metrics",
      "relations": [
        "evaluated_by"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "Gopher",
      "relations": [
        "compares_with"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "OPT",
      "relations": [
        "compares_with"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "OPT-IML",
      "relations": [
        "compares_with"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.8
    },
    {
      "source": "LLaMA-I",
      "target": "LaMDA",
      "relations": [
        "compares_with"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.8
    },
    {
      "source": "LLaMA-I",
      "target": "Natural Questions",
      "relations": [
        "evaluates_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "TriviaQA",
      "relations": [
        "evaluates_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "MATH",
      "relations": [
        "evaluates_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "GSM8k",
      "relations": [
        "evaluates_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "RACE",
      "relations": [
        "evaluates_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "BoolQ",
      "relations": [
        "evaluates_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.8
    },
    {
      "source": "LLaMA-I",
      "target": "Flan-PaLM",
      "relations": [
        "evaluates_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.8
    },
    {
      "source": "LLaMA-I",
      "target": "Exact Match",
      "relations": [
        "achieves_performance"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-I",
      "target": "pass@",
      "relations": [
        "achieves_performance"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "Chinchilla",
      "target": "LLaMA-I",
      "relations": [
        "is_compared_with"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "PaLM",
      "target": "LLaMA-I",
      "relations": [
        "is_compared_with"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "PaLM",
      "target": "Transformer",
      "relations": [
        "is_based_on",
        "based_on"
      ],
      "mentions": 2,
      "sources": [
        "palm",
        "palm"
      ],
      "confidence": 0.95
    },
    {
      "source": "PaLM",
      "target": "Pathways",
      "relations": [
        "uses",
        "is based_on"
      ],
      "mentions": 2,
      "sources": [
        "palm",
        "palm"
      ],
      "confidence": 0.9
    },
    {
      "source": "PaLM",
      "target": "TPUv4",
      "relations": [
        "trained_on"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 0.9
    },
    {
      "source": "PaLM",
      "target": "GPT-3",
      "relations": [
        "outperforms"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 0.8
    },
    {
      "source": "PaLM",
      "target": "BIG-bench",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 0.9
    },
    {
      "source": "PaLM",
      "target": "SwiGLU",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 0.9
    },
    {
      "source": "PaLM",
      "target": "RoPE",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 0.9
    },
    {
      "source": "PaLM",
      "target": "SentencePiece",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 0.85
    },
    {
      "source": "PaLM",
      "target": "WinoGender",
      "relations": [
        "evaluates"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 0.8
    },
    {
      "source": "PaLM",
      "target": "540B parameters",
      "relations": [
        "has_model_scale"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 1.0
    },
    {
      "source": "PaLM",
      "target": "62B parameters",
      "relations": [
        "has_model_scale"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 1.0
    },
    {
      "source": "PaLM",
      "target": "8B parameters",
      "relations": [
        "has_model_scale"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 1.0
    },
    {
      "source": "PaLM",
      "target": "780 billion tokens",
      "relations": [
        "trained_on"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 1.0
    },
    {
      "source": "PaLM",
      "target": "JAX",
      "relations": [
        "trained_using"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 1.0
    },
    {
      "source": "PaLM",
      "target": "T5X",
      "relations": [
        "trained_using"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 1.0
    },
    {
      "source": "Transformer Architecture",
      "target": "Vaswani et al. (2017)",
      "relations": [
        "is_based_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "Gopher",
      "target": "LLaMA-I",
      "relations": [
        "is_compared_with"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "Gopher",
      "target": "GPT-3",
      "relations": [
        "outperforms"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.85
    },
    {
      "source": "LLaMA-65B",
      "target": "Chinchilla",
      "relations": [
        "outperforms"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-65B",
      "target": "PaLM",
      "relations": [
        "outperforms"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaMA-65B",
      "target": "RealToxicityPrompts",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.7
    },
    {
      "source": "Zhang et al. (2022)",
      "target": "Hoffmann et al. (2022)",
      "relations": [
        "cites"
      ],
      "mentions": 1,
      "sources": [
        "llama"
      ],
      "confidence": 0.8
    },
    {
      "source": "Perplexity",
      "target": "Transformer-XL",
      "relations": [
        "is reduced by"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.9
    },
    {
      "source": "Longformer",
      "target": "self-attention",
      "relations": [
        "improves"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Longformer",
      "target": "RoBERTa",
      "relations": [
        "outperforms",
        "improves",
        "is_based_on"
      ],
      "mentions": 3,
      "sources": [
        "longformer",
        "longformer",
        "longformer"
      ],
      "confidence": 0.95
    },
    {
      "source": "Longformer",
      "target": "text8",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Longformer",
      "target": "enwik8",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Longformer",
      "target": "WikiHop",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "Longformer",
      "target": "TriviaQA",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "Longformer",
      "target": "LED",
      "relations": [
        "used_in"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "Longformer",
      "target": "Transformer architecture",
      "relations": [
        "based_on"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Longformer",
      "target": "Sparse Transformer",
      "relations": [
        "compared_to"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "Longformer",
      "target": "Transformer",
      "relations": [
        "is_based_on"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.95
    },
    {
      "source": "Longformer",
      "target": "Attention Pattern",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "Longformer",
      "target": "Position Embeddings",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "Longformer",
      "target": "MLM",
      "relations": [
        "is_pretrained_with"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Longformer",
      "target": "BERT",
      "relations": [
        "compared_with"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "enwik8",
      "target": "text8",
      "relations": [
        "is compared with"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.7
    },
    {
      "source": "Transformer-XL",
      "target": "Longformer",
      "relations": [
        "compared_to"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.75
    },
    {
      "source": "Transformer-XL",
      "target": "long-term dependency",
      "relations": [
        "improves"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.9
    },
    {
      "source": "Transformer-XL",
      "target": "context fragmentation",
      "relations": [
        "resolves"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.85
    },
    {
      "source": "Transformer-XL",
      "target": "Positional Encoding",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.95
    },
    {
      "source": "Transformer-XL",
      "target": "Perplexity",
      "relations": [
        "improves"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.9
    },
    {
      "source": "Transformer-XL",
      "target": "AWD-LSTM",
      "relations": [
        "compared_with"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.85
    },
    {
      "source": "Transformer-XL",
      "target": "One Billion Word",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.8
    },
    {
      "source": "Transformer-XL",
      "target": "WikiText-103",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.8
    },
    {
      "source": "BlockSparse",
      "target": "TensorFlow",
      "relations": [
        "is_designed_for"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "LED",
      "target": "Longformer",
      "relations": [
        "is_a_variant_of"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.95
    },
    {
      "source": "CPC loss",
      "target": "pre-training",
      "relations": [
        "is_used_for"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "BigBird",
      "target": "ETC",
      "relations": [
        "is_an_extension_of"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Ye et al. (2019)",
      "target": "BP-Transformer",
      "relations": [
        "discusses"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "BERT",
      "target": "T5",
      "relations": [
        "is_related_to"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 0.7
    },
    {
      "source": "Adaptive Span",
      "target": "Longformer",
      "relations": [
        "compared_to"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.7
    },
    {
      "source": "Compressive Transformer",
      "target": "Longformer",
      "relations": [
        "compared_to"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.7
    },
    {
      "source": "Ott et al.",
      "target": "fairseq",
      "relations": [
        "developed"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Devlin et al.",
      "target": "BERT",
      "relations": [
        "developed"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Liu et al.",
      "target": "RoBERTa",
      "relations": [
        "developed"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Rae et al.",
      "target": "Compressive Transformer",
      "relations": [
        "discussed"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "Longformer-large",
      "target": "RoBERTa-large",
      "relations": [
        "improves"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Longformer-large",
      "target": "WikiHop",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.95
    },
    {
      "source": "Longformer-large",
      "target": "TriviaQA",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.95
    },
    {
      "source": "Longformer-large",
      "target": "HotpotQA",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.95
    },
    {
      "source": "Longformer-large",
      "target": "coreference resolution",
      "relations": [
        "used_for"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "OntoNotes",
      "target": "coreference resolution",
      "relations": [
        "used_for"
      ],
      "mentions": 1,
      "sources": [
        "longformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Transformer architecture",
      "target": "GPT-3",
      "relations": [
        "is used in"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 0.95
    },
    {
      "source": "780 billion tokens",
      "target": "GitHub",
      "relations": [
        "composed_of"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 1.0
    },
    {
      "source": "780 billion tokens",
      "target": "Wikipedia",
      "relations": [
        "composed_of"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 1.0
    },
    {
      "source": "Pathways system",
      "target": "TPU v4",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 0.9
    },
    {
      "source": "Pathways system",
      "target": "JAX/XLA",
      "relations": [
        "executes"
      ],
      "mentions": 1,
      "sources": [
        "palm"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaVA",
      "target": "GPT-3",
      "relations": [
        "is_based_on",
        "compared_to",
        "is evaluated by"
      ],
      "mentions": 3,
      "sources": [
        "segment_anything",
        "segment_anything",
        "segment_anything"
      ],
      "confidence": 1.0
    },
    {
      "source": "LLaVA",
      "target": "CLIP",
      "relations": [
        "connects",
        "uses"
      ],
      "mentions": 2,
      "sources": [
        "segment_anything",
        "segment_anything"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaVA",
      "target": "Vicuna",
      "relations": [
        "connects",
        "is based on"
      ],
      "mentions": 2,
      "sources": [
        "segment_anything",
        "segment_anything"
      ],
      "confidence": 0.8
    },
    {
      "source": "LLaVA",
      "target": "Science QA",
      "relations": [
        "is_evaluated_on",
        "is_fine_tuned_on"
      ],
      "mentions": 2,
      "sources": [
        "segment_anything",
        "segment_anything"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaVA",
      "target": "multi-turn conversation data",
      "relations": [
        "is trained on"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaVA",
      "target": "Flamingo",
      "relations": [
        "compares to"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.6
    },
    {
      "source": "LLaVA",
      "target": "BLIP-2",
      "relations": [
        "compares to",
        "compared_to",
        "compares_with"
      ],
      "mentions": 3,
      "sources": [
        "segment_anything",
        "segment_anything",
        "segment_anything"
      ],
      "confidence": 1.0
    },
    {
      "source": "LLaVA",
      "target": "OpenFlamingo",
      "relations": [
        "compared_to",
        "compares_with"
      ],
      "mentions": 2,
      "sources": [
        "segment_anything",
        "segment_anything"
      ],
      "confidence": 1.0
    },
    {
      "source": "LLaVA",
      "target": "LLaVA-Bench",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.95
    },
    {
      "source": "LLaVA",
      "target": "instruction-following capability",
      "relations": [
        "improves"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.9
    },
    {
      "source": "LLaVA-Bench",
      "target": "COCO-Val-2014",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.9
    },
    {
      "source": "BLIP-2",
      "target": "LMM",
      "relations": [
        "is_a"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.9
    },
    {
      "source": "FROMAGe",
      "target": "LMM",
      "relations": [
        "is_a"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.9
    },
    {
      "source": "KOSMOS-1",
      "target": "LMM",
      "relations": [
        "is_a"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.9
    },
    {
      "source": "PaLM-E",
      "target": "LMM",
      "relations": [
        "is_a"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.9
    },
    {
      "source": "OpenFlamingo",
      "target": "LLaMA-I",
      "relations": [
        "is_based_on"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.8
    },
    {
      "source": "LLaMA-Adapter",
      "target": "LLaMA-I",
      "relations": [
        "is_based_on"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.8
    },
    {
      "source": "visual feature Z",
      "target": "language embedding tokens H",
      "relations": [
        "is converted to"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.8
    },
    {
      "source": "projection matrix W",
      "target": "visual feature Z",
      "relations": [
        "connects"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.85
    },
    {
      "source": "multi-turn conversation data",
      "target": "instruction tokens X",
      "relations": [
        "contains"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.8
    },
    {
      "source": "multi-turn conversation data",
      "target": "assistant answers X",
      "relations": [
        "contains"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 0.8
    },
    {
      "source": "evaluation metric",
      "target": "instruction-following capability",
      "relations": [
        "measures"
      ],
      "mentions": 1,
      "sources": [
        "segment_anything"
      ],
      "confidence": 1.0
    },
    {
      "source": "Swin Transformer",
      "target": "ViT/DeiT",
      "relations": [
        "outperforms"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Swin Transformer",
      "target": "DetectoRS",
      "relations": [
        "outperforms"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Swin Transformer",
      "target": "SETR",
      "relations": [
        "outperforms"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Swin Transformer",
      "target": "ResNet-50",
      "relations": [
        "is similar to"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.75
    },
    {
      "source": "Swin Transformer",
      "target": "ResNet-101",
      "relations": [
        "is similar to"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.75
    },
    {
      "source": "Swin Transformer",
      "target": "ImageNet-21k",
      "relations": [
        "evaluated_on"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Swin Transformer",
      "target": "DeiT",
      "relations": [
        "compared_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Swin Transformer",
      "target": "EfficientNet",
      "relations": [
        "compared_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "Swin Transformer",
      "target": "RegNet",
      "relations": [
        "compared_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "Swin Transformer",
      "target": "AdamW",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Swin Transformer",
      "target": "Relative Position Bias",
      "relations": [
        "contains"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "Swin Transformer",
      "target": "Top-1 Accuracy",
      "relations": [
        "achieves"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Swin Transformer",
      "target": "FLOPs",
      "relations": [
        "has"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Swin Transformer",
      "target": "HTC++",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Microsoft Research Asia",
      "target": "Ze Liu",
      "relations": [
        "affiliated_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 1.0
    },
    {
      "source": "Microsoft Research Asia",
      "target": "Yutong Lin",
      "relations": [
        "affiliated_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 1.0
    },
    {
      "source": "Microsoft Research Asia",
      "target": "Yue Cao",
      "relations": [
        "affiliated_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 1.0
    },
    {
      "source": "Microsoft Research Asia",
      "target": "Han Hu",
      "relations": [
        "affiliated_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 1.0
    },
    {
      "source": "Microsoft Research Asia",
      "target": "Yixuan Wei",
      "relations": [
        "affiliated_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 1.0
    },
    {
      "source": "Microsoft Research Asia",
      "target": "Zheng Zhang",
      "relations": [
        "affiliated_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 1.0
    },
    {
      "source": "Microsoft Research Asia",
      "target": "Stephen Lin",
      "relations": [
        "affiliated_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 1.0
    },
    {
      "source": "Microsoft Research Asia",
      "target": "Baining Guo",
      "relations": [
        "affiliated_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 1.0
    },
    {
      "source": "feature pyramid networks (FPN)",
      "target": "Swin Transformer",
      "relations": [
        "is_used_in"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "U-Net",
      "target": "Swin Transformer",
      "relations": [
        "is_used_in"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "ViT",
      "target": "Transformer architecture",
      "relations": [
        "is based on"
      ],
      "mentions": 1,
      "sources": [
        "deit"
      ],
      "confidence": 0.95
    },
    {
      "source": "ViT",
      "target": "JFT-300M",
      "relations": [
        "pre_trained_on",
        "requires"
      ],
      "mentions": 3,
      "sources": [
        "reformer",
        "swin_transformer",
        "vision_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "ViT",
      "target": "weight decay",
      "relations": [
        "optimized_with"
      ],
      "mentions": 2,
      "sources": [
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.7
    },
    {
      "source": "ViT",
      "target": "dropout",
      "relations": [
        "optimized_with"
      ],
      "mentions": 2,
      "sources": [
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.7
    },
    {
      "source": "ViT",
      "target": "label smoothing",
      "relations": [
        "optimized_with"
      ],
      "mentions": 2,
      "sources": [
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.7
    },
    {
      "source": "Stage 1",
      "target": "Stage 1",
      "relations": [
        "is followed by"
      ],
      "mentions": 3,
      "sources": [
        "swin_transformer",
        "swin_transformer",
        "swin_transformer"
      ],
      "confidence": 0.95
    },
    {
      "source": "Swin-T",
      "target": "ImageNet-21k",
      "relations": [
        "fine-tuned_on"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.9
    },
    {
      "source": "Swin-T",
      "target": "ViT",
      "relations": [
        "compared_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "Swin-T",
      "target": "DeiT-S",
      "relations": [
        "compared_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "Cascade Mask R-CNN",
      "target": "Swin-T",
      "relations": [
        "used_with"
      ],
      "mentions": 1,
      "sources": [
        "swin_transformer"
      ],
      "confidence": 0.85
    },
    {
      "source": "LSTM",
      "target": "Transformer-XL",
      "relations": [
        "is compared to"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.8
    },
    {
      "source": "RNN",
      "target": "Transformer-XL",
      "relations": [
        "is compared to",
        "compared_to"
      ],
      "mentions": 2,
      "sources": [
        "transformer_xl",
        "transformer_xl"
      ],
      "confidence": 0.8
    },
    {
      "source": "SG function",
      "target": "Transformer-XL",
      "relations": [
        "is used in"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.85
    },
    {
      "source": "hidden state",
      "target": "Transformer-XL",
      "relations": [
        "are_cached_in"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.9
    },
    {
      "source": "long-term dependency",
      "target": "Transformer-XL",
      "relations": [
        "is modeled by"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.8
    },
    {
      "source": "BPTT",
      "target": "RNN",
      "relations": [
        "is_based_on"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.85
    },
    {
      "source": "query vector",
      "target": "key vector",
      "relations": [
        "attends_on"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.85
    },
    {
      "source": "Shaw et al. (2018)",
      "target": "Transformer-XL",
      "relations": [
        "compares_with"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.7
    },
    {
      "source": "Huang et al. (2018)",
      "target": "Positional Encoding",
      "relations": [
        "uses"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.75
    },
    {
      "source": "absolute positional embedding",
      "target": "absolute positional embedding",
      "relations": [
        "is replaced by"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.8
    },
    {
      "source": "u",
      "target": "query vector",
      "relations": [
        "replaces"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.85
    },
    {
      "source": "v",
      "target": "query vector",
      "relations": [
        "substitutes"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.85
    },
    {
      "source": "Khandelwal et al. (2018)",
      "target": "Effective Context Length (ECL)",
      "relations": [
        "proposed"
      ],
      "mentions": 1,
      "sources": [
        "transformer_xl"
      ],
      "confidence": 0.9
    },
    {
      "source": "Self-Supervision",
      "target": "Vision Transformer",
      "relations": [
        "is_explored_for"
      ],
      "mentions": 1,
      "sources": [
        "vision_transformer"
      ],
      "confidence": 0.8
    },
    {
      "source": "hybrids",
      "target": "ViT",
      "relations": [
        "outperform"
      ],
      "mentions": 2,
      "sources": [
        "reformer",
        "vision_transformer"
      ],
      "confidence": 0.6
    },
    {
      "source": "position embeddings",
      "target": "2D image topology",
      "relations": [
        "represent"
      ],
      "mentions": 1,
      "sources": [
        "vision_transformer"
      ],
      "confidence": 0.8
    }
  ],
  "statistics": {
    "num_nodes": 609,
    "num_edges": 304,
    "density": 0.0008210180623973727
  }
}