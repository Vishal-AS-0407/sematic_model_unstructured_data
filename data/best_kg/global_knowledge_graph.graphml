<?xml version='1.0' encoding='utf-8'?>
<graphml xmlns="http://graphml.graphdrawing.org/xmlns" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd"><key id="d11" for="edge" attr.name="confidence" attr.type="double"/>
<key id="d10" for="edge" attr.name="sources" attr.type="string"/>
<key id="d9" for="edge" attr.name="mentions" attr.type="long"/>
<key id="d8" for="edge" attr.name="relations" attr.type="string"/>
<key id="d7" for="node" attr.name="centrality" attr.type="long"/>
<key id="d6" for="node" attr.name="pagerank" attr.type="long"/>
<key id="d5" for="node" attr.name="confidence" attr.type="long"/>
<key id="d4" for="node" attr.name="description" attr.type="string"/>
<key id="d3" for="node" attr.name="aliases" attr.type="string"/>
<key id="d2" for="node" attr.name="mentions" attr.type="long"/>
<key id="d1" for="node" attr.name="documents" attr.type="string"/>
<key id="d0" for="node" attr.name="type" attr.type="string"/>
<graph edgedefault="directed"><node id="Transformer">
  <data key="d0">architecture</data>
  <data key="d1">attention_is_all_you_need,deit,gpt3_language_models,gpt3,palm,reformer</data>
  <data key="d2">6</data>
  <data key="d3">transformer,Transformer</data>
  <data key="d4">A new network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Attention Mechanism">
  <data key="d0">method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Attention Mechanism</data>
  <data key="d4">A mechanism that allows modeling of dependencies without regard to their distance in input or output sequences.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BLEU">
  <data key="d0">metric</data>
  <data key="d1">attention_is_all_you_need,gpt3_language_models,gpt3</data>
  <data key="d2">3</data>
  <data key="d3">BLEU</data>
  <data key="d4">A metric for evaluating the quality of machine translation by comparing a machine's output with a reference output.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="WMT 2014 English-to-German">
  <data key="d0">dataset</data>
  <data key="d1">attention_is_all_you_need,attention_is_all_you_need</data>
  <data key="d2">2</data>
  <data key="d3">WMT 2014 English-to-German,WMT 2014 English-German dataset</data>
  <data key="d4">A dataset used for evaluating machine translation performance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="WMT 2014 English-to-French">
  <data key="d0">dataset</data>
  <data key="d1">attention_is_all_you_need,attention_is_all_you_need</data>
  <data key="d2">2</data>
  <data key="d3">WMT 2014 English-to-French,WMT 2014 English-French dataset</data>
  <data key="d4">A dataset used for evaluating machine translation performance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Google Brain">
  <data key="d0">organization</data>
  <data key="d1">attention_is_all_you_need,transformer_xl</data>
  <data key="d2">2</data>
  <data key="d3">Google Brain</data>
  <data key="d4">A deep learning research team at Google.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Google Research">
  <data key="d0">organization</data>
  <data key="d1">attention_is_all_you_need,deit,palm,reformer,vision_transformer</data>
  <data key="d2">5</data>
  <data key="d3">Google Research</data>
  <data key="d4">A research division of Google focusing on various scientific and technological advancements.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Ashish Vaswani">
  <data key="d0">person</data>
  <data key="d1">attention_is_all_you_need,deit,reformer</data>
  <data key="d2">3</data>
  <data key="d3">Ashish Vaswani</data>
  <data key="d4">One of the authors who designed and implemented the first Transformer models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Noam Shazeer">
  <data key="d0">person</data>
  <data key="d1">attention_is_all_you_need,deit,reformer</data>
  <data key="d2">3</data>
  <data key="d3">Noam Shazeer</data>
  <data key="d4">One of the authors who proposed scaled dot-product attention and multi-head attention.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Niki Parmar">
  <data key="d0">person</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Niki Parmar</data>
  <data key="d4">One of the authors involved in the design and implementation of the Transformer.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Jakob Uszkoreit">
  <data key="d0">person</data>
  <data key="d1">attention_is_all_you_need,deit,reformer,vision_transformer</data>
  <data key="d2">4</data>
  <data key="d3">Jakob Uszkoreit</data>
  <data key="d4">One of the authors who proposed replacing RNNs with self-attention.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Llion Jones">
  <data key="d0">person</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Llion Jones</data>
  <data key="d4">One of the authors responsible for the initial codebase and efficient inference.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Aidan N. Gomez">
  <data key="d0">person</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Aidan N. Gomez</data>
  <data key="d4">One of the authors involved in designing various parts of the Tensor2Tensor framework.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Łukasz Kaiser">
  <data key="d0">person</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Łukasz Kaiser</data>
  <data key="d4">One of the authors who contributed to the design and implementation of Tensor2Tensor.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Illia Polosukhin">
  <data key="d0">person</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Illia Polosukhin</data>
  <data key="d4">One of the authors who contributed to the design and implementation of the Transformer.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Encoder">
  <data key="d0">Architecture</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Encoder</data>
  <data key="d4">A component of the model composed of a stack of identical layers with multi-head self-attention and feed-forward networks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Decoder">
  <data key="d0">Architecture</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Decoder</data>
  <data key="d4">A component of the model that generates output sequences, incorporating attention mechanisms over encoder outputs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Multi-Head Attention">
  <data key="d0">Method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Multi-Head Attention</data>
  <data key="d4">An attention mechanism that allows the model to jointly attend to information from different representation subspaces.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Scaled Dot-Product Attention">
  <data key="d0">Method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Scaled Dot-Product Attention</data>
  <data key="d4">An attention function that computes a weighted sum of values based on the compatibility of queries and keys.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Residual Connection">
  <data key="d0">Method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Residual Connection</data>
  <data key="d4">A technique used to facilitate training by allowing gradients to flow through the network more easily.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Layer Normalization">
  <data key="d0">Method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Layer Normalization</data>
  <data key="d4">A normalization technique applied to the outputs of sub-layers to stabilize and accelerate training.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Feed-Forward Network">
  <data key="d0">Method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Feed-Forward Network</data>
  <data key="d4">A fully connected network applied to each position separately in the encoder and decoder.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Embedding Layer">
  <data key="d0">Architecture</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Embedding Layer</data>
  <data key="d4">A layer that converts input tokens and output tokens into vector representations.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Softmax Function">
  <data key="d0">Method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Softmax Function</data>
  <data key="d4">A function used to convert decoder outputs into predicted next-token probabilities.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Attention Function">
  <data key="d0">Method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Attention Function</data>
  <data key="d4">A function that maps queries and key-value pairs to an output.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ReLU Activation">
  <data key="d0">Method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">ReLU Activation</data>
  <data key="d4">An activation function used in feed-forward networks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Attention(Q, K, V)">
  <data key="d0">Function</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Attention(Q, K, V)</data>
  <data key="d4">The mathematical representation of the attention mechanism.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="d_model">
  <data key="d0">Metric</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">d_model</data>
  <data key="d4">The dimensionality of the model's representations.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="n">
  <data key="d0">Metric</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">n</data>
  <data key="d4">The sequence length.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="k">
  <data key="d0">Metric</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">k</data>
  <data key="d4">The kernel size of convolutions.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="r">
  <data key="d0">Metric</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">r</data>
  <data key="d4">The size of the neighborhood in restricted self-attention.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Self-Attention">
  <data key="d0">method</data>
  <data key="d1">attention_is_all_you_need,reformer</data>
  <data key="d2">2</data>
  <data key="d3">Self-Attention,Self-attention</data>
  <data key="d4">A mechanism that allows the model to weigh the importance of different tokens in a sequence.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Recurrent Neural Network (RNN)">
  <data key="d0">architecture</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Recurrent Neural Network (RNN)</data>
  <data key="d4">A type of neural network designed for sequential data processing.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Convolutional Neural Network (CNN)">
  <data key="d0">architecture</data>
  <data key="d1">attention_is_all_you_need,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">CNN (Convolutional Neural Network),Convolutional Neural Network (CNN)</data>
  <data key="d4">A type of neural network primarily used for processing grid-like data such as images.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Positional Encoding">
  <data key="d0">method</data>
  <data key="d1">attention_is_all_you_need,transformer_xl,transformer_xl</data>
  <data key="d2">3</data>
  <data key="d3">Positional Encoding,relative positional encoding,positional encoding</data>
  <data key="d4">A technique used to inject information about the position of tokens in a sequence.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Adam Optimizer">
  <data key="d0">method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Adam Optimizer</data>
  <data key="d4">An optimization algorithm used for training machine learning models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BLEU Score">
  <data key="d0">metric</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">BLEU Score</data>
  <data key="d4">A metric for evaluating the quality of text which has been machine-translated.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Byte-Pair Encoding">
  <data key="d0">method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Byte-Pair Encoding</data>
  <data key="d4">A data compression technique used for encoding text.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Word-Piece Vocabulary">
  <data key="d0">method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Word-Piece Vocabulary</data>
  <data key="d4">A subword tokenization method used in natural language processing.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Residual Dropout">
  <data key="d0">method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Residual Dropout</data>
  <data key="d4">A regularization technique applied to neural networks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Label Smoothing">
  <data key="d0">method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Label Smoothing</data>
  <data key="d4">A technique used during training to prevent overfitting by softening the target labels.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Separable Convolutions">
  <data key="d0">method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Separable Convolutions</data>
  <data key="d4">A type of convolution that reduces the computational complexity of standard convolutions.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="NVIDIA P100 GPU">
  <data key="d0">hardware</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">NVIDIA P100 GPU</data>
  <data key="d4">A type of graphics processing unit used for training deep learning models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ConvS2SEnsemble">
  <data key="d0">model</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">ConvS2SEnsemble</data>
  <data key="d4">An ensemble model used for machine translation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="WMT2014">
  <data key="d0">dataset</data>
  <data key="d1">attention_is_all_you_need,attention_is_all_you_need</data>
  <data key="d2">2</data>
  <data key="d3">WMT2014,WMT 2014</data>
  <data key="d4">A benchmark dataset for machine translation tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="P100 GPUs">
  <data key="d0">hardware</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">P100 GPUs</data>
  <data key="d4">A type of GPU used for training the models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Penn Treebank">
  <data key="d0">dataset</data>
  <data key="d1">attention_is_all_you_need,transformer_xl</data>
  <data key="d2">2</data>
  <data key="d3">Penn Treebank</data>
  <data key="d4">A dataset used for English constituency parsing.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Wall Street Journal">
  <data key="d0">dataset</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Wall Street Journal</data>
  <data key="d4">A portion of the Penn Treebank used for training.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Beam Search">
  <data key="d0">method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Beam Search</data>
  <data key="d4">A search algorithm used during inference to generate translations.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Attention Heads">
  <data key="d0">architecture component</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Attention Heads</data>
  <data key="d4">Components of the Transformer that allow it to focus on different parts of the input.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Semi-supervised Setting">
  <data key="d0">training method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Semi-supervised Setting</data>
  <data key="d4">A training approach that uses both labeled and unlabeled data.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Vinyals &amp; Kaiser (2014)">
  <data key="d0">publication</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Vinyals &amp; Kaiser (2014)</data>
  <data key="d4">A reference for previous work in English constituency parsing.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Dyer et al. (2016)">
  <data key="d0">publication</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Dyer et al. (2016)</data>
  <data key="d4">A reference for previous work in English constituency parsing.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Zhu et al. (2013)">
  <data key="d0">publication</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Zhu et al. (2013)</data>
  <data key="d4">A reference for previous work in English constituency parsing.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Huang &amp; Harper (2009)">
  <data key="d0">publication</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Huang &amp; Harper (2009)</data>
  <data key="d4">A reference for previous work in English constituency parsing.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="McClosky et al. (2006)">
  <data key="d0">publication</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">McClosky et al. (2006)</data>
  <data key="d4">A reference for previous work in English constituency parsing.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Luong et al. (2015)">
  <data key="d0">publication</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Luong et al. (2015)</data>
  <data key="d4">A reference for previous work in English constituency parsing.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="attention-based models">
  <data key="d0">method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">attention-based models</data>
  <data key="d4">Models that use attention mechanisms to improve performance in tasks like translation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="images">
  <data key="d0">data type</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">images</data>
  <data key="d4">Visual data type that the authors plan to apply their models to.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="audio">
  <data key="d0">data type</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">audio</data>
  <data key="d4">Sound data type that the authors plan to apply their models to.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="video">
  <data key="d0">data type</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">video</data>
  <data key="d4">Moving visual data type that the authors plan to apply their models to.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="local, restricted attention mechanisms">
  <data key="d0">method</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">local, restricted attention mechanisms</data>
  <data key="d4">Attention mechanisms designed to efficiently handle large inputs and outputs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="code repository">
  <data key="d0">resource</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">code repository</data>
  <data key="d4">GitHub repository for the code used to train and evaluate models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Nal Kalchbrenner">
  <data key="d0">person</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Nal Kalchbrenner</data>
  <data key="d4">Researcher acknowledged for comments and inspiration.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Stephan Gouws">
  <data key="d0">person</data>
  <data key="d1">attention_is_all_you_need</data>
  <data key="d2">1</data>
  <data key="d3">Stephan Gouws</data>
  <data key="d4">Researcher acknowledged for comments and inspiration.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="CLIP">
  <data key="d0">model</data>
  <data key="d1">clip,segment_anything</data>
  <data key="d2">2</data>
  <data key="d3">CLIP</data>
  <data key="d4">A model that jointly trains an image encoder and a text encoder to predict correct pairings of image and text.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="GPT-3">
  <data key="d0">model</data>
  <data key="d1">clip,gpt3_language_models,gpt3,llama,palm,segment_anything</data>
  <data key="d2">6</data>
  <data key="d3">GPT-3,GPT-4</data>
  <data key="d4">A state-of-the-art language model that is competitive across many tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ImageNet">
  <data key="d0">dataset</data>
  <data key="d1">clip,deit,reformer,vision_transformer,vision_transformer</data>
  <data key="d2">5</data>
  <data key="d3">ImageNet,ImageNet ReaL</data>
  <data key="d4">A large dataset used for image classification tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="YFCC100M">
  <data key="d0">dataset</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">YFCC100M</data>
  <data key="d4">A dataset containing images and associated metadata used for training models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ResNet-50">
  <data key="d0">model</data>
  <data key="d1">clip,swin_transformer</data>
  <data key="d2">2</data>
  <data key="d3">ResNet-50</data>
  <data key="d4">A convolutional neural network architecture used for image classification.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="VirTex">
  <data key="d0">model</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">VirTex</data>
  <data key="d4">A model that uses natural language supervision for image representation learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ICMLM">
  <data key="d0">model</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">ICMLM</data>
  <data key="d4">A model that employs masked language modeling for learning image representations.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ConVIRT">
  <data key="d0">model</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">ConVIRT</data>
  <data key="d4">A model that uses contrastive objectives to learn image representations from text.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Dai &amp; Le">
  <data key="d0">people</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Dai &amp; Le</data>
  <data key="d4">Researchers who contributed to advancements in pre-training methods in NLP.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Peters et al.">
  <data key="d0">people</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Peters et al.</data>
  <data key="d4">Researchers who contributed to advancements in pre-training methods in NLP.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="OpenAI">
  <data key="d0">organization</data>
  <data key="d1">clip,gpt3_language_models,gpt3</data>
  <data key="d2">3</data>
  <data key="d3">OpenAI</data>
  <data key="d4">The organization behind the development of CLIP and other AI models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="400 million (image, text) pairs">
  <data key="d0">dataset</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">400 million (image, text) pairs</data>
  <data key="d4">A dataset used for training the model, consisting of image and text pairs collected from the internet.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="OCR">
  <data key="d0">task</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">OCR</data>
  <data key="d4">Optical Character Recognition, a task in computer vision.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="geo-localization">
  <data key="d0">task</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">geo-localization</data>
  <data key="d4">A task in computer vision that involves determining the geographic location of an image.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="fine-grained object classification">
  <data key="d0">task</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">fine-grained object classification</data>
  <data key="d4">A task in computer vision that involves classifying objects into very specific categories.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="zero-shot transfer">
  <data key="d0">method</data>
  <data key="d1">clip,gpt3_language_models</data>
  <data key="d2">2</data>
  <data key="d3">zero-shot transfer</data>
  <data key="d4">A method that allows a model to perform tasks without specific training on those tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="JFT-300M">
  <data key="d0">dataset</data>
  <data key="d1">clip,deit,reformer,swin_transformer,vision_transformer</data>
  <data key="d2">5</data>
  <data key="d3">JFT-300M</data>
  <data key="d4">A dataset with noisy labels used for training models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MS-COCO">
  <data key="d0">dataset</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">MS-COCO</data>
  <data key="d4">A high-quality crowd-labeled dataset for image captioning and object detection.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Visual Genome">
  <data key="d0">dataset</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Visual Genome</data>
  <data key="d4">A dataset containing images and their associated descriptions.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="GPT">
  <data key="d0">architecture</data>
  <data key="d1">clip,clip</data>
  <data key="d2">2</data>
  <data key="d3">GPT-1,GPT</data>
  <data key="d4">Generative Pre-trained Transformer, a family of language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Li et al. (2017)">
  <data key="d0">person</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Li et al. (2017)</data>
  <data key="d4">Researchers who achieved 11.5% accuracy on ImageNet in a zero-shot setting.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Xie et al. (2020)">
  <data key="d0">person</data>
  <data key="d1">clip,deit,reformer,vision_transformer</data>
  <data key="d2">4</data>
  <data key="d3">Xie et al. (2020)</data>
  <data key="d4">Researchers who established the current state of the art with 88.4% accuracy.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Mahajan et al. (2018)">
  <data key="d0">person</data>
  <data key="d1">clip,deit,reformer,vision_transformer</data>
  <data key="d2">4</data>
  <data key="d3">Mahajan et al. (2018)</data>
  <data key="d4">Researchers who demonstrated the effectiveness of predicting hashtags on Instagram images.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Kolesnikov et al. (2019)">
  <data key="d0">person</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Kolesnikov et al. (2019)</data>
  <data key="d4">Researchers who showed large gains on transfer benchmarks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Dosovitskiy et al. (2020)">
  <data key="d0">person</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Dosovitskiy et al. (2020)</data>
  <data key="d4">Researchers who contributed to the understanding of transfer performance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Hestness et al. (2017)">
  <data key="d0">person</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Hestness et al. (2017)</data>
  <data key="d4">Researchers who studied the relationship between compute and transfer performance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Kaplan et al. (2020)">
  <data key="d0">person</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Kaplan et al. (2020)</data>
  <data key="d4">Researchers who analyzed the predictability of transfer performance based on compute.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="McCann et al. (2017)">
  <data key="d0">person</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">McCann et al. (2017)</data>
  <data key="d4">Researchers who discussed improvements in deep contextual representation learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="WIT">
  <data key="d0">dataset</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">WIT</data>
  <data key="d4">WebImageText dataset used for training CLIP, consisting of image-text pairs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Vision Transformer">
  <data key="d0">architecture</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Vision Transformer</data>
  <data key="d4">An architecture used for image encoding, based on transformer models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="EfficientNet">
  <data key="d0">architecture</data>
  <data key="d1">clip,swin_transformer</data>
  <data key="d2">2</data>
  <data key="d3">EfficientNet</data>
  <data key="d4">A family of convolutional neural networks that optimize accuracy and efficiency.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="WebText">
  <data key="d0">dataset</data>
  <data key="d1">clip,gpt3_language_models,gpt3</data>
  <data key="d2">3</data>
  <data key="d3">WebText</data>
  <data key="d4">A dataset used to train the GPT-2 model.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Zhang et al. (2020)">
  <data key="d0">person</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Zhang et al. (2020)</data>
  <data key="d4">Researchers who adapted contrastive representation learning for medical imaging.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Oord et al. (2018)">
  <data key="d0">person</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Oord et al. (2018)</data>
  <data key="d4">Researchers who popularized the InfoNCE loss for contrastive representation learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Chen et al. (2020)">
  <data key="d0">person</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Chen et al. (2020)</data>
  <data key="d4">Researchers who explored generative models and contrastive models in representation learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Sohn (2016)">
  <data key="d0">person</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Sohn (2016)</data>
  <data key="d4">Introduced the multi-class N-pair loss in deep metric learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Tian et al. (2019)">
  <data key="d0">person</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Tian et al. (2019)</data>
  <data key="d4">Researchers who found that contrastive objectives can learn better representations.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ResNet-101">
  <data key="d0">architecture</data>
  <data key="d1">clip,deit,reformer,swin_transformer,vision_transformer</data>
  <data key="d2">5</data>
  <data key="d3">ResNet-101,ResNet</data>
  <data key="d4">A deeper version of ResNet-50 with 101 layers.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Vision Transformer (ViT)">
  <data key="d0">architecture</data>
  <data key="d1">clip,deit,reformer,vision_transformer</data>
  <data key="d2">4</data>
  <data key="d3">Vision Transformer (ViT)</data>
  <data key="d4">A transformer-based model for image classification.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Adam optimizer">
  <data key="d0">algorithm</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Adam optimizer</data>
  <data key="d4">An optimization algorithm that computes adaptive learning rates for each parameter.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="cross_entropy_loss">
  <data key="d0">metric</data>
  <data key="d1">clip,gpt3_language_models,gpt3</data>
  <data key="d2">3</data>
  <data key="d3">cross_entropy_loss,cross-entropy loss</data>
  <data key="d4">A loss function used for classification tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MOTIVATION">
  <data key="d0">section</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">MOTIVATION</data>
  <data key="d4">A section discussing the rationale behind zero-shot transfer.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="zero-shot learning">
  <data key="d0">method</data>
  <data key="d1">clip,gpt3_language_models,gpt3</data>
  <data key="d2">3</data>
  <data key="d3">zero-shot learning,Zero-Shot Learning</data>
  <data key="d4">A method that generalizes to unseen object categories without additional training.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="temperature parameter (τ)">
  <data key="d0">parameter</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">temperature parameter (τ)</data>
  <data key="d4">A parameter used to scale logits in the softmax function.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="V100 GPU">
  <data key="d0">hardware</data>
  <data key="d1">clip,gpt3_language_models,gpt3</data>
  <data key="d2">3</data>
  <data key="d3">V100 GPU</data>
  <data key="d4">A type of GPU used for high-performance computing.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="mixed-precision training">
  <data key="d0">method</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">mixed-precision training</data>
  <data key="d4">A training technique that uses both 16-bit and 32-bit floating-point types.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="gradient checkpointing">
  <data key="d0">method</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">gradient checkpointing</data>
  <data key="d4">A technique to save memory during training by storing only a subset of activations.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="CIFAR-10">
  <data key="d0">dataset</data>
  <data key="d1">clip,deit,deit,reformer,reformer,vision_transformer,vision_transformer</data>
  <data key="d2">7</data>
  <data key="d3">CIFAR-10,CIFAR-100</data>
  <data key="d4">A dataset commonly used for image classification tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="TinyImages">
  <data key="d0">dataset</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">TinyImages</data>
  <data key="d4">A dataset from which CIFAR-10 is derived.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="SVHN">
  <data key="d0">dataset</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">SVHN</data>
  <data key="d4">A dataset for street number transcription from Google Street View images.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Visual N-Grams">
  <data key="d0">method</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Visual N-Grams</data>
  <data key="d4">A method for zero-shot transfer in image classification.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="hypernetwork">
  <data key="d0">architecture</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">hypernetwork</data>
  <data key="d4">A network that generates weights for another network based on input.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Inception-V4">
  <data key="d0">architecture</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Inception-V4</data>
  <data key="d4">A deep learning model for image classification.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Jelinek-Mercer smoothing">
  <data key="d0">method</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Jelinek-Mercer smoothing</data>
  <data key="d4">A technique used to optimize probabilities in language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Szegedy et al. (2016)">
  <data key="d0">people</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Szegedy et al. (2016)</data>
  <data key="d4">Researchers who contributed to the development of Inception-V4.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Liu et al. (2018)">
  <data key="d0">people</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Liu et al. (2018)</data>
  <data key="d4">Researchers who identified task learning as a side-effect in language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Lei Ba et al. (2015)">
  <data key="d0">people</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Lei Ba et al. (2015)</data>
  <data key="d4">Researchers who introduced a zero-shot image classifier.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Elhoseiny et al. (2013)">
  <data key="d0">people</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Elhoseiny et al. (2013)</data>
  <data key="d4">Researchers associated with early work on zero-shot learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Flowers102">
  <data key="d0">dataset</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Flowers102</data>
  <data key="d4">An image classification dataset focused on flower species.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="GTSRB">
  <data key="d0">dataset</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">GTSRB</data>
  <data key="d4">German Traffic Sign Recognition Benchmark dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="SUN">
  <data key="d0">dataset</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">SUN</data>
  <data key="d4">A dataset used for scene recognition.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Yahoo">
  <data key="d0">dataset</data>
  <data key="d1">clip</data>
  <data key="d2">1</data>
  <data key="d3">Yahoo</data>
  <data key="d4">A dataset used for image classification.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="VTAB">
  <data key="d0">dataset</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">VTAB</data>
  <data key="d4">A suite of 19 tasks for evaluating transfer learning in vision.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Alexey Dosovitskiy">
  <data key="d0">person</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Alexey Dosovitskiy</data>
  <data key="d4">One of the authors of the paper and a researcher at Google Research.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Lucas Beyer">
  <data key="d0">person</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Lucas Beyer</data>
  <data key="d4">One of the authors of the paper and a researcher at Google Research.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Alexander Kolesnikov">
  <data key="d0">person</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Alexander Kolesnikov</data>
  <data key="d4">One of the authors of the paper and a researcher at Google Research.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Dirk Weissenborn">
  <data key="d0">person</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Dirk Weissenborn</data>
  <data key="d4">One of the authors of the paper and a researcher at Google Research.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Xiaohua Zhai">
  <data key="d0">person</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Xiaohua Zhai</data>
  <data key="d4">One of the authors of the paper and a researcher at Google Research.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Thomas Unterthiner">
  <data key="d0">person</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Thomas Unterthiner</data>
  <data key="d4">One of the authors of the paper and a researcher at Google Research.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Mostafa Dehghani">
  <data key="d0">person</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Mostafa Dehghani</data>
  <data key="d4">One of the authors of the paper and a researcher at Google Research.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Matthias Minderer">
  <data key="d0">person</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Matthias Minderer</data>
  <data key="d4">One of the authors of the paper and a researcher at Google Research.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Georg Heigold">
  <data key="d0">person</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Georg Heigold</data>
  <data key="d4">One of the authors of the paper and a researcher at Google Research.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Sylvain Gelly">
  <data key="d0">person</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Sylvain Gelly</data>
  <data key="d4">One of the authors of the paper and a researcher at Google Research.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Neil Houlsby">
  <data key="d0">person</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Neil Houlsby</data>
  <data key="d4">One of the authors of the paper and a researcher at Google Research.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ImageNet-21k">
  <data key="d0">dataset</data>
  <data key="d1">deit,reformer,swin_transformer,swin_transformer,vision_transformer</data>
  <data key="d2">5</data>
  <data key="d3">ImageNet-21k,ImageNet-1K,ImageNet-22K</data>
  <data key="d4">A large dataset used for pre-training the Vision Transformer.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MLP Head">
  <data key="d0">Architecture Component</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">MLP Head</data>
  <data key="d4">A multi-layer perceptron used as a classification head in the ViT.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Transformer Encoder">
  <data key="d0">Architecture Component</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Transformer Encoder</data>
  <data key="d4">A component of the ViT that processes input sequences using self-attention.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Multi-Head Self-Attention (MSA)">
  <data key="d0">Architecture Component</data>
  <data key="d1">deit,vision_transformer</data>
  <data key="d2">2</data>
  <data key="d3">Multi-Head Self-Attention (MSA)</data>
  <data key="d4">A mechanism in transformers that allows the model to focus on different parts of the input.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Position Embeddings">
  <data key="d0">Architecture Component</data>
  <data key="d1">deit,longformer,reformer</data>
  <data key="d2">3</data>
  <data key="d3">Position Embeddings</data>
  <data key="d4">Learnable embeddings added to retain positional information in the input sequence.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Self-Supervised Learning">
  <data key="d0">Learning Method</data>
  <data key="d1">deit,reformer</data>
  <data key="d2">2</data>
  <data key="d3">Self-Supervised Learning</data>
  <data key="d4">A method of training models using unlabeled data.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ICLR 2021">
  <data key="d0">Conference</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">ICLR 2021</data>
  <data key="d4">The conference where the paper was published.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Touvron et al. (2019)">
  <data key="d0">Citation</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Touvron et al. (2019)</data>
  <data key="d4">A referenced work discussing fine-tuning and higher resolution.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Sun et al. (2017)">
  <data key="d0">Citation</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Sun et al. (2017)</data>
  <data key="d4">A referenced work studying CNN performance scaling.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Kolesnikov et al. (2020)">
  <data key="d0">Citation</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Kolesnikov et al. (2020)</data>
  <data key="d4">A referenced work performing empirical exploration of CNN transfer learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Djolonga et al. (2020)">
  <data key="d0">Citation</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Djolonga et al. (2020)</data>
  <data key="d4">A referenced work related to CNN transfer learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Vaswani et al. (2017)">
  <data key="d0">Citation</data>
  <data key="d1">deit,longformer,reformer,transformer_xl,vision_transformer</data>
  <data key="d2">5</data>
  <data key="d3">Vaswani et al. (2017)</data>
  <data key="d4">The original paper introducing the Transformer architecture.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="GELU">
  <data key="d0">Activation Function</data>
  <data key="d1">deit,reformer,swin_transformer,vision_transformer</data>
  <data key="d2">4</data>
  <data key="d3">GELU</data>
  <data key="d4">An activation function used in the MLP layers.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ILSVRC-2012 ImageNet">
  <data key="d0">dataset</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">ILSVRC-2012 ImageNet</data>
  <data key="d4">A dataset with 1k classes and 1.3M images used for image classification.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="JFT">
  <data key="d0">dataset</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">JFT</data>
  <data key="d4">A dataset with 18k classes and 303M high-resolution images.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Oxford-IIIT Pets">
  <data key="d0">dataset</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Oxford-IIIT Pets</data>
  <data key="d4">A dataset containing images of pets for classification.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Oxford Flowers-102">
  <data key="d0">dataset</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Oxford Flowers-102</data>
  <data key="d4">A dataset containing images of flowers for classification.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ViT-Base">
  <data key="d0">model</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">ViT-Base</data>
  <data key="d4">A Vision Transformer model variant with 12 layers and 86M parameters.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ViT-Large">
  <data key="d0">model</data>
  <data key="d1">deit,deit,reformer,reformer,vision_transformer,vision_transformer</data>
  <data key="d2">6</data>
  <data key="d3">ViT-Huge,ViT-Large</data>
  <data key="d4">A Vision Transformer model variant with 24 layers and 307M parameters.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Adam">
  <data key="d0">optimizer</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Adam</data>
  <data key="d4">An optimization algorithm used for training models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="SGD">
  <data key="d0">optimizer</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">SGD</data>
  <data key="d4">Stochastic Gradient Descent, an optimization algorithm used for fine-tuning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Noisy Student">
  <data key="d0">model</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Noisy Student</data>
  <data key="d4">A large EfficientNet trained using semi-supervised learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Big Transfer (BiT)">
  <data key="d0">model</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Big Transfer (BiT)</data>
  <data key="d4">A method for supervised transfer learning with large ResNets.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Polyak &amp; Juditsky (1992)">
  <data key="d0">publication</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Polyak &amp; Juditsky (1992)</data>
  <data key="d4">A paper discussing averaging techniques used in model training.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ViT-L/16">
  <data key="d0">model</data>
  <data key="d1">deit,deit,reformer,segment_anything,vision_transformer,vision_transformer</data>
  <data key="d2">6</data>
  <data key="d3">ViT-L/16,ViT-B/16,ViT-L/14</data>
  <data key="d4">Vision Transformer model pre-trained on ImageNet-21k</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="TPUv3">
  <data key="d0">hardware</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">TPUv3</data>
  <data key="d4">Cloud TPU version 3 used for training</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BiT">
  <data key="d0">method</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">BiT</data>
  <data key="d4">State-of-the-art method based on ResNet co-trained on ImageNet and YouTube</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="VIVI">
  <data key="d0">method</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">VIVI</data>
  <data key="d4">ResNet co-trained on ImageNet and YouTube</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="S4L">
  <data key="d0">method</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">S4L</data>
  <data key="d4">Supervised plus semi-supervised learning method on ImageNet</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ViT-H/14">
  <data key="d0">model</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">ViT-H/14</data>
  <data key="d4">Vision Transformer model that outperforms BiT-R152x4 on Natural and Structured tasks</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="weight decay">
  <data key="d0">hyperparameter</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">weight decay</data>
  <data key="d4">Regularization parameter used to optimize model performance</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="dropout">
  <data key="d0">hyperparameter</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">dropout</data>
  <data key="d4">Regularization technique used to prevent overfitting</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="label smoothing">
  <data key="d0">hyperparameter</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">label smoothing</data>
  <data key="d4">Regularization technique used to improve model generalization</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ViT-B/32">
  <data key="d0">model</data>
  <data key="d1">deit,deit,vision_transformer,vision_transformer</data>
  <data key="d2">4</data>
  <data key="d3">ViT-B/32,ViT-L/32</data>
  <data key="d4">Vision Transformer model with specific architecture</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ViT-B">
  <data key="d0">model</data>
  <data key="d1">deit,vision_transformer</data>
  <data key="d2">2</data>
  <data key="d3">ViT-B</data>
  <data key="d4">Vision Transformer model with all hidden dimensions halved</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Hybrid models">
  <data key="d0">architecture</data>
  <data key="d1">deit</data>
  <data key="d2">1</data>
  <data key="d3">Hybrid models</data>
  <data key="d4">Models combining ResNet and Vision Transformer architectures</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ICLR2021">
  <data key="d0">conference</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">ICLR2021</data>
  <data key="d4">Conference where the paper was published</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Attention">
  <data key="d0">mechanism</data>
  <data key="d1">deit</data>
  <data key="d2">1</data>
  <data key="d3">Attention</data>
  <data key="d4">Mechanism used in Vision Transformers to integrate information across the image</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Principal components">
  <data key="d0">concept</data>
  <data key="d1">deit</data>
  <data key="d2">1</data>
  <data key="d3">Principal components</data>
  <data key="d4">Statistical method used to analyze learned embeddings</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="self-attention">
  <data key="d0">method</data>
  <data key="d1">deit,longformer,swin_transformer,transformer_xl,vision_transformer</data>
  <data key="d2">5</data>
  <data key="d3">self-attention</data>
  <data key="d4">A mechanism that allows the model to weigh the importance of different parts of the input data.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="CNN">
  <data key="d0">architecture</data>
  <data key="d1">deit,reformer,swin_transformer</data>
  <data key="d2">3</data>
  <data key="d3">CNN</data>
  <data key="d4">Convolutional Neural Networks, commonly used for image processing tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="masked language modeling">
  <data key="d0">method</data>
  <data key="d1">deit</data>
  <data key="d2">1</data>
  <data key="d3">masked language modeling</data>
  <data key="d4">A self-supervised learning task used in models like BERT.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="self-supervised pre-training">
  <data key="d0">method</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">self-supervised pre-training</data>
  <data key="d4">A training approach where the model learns from unlabeled data.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="attention distance">
  <data key="d0">metric</data>
  <data key="d1">deit,reformer</data>
  <data key="d2">2</data>
  <data key="d3">attention distance</data>
  <data key="d4">A measure of how far information is integrated across the image based on attention weights.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Andreas Steiner">
  <data key="d0">person</data>
  <data key="d1">deit,reformer,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">Andreas Steiner</data>
  <data key="d4">A colleague at Google who contributed to the infrastructure.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Joan Puigcerver">
  <data key="d0">person</data>
  <data key="d1">deit,reformer</data>
  <data key="d2">2</data>
  <data key="d3">Joan Puigcerver</data>
  <data key="d4">A colleague at Google who assisted with large-scale training infrastructure.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Maxim Neumann">
  <data key="d0">person</data>
  <data key="d1">deit,reformer</data>
  <data key="d2">2</data>
  <data key="d3">Maxim Neumann</data>
  <data key="d4">A colleague at Google who helped with large-scale training infrastructure.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Dmitry Lepikhin">
  <data key="d0">person</data>
  <data key="d1">deit,reformer</data>
  <data key="d2">2</data>
  <data key="d3">Dmitry Lepikhin</data>
  <data key="d4">A colleague at Google involved in discussions related to the work.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Aravindh Mahendran">
  <data key="d0">person</data>
  <data key="d1">deit,reformer</data>
  <data key="d2">2</data>
  <data key="d3">Aravindh Mahendran</data>
  <data key="d4">A colleague at Google involved in discussions related to the work.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Daniel Keysers">
  <data key="d0">person</data>
  <data key="d1">deit,reformer</data>
  <data key="d2">2</data>
  <data key="d3">Daniel Keysers</data>
  <data key="d4">A colleague at Google involved in discussions related to the work.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Mario Lucic">
  <data key="d0">person</data>
  <data key="d1">deit,reformer</data>
  <data key="d2">2</data>
  <data key="d3">Mario Lucic</data>
  <data key="d4">A colleague at Google involved in discussions related to the work.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Colin Raffel">
  <data key="d0">person</data>
  <data key="d1">deit,reformer</data>
  <data key="d2">2</data>
  <data key="d3">Colin Raffel</data>
  <data key="d4">A colleague at Google involved in discussions related to the work.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Devlin et al. (2019)">
  <data key="d0">reference</data>
  <data key="d1">deit,longformer,reformer</data>
  <data key="d2">3</data>
  <data key="d3">Devlin et al. (2019)</data>
  <data key="d4">Authors of the BERT paper, which introduced masked language modeling.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Chen et al. (2020b)">
  <data key="d0">reference</data>
  <data key="d1">deit,reformer</data>
  <data key="d2">2</data>
  <data key="d3">Chen et al. (2020b)</data>
  <data key="d4">Authors of a paper on contrastive pre-training.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="He et al. (2020)">
  <data key="d0">reference</data>
  <data key="d1">deit,reformer</data>
  <data key="d2">2</data>
  <data key="d3">He et al. (2020)</data>
  <data key="d4">Authors of a paper on unsupervised visual representation learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Bachman et al. (2019)">
  <data key="d0">reference</data>
  <data key="d1">deit,reformer</data>
  <data key="d2">2</data>
  <data key="d3">Bachman et al. (2019)</data>
  <data key="d4">Authors of a paper on maximizing mutual information across views.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Hénaff et al. (2020)">
  <data key="d0">reference</data>
  <data key="d1">deit</data>
  <data key="d2">1</data>
  <data key="d3">Hénaff et al. (2020)</data>
  <data key="d4">Authors of a paper on contrastive learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Carion et al. (2020)">
  <data key="d0">reference</data>
  <data key="d1">deit,reformer</data>
  <data key="d2">2</data>
  <data key="d3">Carion et al. (2020)</data>
  <data key="d4">Authors of a paper on end-to-end object detection with transformers.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="NLP">
  <data key="d0">field</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">NLP</data>
  <data key="d4">Natural Language Processing, a field of AI focused on the interaction between computers and human language.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="few-shot learning">
  <data key="d0">method</data>
  <data key="d1">gpt3_language_models,gpt3_language_models,gpt3,gpt3,palm</data>
  <data key="d2">5</data>
  <data key="d3">one-shot learning,few-shot learning</data>
  <data key="d4">A learning paradigm where a model learns to perform a task with very few examples.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="pre-training">
  <data key="d0">method</data>
  <data key="d1">gpt3_language_models,reformer</data>
  <data key="d2">2</data>
  <data key="d3">Pre-training,pre-training</data>
  <data key="d4">The initial training phase of a model on a large corpus of text.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="fine-tuning">
  <data key="d0">method</data>
  <data key="d1">gpt3_language_models,gpt3,reformer</data>
  <data key="d2">3</data>
  <data key="d3">Fine-tuning,fine-tuning</data>
  <data key="d4">The process of adapting a pre-trained model to a specific task using a smaller dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="language tasks">
  <data key="d0">concept</data>
  <data key="d1">gpt3_language_models</data>
  <data key="d2">1</data>
  <data key="d3">language tasks</data>
  <data key="d4">Various tasks that involve understanding or generating human language.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="translation">
  <data key="d0">task</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">translation</data>
  <data key="d4">The task of converting text from one language to another.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="question-answering">
  <data key="d0">task</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">question-answering</data>
  <data key="d4">The task of providing answers to questions based on a given context.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="cloze tasks">
  <data key="d0">task</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">cloze tasks</data>
  <data key="d4">Tasks that involve filling in the blanks in a sentence.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="3-digit arithmetic">
  <data key="d0">task</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">3-digit arithmetic</data>
  <data key="d4">A task that involves performing arithmetic operations with three-digit numbers.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Common Crawl">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3,llama</data>
  <data key="d2">3</data>
  <data key="d3">Common Crawl</data>
  <data key="d4">A dataset used for training language models, consisting of web-crawled data.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="SuperGLUE">
  <data key="d0">benchmark</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">SuperGLUE</data>
  <data key="d4">A benchmark for evaluating the performance of NLP models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Johns Hopkins University">
  <data key="d0">organization</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">Johns Hopkins University</data>
  <data key="d4">An academic institution associated with one of the authors.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="parameters">
  <data key="d0">metric</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">parameters</data>
  <data key="d4">The number of adjustable weights in a neural network model.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="societal impacts">
  <data key="d0">concept</data>
  <data key="d1">gpt3_language_models</data>
  <data key="d2">1</data>
  <data key="d3">societal impacts</data>
  <data key="d4">The broader implications of language models like GPT-3 on society.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="in-context learning">
  <data key="d0">method</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">in-context learning</data>
  <data key="d4">A meta-learning approach where a model uses contextual information to adapt to tasks without gradient updates.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="meta-learning">
  <data key="d0">method</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">meta-learning</data>
  <data key="d4">A learning paradigm where models develop a broad set of skills during training to adapt quickly to new tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Natural Questions">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3,llama</data>
  <data key="d2">3</data>
  <data key="d3">Natural Questions</data>
  <data key="d4">A benchmark dataset used to evaluate question answering systems.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="CoQA">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">CoQA</data>
  <data key="d4">A conversational question answering dataset used to evaluate models on dialogue-based tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="TriviaQA">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3,llama,longformer</data>
  <data key="d2">4</data>
  <data key="d3">TriviaQA</data>
  <data key="d4">A dataset for question answering that includes trivia questions.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="log loss">
  <data key="d0">metric</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">log loss</data>
  <data key="d4">A performance metric that correlates well with many downstream NLP tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="RWC+19">
  <data key="d0">reference</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">RWC+19</data>
  <data key="d4">A citation for a paper discussing in-context learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="YdC+19">
  <data key="d0">reference</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">YdC+19</data>
  <data key="d4">A citation for a paper discussing generalization in models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MPL19">
  <data key="d0">reference</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">MPL19</data>
  <data key="d4">A citation for a paper related to model performance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="GSL+18">
  <data key="d0">reference</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">GSL+18</data>
  <data key="d4">A citation for a paper discussing the performance of fine-tuned models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="NK19">
  <data key="d0">reference</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">NK19</data>
  <data key="d4">A citation for a paper related to model evaluation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="KMH+20">
  <data key="d0">reference</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">KMH+20</data>
  <data key="d4">A citation for a paper discussing the correlation of log loss with model performance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="RNSS18">
  <data key="d0">reference</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">RNSS18</data>
  <data key="d4">A citation for a paper discussing the early transformer models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="DCLT18">
  <data key="d0">reference</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">DCLT18</data>
  <data key="d4">A citation for a paper discussing the scaling of transformer models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="SPP+19">
  <data key="d0">reference</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">SPP+19</data>
  <data key="d4">A citation for a paper discussing improvements in transformer models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="RSR+19">
  <data key="d0">reference</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">RSR+19</data>
  <data key="d4">A citation for a paper discussing the scaling of language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Tur20">
  <data key="d0">reference</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">Tur20</data>
  <data key="d4">A citation for a paper discussing the latest advancements in transformer models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ANLI">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">ANLI</data>
  <data key="d4">A natural language inference dataset used to evaluate model performance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="RACE">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3,llama</data>
  <data key="d2">3</data>
  <data key="d3">RACE</data>
  <data key="d4">A reading comprehension dataset for evaluating language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="QuAC">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">QuAC</data>
  <data key="d4">A dataset for question answering in a conversational context.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="CommonCrawl">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3,llama</data>
  <data key="d2">3</data>
  <data key="d3">CommonCrawl</data>
  <data key="d4">A web corpus used for training language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Data Contamination">
  <data key="d0">concept</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">Data Contamination,data contamination</data>
  <data key="d4">The issue of training models on datasets that may include content from test datasets.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Bias and Fairness">
  <data key="d0">concept</data>
  <data key="d1">gpt3_language_models</data>
  <data key="d2">1</data>
  <data key="d3">Bias and Fairness</data>
  <data key="d4">Concerns regarding the ethical implications and societal impacts of AI models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Books1">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3_language_models,gpt3,gpt3</data>
  <data key="d2">4</data>
  <data key="d3">Books2,Books1</data>
  <data key="d4">An internet-based corpus used in training language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Wikipedia">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3,llama,palm</data>
  <data key="d2">4</data>
  <data key="d3">Wikipedia</data>
  <data key="d4">An English-language encyclopedia used in training language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Sparse Transformer">
  <data key="d0">architecture</data>
  <data key="d1">gpt3_language_models,gpt3,longformer</data>
  <data key="d2">3</data>
  <data key="d3">Sparse Transformer</data>
  <data key="d4">An architecture that uses alternating dense and locally banded sparse attention patterns.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Validation loss">
  <data key="d0">metric</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">Validation loss</data>
  <data key="d4">A measure used to evaluate the performance of models during training.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Scaling Laws for Neural Language Models">
  <data key="d0">research</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">Scaling Laws for Neural Language Models</data>
  <data key="d4">A study that analyzes the relationship between model size and performance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Microsoft">
  <data key="d0">organization</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">Microsoft</data>
  <data key="d4">Provider of high-bandwidth cluster for training.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LAMBADA">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">LAMBADA</data>
  <data key="d4">A dataset testing long-range dependencies in text.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Storycloze">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">Storycloze</data>
  <data key="d4">A dataset used for evaluating story completion tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Winograd">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">Winograd</data>
  <data key="d4">A dataset for evaluating commonsense reasoning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ARC">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">ARC</data>
  <data key="d4">A dataset for evaluating reasoning capabilities.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="OpenBookQA">
  <data key="d0">dataset</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">OpenBookQA</data>
  <data key="d4">A dataset for evaluating question answering.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="F1 similarity score">
  <data key="d0">metric</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">F1 similarity score</data>
  <data key="d4">A metric for evaluating model performance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="K">
  <data key="d0">parameter</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">K</data>
  <data key="d4">The number of examples drawn from the training set for few-shot learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="model parallelism">
  <data key="d0">method</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">model parallelism</data>
  <data key="d4">A technique used to distribute model training across multiple GPUs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="gradient noise scaling">
  <data key="d0">method</data>
  <data key="d1">gpt3_language_models,gpt3</data>
  <data key="d2">2</data>
  <data key="d3">gradient noise scaling</data>
  <data key="d4">A technique used to guide the choice of batch size during training.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="task-specific fine-tuning">
  <data key="d0">Method</data>
  <data key="d1">gpt3</data>
  <data key="d2">1</data>
  <data key="d3">task-specific fine-tuning</data>
  <data key="d4">The process of adapting a pre-trained model to a specific task using a labeled dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="human evaluators">
  <data key="d0">People</data>
  <data key="d1">gpt3</data>
  <data key="d2">1</data>
  <data key="d3">human evaluators</data>
  <data key="d4">Individuals who assess the quality of generated text.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="F1 Score">
  <data key="d0">metric</data>
  <data key="d1">gpt3,longformer</data>
  <data key="d2">2</data>
  <data key="d3">F1 Score</data>
  <data key="d4">A measure of a model's accuracy on a dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="accuracy">
  <data key="d0">metric</data>
  <data key="d1">gpt3,segment_anything,vision_transformer</data>
  <data key="d2">3</data>
  <data key="d3">accuracy</data>
  <data key="d4">The ratio of correctly predicted instances to the total instances.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LLaMA-I">
  <data key="d0">Language Model</data>
  <data key="d1">llama,llama,segment_anything</data>
  <data key="d2">3</data>
  <data key="d3">LLaMA,LLaMA-I</data>
  <data key="d4">A collection of foundation language models ranging from 7B to 65B parameters.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Chinchilla">
  <data key="d0">Language Model</data>
  <data key="d1">llama,palm</data>
  <data key="d2">2</data>
  <data key="d3">Chinchilla</data>
  <data key="d4">A large language model with 70B parameters, used for performance comparison.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="PaLM">
  <data key="d0">Language Model</data>
  <data key="d1">llama,palm</data>
  <data key="d2">2</data>
  <data key="d3">PaLM</data>
  <data key="d4">A large language model with 540B parameters, used for performance comparison.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MetaAI">
  <data key="d0">Organization</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">MetaAI</data>
  <data key="d4">The organization behind the development of LLaMA.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Hoffmann et al. (2022)">
  <data key="d0">Research Paper</data>
  <data key="d1">llama,palm</data>
  <data key="d2">2</data>
  <data key="d3">Hoffmann et al. (2022)</data>
  <data key="d4">A study that discusses scaling laws for language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="C4">
  <data key="d0">Dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">C4</data>
  <data key="d4">A dataset used for training, consisting of web data filtered for quality.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Github">
  <data key="d0">Dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Github</data>
  <data key="d4">A dataset containing public GitHub repositories.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Books">
  <data key="d0">Dataset</data>
  <data key="d1">llama,palm</data>
  <data key="d2">2</data>
  <data key="d3">Books</data>
  <data key="d4">A dataset containing public domain books.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ArXiv">
  <data key="d0">Dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">ArXiv</data>
  <data key="d4">A dataset containing scientific papers from arXiv.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="StackExchange">
  <data key="d0">Dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">StackExchange</data>
  <data key="d4">A dataset containing questions and answers from Stack Exchange.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Transformer Architecture">
  <data key="d0">Architecture</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Transformer Architecture</data>
  <data key="d4">The neural network architecture used for training LLaMA.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Performance Metrics">
  <data key="d0">Metric</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Performance Metrics</data>
  <data key="d4">Benchmarks used to evaluate the performance of language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="CCNet">
  <data key="d0">dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">CCNet</data>
  <data key="d4">A dataset used for increasing consistency across papers.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Stack Exchange">
  <data key="d0">website</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Stack Exchange</data>
  <data key="d4">A platform for high-quality questions and answers across various domains.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Google BigQuery">
  <data key="d0">service</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Google BigQuery</data>
  <data key="d4">A cloud-based data warehouse for querying large datasets.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Apache License">
  <data key="d0">license</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Apache License</data>
  <data key="d4">A permissive free software license.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BSD License">
  <data key="d0">license</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">BSD License</data>
  <data key="d4">A family of permissive free software licenses.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MIT License">
  <data key="d0">license</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">MIT License</data>
  <data key="d4">A permissive free software license.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Byte-Pair Encoding (BPE)">
  <data key="d0">algorithm</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Byte-Pair Encoding (BPE)</data>
  <data key="d4">A tokenization algorithm used for processing text.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="RMSNorm">
  <data key="d0">normalization function</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">RMSNorm</data>
  <data key="d4">A normalization function used to improve training stability.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="SwiGLU">
  <data key="d0">activation function</data>
  <data key="d1">llama,palm</data>
  <data key="d2">2</data>
  <data key="d3">SwiGLU</data>
  <data key="d4">An activation function used to improve performance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Rotary Positional Embeddings (RoPE)">
  <data key="d0">embedding technique</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Rotary Positional Embeddings (RoPE)</data>
  <data key="d4">A technique for adding positional information to transformer models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="AdamW">
  <data key="d0">optimizer</data>
  <data key="d1">llama,swin_transformer</data>
  <data key="d2">2</data>
  <data key="d3">AdamW</data>
  <data key="d4">An optimization algorithm used for training models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="CommonSense Reasoning Tasks">
  <data key="d0">task</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">CommonSense Reasoning Tasks</data>
  <data key="d4">A set of tasks for evaluating models on common sense reasoning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Gopher">
  <data key="d0">model</data>
  <data key="d1">llama,palm</data>
  <data key="d2">2</data>
  <data key="d3">Gopher</data>
  <data key="d4">A large language model developed by DeepMind.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Table 2">
  <data key="d0">table</data>
  <data key="d1">llama,llama</data>
  <data key="d2">2</data>
  <data key="d3">Table 3,Table 2</data>
  <data key="d4">A table containing model sizes, architectures, and optimization hyper-parameters.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="OPT">
  <data key="d0">model</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">OPT</data>
  <data key="d4">Open-sourced language models compared with LLaMA.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="OPT-IML">
  <data key="d0">model</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">OPT-IML</data>
  <data key="d4">An instruction-tuned model compared with LLaMA.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="HumanEval">
  <data key="d0">dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">HumanEval</data>
  <data key="d4">A benchmark for evaluating code generation from natural language.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MBPP">
  <data key="d0">dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">MBPP</data>
  <data key="d4">A benchmark for evaluating code generation from natural language.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MATH">
  <data key="d0">dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">MATH</data>
  <data key="d4">A dataset of mathematical problems for evaluation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="GSM8k">
  <data key="d0">dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">GSM8k</data>
  <data key="d4">A dataset of middle school mathematical problems.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BoolQ">
  <data key="d0">dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">BoolQ</data>
  <data key="d4">A common sense reasoning benchmark.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Flan-PaLM">
  <data key="d0">dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Flan-PaLM</data>
  <data key="d4">An instruction-tuned model benchmark.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="WinoGrande">
  <data key="d0">dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">WinoGrande</data>
  <data key="d4">A common sense reasoning benchmark.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ARCeasy">
  <data key="d0">dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">ARCeasy</data>
  <data key="d4">A common sense reasoning benchmark.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ARChallenge">
  <data key="d0">dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">ARChallenge</data>
  <data key="d4">A common sense reasoning benchmark.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Exact Match">
  <data key="d0">metric</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Exact Match</data>
  <data key="d4">A performance metric for evaluating question answering.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Zero-shot">
  <data key="d0">evaluation setting</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Zero-shot</data>
  <data key="d4">An evaluation setting where models are tested without prior examples.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Few-shot">
  <data key="d0">evaluation setting</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Few-shot</data>
  <data key="d4">An evaluation setting where models are tested with a few examples.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="pass@">
  <data key="d0">metric</data>
  <data key="d1">llama,llama</data>
  <data key="d2">2</data>
  <data key="d3">pass@,pass@1</data>
  <data key="d4">A performance metric for evaluating code generation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MMLU">
  <data key="d0">benchmark</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">MMLU</data>
  <data key="d4">Massive multitask language understanding benchmark.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LaMDA">
  <data key="d0">model</data>
  <data key="d1">llama,palm</data>
  <data key="d2">2</data>
  <data key="d3">LaMDA</data>
  <data key="d4">A language model developed by Google, compared with LLaMA.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LLaMA-65B">
  <data key="d0">model</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">LLaMA-65B</data>
  <data key="d4">A large language model with 65 billion parameters.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Gutenberg">
  <data key="d0">dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Gutenberg</data>
  <data key="d4">A digital library of free eBooks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Books3">
  <data key="d0">dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Books3</data>
  <data key="d4">A dataset used in training language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="pass@100">
  <data key="d0">metric</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">pass@100</data>
  <data key="d4">A metric indicating the percentage of correct answers within 100 attempts.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="pass@80">
  <data key="d0">metric</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">pass@80</data>
  <data key="d4">A metric indicating the percentage of correct answers within 80 attempts.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="RealToxicityPrompts">
  <data key="d0">benchmark</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">RealToxicityPrompts</data>
  <data key="d4">A benchmark for evaluating the toxicity of language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="PerspectiveAPI">
  <data key="d0">API</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">PerspectiveAPI</data>
  <data key="d4">An API used to evaluate the toxicity of generated text.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Chen et al. (2021)">
  <data key="d0">citation</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Chen et al. (2021)</data>
  <data key="d4">A reference to a paper discussing methods for unbiased estimates.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Chowdhery et al. (2022)">
  <data key="d0">citation</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Chowdhery et al. (2022)</data>
  <data key="d4">A reference to a paper discussing the PaLM-Coder model.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Iyer et al. (2022)">
  <data key="d0">citation</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Iyer et al. (2022)</data>
  <data key="d4">A reference to a paper discussing instruction-tuned models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Zhang et al. (2022)">
  <data key="d0">citation</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Zhang et al. (2022)</data>
  <data key="d4">A reference to a paper discussing toxic content generation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="WinoGender">
  <data key="d0">dataset</data>
  <data key="d1">llama,palm</data>
  <data key="d2">2</data>
  <data key="d3">Winogender,WinoGender</data>
  <data key="d4">A dataset for evaluating co-reference resolution and biases related to gender.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="CrowS-Pairs">
  <data key="d0">dataset</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">CrowS-Pairs</data>
  <data key="d4">A dataset used to measure biases in various categories including gender and religion.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="TruthfulQA">
  <data key="d0">benchmark</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">TruthfulQA</data>
  <data key="d4">A benchmark for measuring the truthfulness of language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Rae et al. (2021)">
  <data key="d0">publication</data>
  <data key="d1">llama,longformer,palm</data>
  <data key="d2">3</data>
  <data key="d3">Rae et al. (2020),Rae et al. (2021)</data>
  <data key="d4">A reference to previous work on gender bias in models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="API">
  <data key="d0">technology</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">API</data>
  <data key="d4">Application Programming Interface used for model interaction.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Carbon Emission">
  <data key="d0">metric</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Carbon Emission</data>
  <data key="d4">A measure of the carbon footprint associated with model training.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Perplexity">
  <data key="d0">metric</data>
  <data key="d1">llama,transformer_xl,transformer_xl</data>
  <data key="d2">3</data>
  <data key="d3">perplexity (PPL),perplexity,Perplexity</data>
  <data key="d4">A measure used to evaluate the performance of language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Co-reference resolution">
  <data key="d0">method</data>
  <data key="d1">llama</data>
  <data key="d2">1</data>
  <data key="d3">Co-reference resolution</data>
  <data key="d4">A task in natural language processing to determine which words refer to the same entity.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Longformer">
  <data key="d0">architecture</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Longformer</data>
  <data key="d4">A modified Transformer architecture with a self-attention operation that scales linearly with sequence length.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Allen Institute for Artificial Intelligence">
  <data key="d0">organization</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Allen Institute for Artificial Intelligence</data>
  <data key="d4">The organization where the authors of the paper are affiliated.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="text8">
  <data key="d0">dataset</data>
  <data key="d1">longformer,transformer_xl</data>
  <data key="d2">2</data>
  <data key="d3">text8</data>
  <data key="d4">A benchmark dataset used for evaluating language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="enwik8">
  <data key="d0">dataset</data>
  <data key="d1">longformer,transformer_xl</data>
  <data key="d2">2</data>
  <data key="d3">enwik8</data>
  <data key="d4">Another benchmark dataset used for evaluating language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="WikiHop">
  <data key="d0">dataset</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">WikiHop</data>
  <data key="d4">A dataset used for evaluating long document tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Longformer-Encoder-Decoder (LED)">
  <data key="d0">architecture</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Longformer-Encoder-Decoder (LED)</data>
  <data key="d4">A variant of Longformer designed for long document generative sequence-to-sequence tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="RoBERTa">
  <data key="d0">architecture</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">RoBERTa</data>
  <data key="d4">A pre-trained Transformer model that Longformer outperforms on long document tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Transformer-XL">
  <data key="d0">architecture</data>
  <data key="d1">longformer,transformer_xl</data>
  <data key="d2">2</data>
  <data key="d3">Transformer-XL</data>
  <data key="d4">A model that addresses the computational efficiency of Transformers on long sequences.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Dai et al. (2019)">
  <data key="d0">reference</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Dai et al. (2019)</data>
  <data key="d4">A reference to prior work on generative language modeling.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Radford et al. (2019)">
  <data key="d0">reference</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Radford et al. (2019)</data>
  <data key="d4">A reference to prior work on generative language modeling.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Cohan et al. (2018)">
  <data key="d0">reference</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Cohan et al. (2018)</data>
  <data key="d4">A reference to prior work on summarization datasets.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BlockSparse">
  <data key="d0">method</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">BlockSparse</data>
  <data key="d4">A method implemented in C++ for specific versions of TensorFlow.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="CUDA">
  <data key="d0">technology</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">CUDA</data>
  <data key="d4">A parallel computing platform and application programming interface model created by NVIDIA.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="TensorFlow">
  <data key="d0">framework</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">TensorFlow</data>
  <data key="d4">An open-source machine learning framework.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="QA">
  <data key="d0">task</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">QA</data>
  <data key="d4">Question Answering, a natural language processing task.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="coreference resolution">
  <data key="d0">task</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">coreference resolution</data>
  <data key="d4">The task of determining when different expressions refer to the same entity.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LED">
  <data key="d0">model</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">LED</data>
  <data key="d4">Longformer-Encoder-Decoder, a variant of Longformer for sequence-to-sequence learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BP-Transformer">
  <data key="d0">model</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">BP-Transformer</data>
  <data key="d4">A transformer model evaluated on machine translation tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="CPC loss">
  <data key="d0">metric</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">CPC loss</data>
  <data key="d4">Contrastive Predictive Coding loss, an additional training objective.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BigBird">
  <data key="d0">model</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">BigBird</data>
  <data key="d4">An extension of ETC for long document tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ETC">
  <data key="d0">model</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">ETC</data>
  <data key="d4">A transformer model that uses local + global attention.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="SQuAD">
  <data key="d0">dataset</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">SQuAD</data>
  <data key="d4">Stanford Question Answering Dataset, typically fits within the 512 limit.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MRQA">
  <data key="d0">dataset</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">MRQA</data>
  <data key="d4">Machine Reading for Question Answering, constructed by dropping long-document examples.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="dilated CNNs">
  <data key="d0">method</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">dilated CNNs</data>
  <data key="d4">Convolutional neural networks that use dilated convolutions.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Sutskever et al. (2014)">
  <data key="d0">publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Sutskever et al. (2014)</data>
  <data key="d4">The paper introducing sequence-to-sequence learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Xie et al. (2019)">
  <data key="d0">publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Xie et al. (2019)</data>
  <data key="d4">Research on truncating documents for classification.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Clark and Gardner (2017)">
  <data key="d0">publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Clark and Gardner (2017)</data>
  <data key="d4">Research on two-stage models for open domain QA.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Chen et al. (2017)">
  <data key="d0">publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Chen et al. (2017)</data>
  <data key="d4">Research related to answer extraction in QA.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Gupta and Berant (2020)">
  <data key="d0">publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Gupta and Berant (2020)</data>
  <data key="d4">Research on using global memory in models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Kovaleva et al. (2019)">
  <data key="d0">publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Kovaleva et al. (2019)</data>
  <data key="d4">Research on the importance of local context.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Josh et al. (2019)">
  <data key="d0">publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Josh et al. (2019)</data>
  <data key="d4">Research on processing document chunks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Wu et al. (2019)">
  <data key="d0">publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Wu et al. (2019)</data>
  <data key="d4">Research on CNNs and their representation capabilities.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="vandenOord et al. (2016)">
  <data key="d0">publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">vandenOord et al. (2016)</data>
  <data key="d4">Research on dilated convolutions.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Ye et al. (2019)">
  <data key="d0">publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Ye et al. (2019)</data>
  <data key="d4">Research on evaluating transformer models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BERT">
  <data key="d0">model</data>
  <data key="d1">longformer,palm,reformer</data>
  <data key="d2">3</data>
  <data key="d3">BERT</data>
  <data key="d4">A state-of-the-art model for natural language processing tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Global Attention">
  <data key="d0">method</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Global Attention</data>
  <data key="d4">An attention mechanism that allows certain tokens to attend to all tokens in the sequence.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Masked Language Modeling (MLM)">
  <data key="d0">task</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Masked Language Modeling (MLM)</data>
  <data key="d4">A task where the model predicts masked words in a sequence.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Question Answering (QA)">
  <data key="d0">task</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Question Answering (QA)</data>
  <data key="d4">A task where the model answers questions based on a given document.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Adaptive Span">
  <data key="d0">model</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Adaptive Span</data>
  <data key="d4">A model that adapts the attention span based on the input.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Compressive Transformer">
  <data key="d0">model</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Compressive Transformer</data>
  <data key="d4">A transformer model that compresses information to handle longer sequences.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Reformer">
  <data key="d0">model</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Reformer</data>
  <data key="d4">A transformer model that uses reversible layers to reduce memory usage.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Dataset text8">
  <data key="d0">dataset</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Dataset text8</data>
  <data key="d4">A dataset used for training language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Dataset enwik8">
  <data key="d0">dataset</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Dataset enwik8</data>
  <data key="d4">A dataset used for evaluating language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="TVM">
  <data key="d0">technology</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">TVM</data>
  <data key="d4">An open-source deep learning compiler stack.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="PyTorch">
  <data key="d0">library</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">PyTorch</data>
  <data key="d4">An open-source machine learning library used for deep learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Sukhbaatar et al. (2019)">
  <data key="d0">publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Sukhbaatar et al. (2019)</data>
  <data key="d4">A reference to a paper that discusses adaptive attention spans.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Child et al. (2019)">
  <data key="d0">publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Child et al. (2019)</data>
  <data key="d4">A reference to a paper that discusses sparse transformers.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Al-Rfou et al. (2018)">
  <data key="d0">publication</data>
  <data key="d1">longformer,transformer_xl</data>
  <data key="d2">2</data>
  <data key="d3">Al-Rfou et al. (2018)</data>
  <data key="d4">A reference to a paper that discusses the T12 dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MLM">
  <data key="d0">Method</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">MLM</data>
  <data key="d4">Masked Language Modeling, a pretraining objective for language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Attention Pattern">
  <data key="d0">Method</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Attention Pattern</data>
  <data key="d4">A technique for configuring attention mechanisms in transformer models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Gradient Updates">
  <data key="d0">Metric</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Gradient Updates</data>
  <data key="d4">The number of updates applied during model training.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="HotpotQA">
  <data key="d0">Dataset</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">HotpotQA</data>
  <data key="d4">A multi-hop question answering dataset that requires evidence extraction.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="fairseq">
  <data key="d0">Framework</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">fairseq</data>
  <data key="d4">A sequence-to-sequence learning toolkit for training models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Clark and Gardner">
  <data key="d0">People</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Clark and Gardner</data>
  <data key="d4">Researchers who proposed a loss function for question answering.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Ott et al.">
  <data key="d0">People</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Ott et al.</data>
  <data key="d4">Researchers who contributed to the fairseq framework.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Devlin et al.">
  <data key="d0">People</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Devlin et al.</data>
  <data key="d4">Researchers who developed the BERT model.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Liu et al.">
  <data key="d0">People</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Liu et al.</data>
  <data key="d4">Researchers who introduced the RoBERTa model.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Rae et al.">
  <data key="d0">People</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Rae et al.</data>
  <data key="d4">Researchers who discussed configurations for transformer models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Clark et al.">
  <data key="d0">People</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Clark et al.</data>
  <data key="d4">Researchers who analyzed BERT's attention heads.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="RoBERTa-large">
  <data key="d0">Model</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">RoBERTa-large</data>
  <data key="d4">A transformer-based model for natural language processing.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Longformer-large">
  <data key="d0">Model</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Longformer-large</data>
  <data key="d4">A transformer model designed for long document processing.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Frozen RoBERTa Weights">
  <data key="d0">Method</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Frozen RoBERTa Weights</data>
  <data key="d4">A technique where the weights of the RoBERTa model are kept constant during training.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="OntoNotes">
  <data key="d0">Dataset</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">OntoNotes</data>
  <data key="d4">A dataset used for coreference resolution.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="IMDB">
  <data key="d0">Dataset</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">IMDB</data>
  <data key="d4">A dataset for sentiment classification based on movie reviews.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Hyperpartisan">
  <data key="d0">Dataset</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Hyperpartisan</data>
  <data key="d4">A dataset for detecting hyperpartisan news.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BPC">
  <data key="d0">Metric</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">BPC</data>
  <data key="d4">Bits per character, a measure of model performance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="GNN">
  <data key="d0">Method</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">GNN</data>
  <data key="d4">Graph Neural Networks, used for reasoning over entities.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Joshi et al. (2019)">
  <data key="d0">Publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Joshi et al. (2019)</data>
  <data key="d4">A paper that presents a model for coreference resolution.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BART">
  <data key="d0">Model</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">BART</data>
  <data key="d4">A pre-trained encoder-decoder model for sequence-to-sequence tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="T5">
  <data key="d0">Model</data>
  <data key="d1">longformer,palm</data>
  <data key="d2">2</data>
  <data key="d3">T5</data>
  <data key="d4">A text-to-text transfer transformer model.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Lee et al. (2018)">
  <data key="d0">Publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Lee et al. (2018)</data>
  <data key="d4">A paper that discusses replacing ELMo with BERT.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Fang et al. (2020)">
  <data key="d0">Publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Fang et al. (2020)</data>
  <data key="d4">A paper that presents a state-of-the-art model for HotpotQA.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Tu et al. (2019)">
  <data key="d0">Publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Tu et al. (2019)</data>
  <data key="d4">A paper that discusses a model for question answering.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Shao et al. (2020)">
  <data key="d0">Publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Shao et al. (2020)</data>
  <data key="d4">A paper that presents a model for question answering.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Kipf and Welling (2017)">
  <data key="d0">Publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Kipf and Welling (2017)</data>
  <data key="d4">A paper that discusses Graph Neural Networks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Glaß et al. (2019)">
  <data key="d0">Publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Glaß et al. (2019)</data>
  <data key="d4">A paper that presents a non-GNN method for question answering.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Groeneveld et al. (2020)">
  <data key="d0">Publication</data>
  <data key="d1">longformer</data>
  <data key="d2">1</data>
  <data key="d3">Groeneveld et al. (2020)</data>
  <data key="d4">A paper that discusses a model for question answering.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Pathways">
  <data key="d0">System</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Pathways</data>
  <data key="d4">A new ML system enabling efficient training across multiple TPU Pods.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="TPUv4">
  <data key="d0">Hardware</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">TPUv4</data>
  <data key="d4">Tensor Processing Unit version 4 used for training the model.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BIG-bench">
  <data key="d0">Benchmark</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">BIG-bench</data>
  <data key="d4">A benchmark suite for evaluating language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Aakanksha Chowdhery">
  <data key="d0">Person</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Aakanksha Chowdhery</data>
  <data key="d4">One of the authors of the paper.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Sharan Narang">
  <data key="d0">Person</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Sharan Narang</data>
  <data key="d4">One of the authors of the paper.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Jacob Devlin">
  <data key="d0">Person</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Jacob Devlin</data>
  <data key="d4">One of the authors of the paper.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Sanjay Ghemawat">
  <data key="d0">Person</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Sanjay Ghemawat</data>
  <data key="d4">One of the authors of the paper.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Ethical Considerations">
  <data key="d0">Topic</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Ethical Considerations</data>
  <data key="d4">Discussion on the ethical implications of large language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Bias and Toxicity">
  <data key="d0">Analysis</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Bias and Toxicity</data>
  <data key="d4">Analysis of bias and toxicity in model outputs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Language Models (LMs)">
  <data key="d0">Technology</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Language Models (LMs)</data>
  <data key="d4">Models used for few-shot predictions based on natural language task descriptions.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Few-shot predictions">
  <data key="d0">Method</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Few-shot predictions</data>
  <data key="d4">A prediction method where the model is given a task description and a few exemplars.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="GLaM">
  <data key="d0">Model</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">GLaM</data>
  <data key="d4">A post-GPT-3 language model that achieved few-shot state-of-the-art results.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Megatron–Turing NLG">
  <data key="d0">Model</data>
  <data key="d1">palm,palm</data>
  <data key="d2">2</data>
  <data key="d3">Megatron-Turing NLG 530B,Megatron–Turing NLG</data>
  <data key="d4">A post-GPT-3 language model developed by Smith et al. in 2022.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Transformer architecture">
  <data key="d0">Architecture</data>
  <data key="d1">palm,swin_transformer</data>
  <data key="d2">2</data>
  <data key="d3">Transformer architecture</data>
  <data key="d4">The architecture used in GPT-3 and its variants.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="TPU v4 Pods">
  <data key="d0">Hardware</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">TPU v4 Pods</data>
  <data key="d4">A type of hardware used for training large models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="FLOPs utilization">
  <data key="d0">Metric</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">FLOPs utilization</data>
  <data key="d4">A measure of efficiency in model and hardware performance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Wei et al. (2022b)">
  <data key="d0">Person</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Wei et al. (2022b)</data>
  <data key="d4">Researchers who contributed to chain-of-thought prompting.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Du et al. (2021)">
  <data key="d0">Person</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Du et al. (2021)</data>
  <data key="d4">Researchers who developed GLaM.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Smith et al. (2022)">
  <data key="d0">Person</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Smith et al. (2022)</data>
  <data key="d4">Researchers who developed Megatron–Turing NLG.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Thoppilan et al. (2022)">
  <data key="d0">Person</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Thoppilan et al. (2022)</data>
  <data key="d4">Researchers who developed LaMDA.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Brown et al. (2020)">
  <data key="d0">Person</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Brown et al. (2020)</data>
  <data key="d4">Researchers who developed GPT-3.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="RoPE">
  <data key="d0">embedding</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">RoPE</data>
  <data key="d4">Rotary Position Embeddings used for better performance on long sequence lengths.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="SentencePiece">
  <data key="d0">tokenization method</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">SentencePiece</data>
  <data key="d4">A method used for generating a vocabulary of tokens from the training data.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Kaplan et al., 2020">
  <data key="d0">publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Kaplan et al., 2020</data>
  <data key="d4">A reference discussing the power law in neural network scaling.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Shazeer, 2020">
  <data key="d0">publication</data>
  <data key="d1">palm,palm</data>
  <data key="d2">2</data>
  <data key="d3">Shazeer, 2020,Shazeer, 2019</data>
  <data key="d4">A reference discussing the effectiveness of SwiGLU activations.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Wang &amp; Komatsuzaki, 2021">
  <data key="d0">publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Wang &amp; Komatsuzaki, 2021</data>
  <data key="d4">A reference discussing the parallel formulation in Transformer blocks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Kudo &amp; Richardson, 2018a">
  <data key="d0">publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Kudo &amp; Richardson, 2018a</data>
  <data key="d4">A reference discussing the SentencePiece vocabulary generation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="540B parameters">
  <data key="d0">Model Scale</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">540B parameters</data>
  <data key="d4">The largest model scale in the comparison.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="62B parameters">
  <data key="d0">Model Scale</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">62B parameters</data>
  <data key="d4">The medium model scale in the comparison.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="8B parameters">
  <data key="d0">Model Scale</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">8B parameters</data>
  <data key="d4">The smallest model scale in the comparison.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="FLOPs">
  <data key="d0">Metric</data>
  <data key="d1">palm,swin_transformer</data>
  <data key="d2">2</data>
  <data key="d3">FLOPs</data>
  <data key="d4">Floating Point Operations per second, approximately equal to the number of parameters.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Transformers">
  <data key="d0">Architecture</data>
  <data key="d1">palm,vision_transformer</data>
  <data key="d2">2</data>
  <data key="d3">Transformers</data>
  <data key="d4">A type of model architecture used for natural language processing.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="JAX">
  <data key="d0">Framework</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">JAX</data>
  <data key="d4">A framework used for training and evaluation codebase.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="T5X">
  <data key="d0">Framework</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">T5X</data>
  <data key="d4">A framework used for training and evaluation codebase.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="780 billion tokens">
  <data key="d0">Dataset Size</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">780 billion tokens</data>
  <data key="d4">The total size of the pretraining dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Filtered webpages">
  <data key="d0">Data Source</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Filtered webpages</data>
  <data key="d4">One of the sources used in the training dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="GitHub">
  <data key="d0">Data Source</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">GitHub</data>
  <data key="d4">Source of code included in the training dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Social media conversations">
  <data key="d0">Data Source</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Social media conversations</data>
  <data key="d4">One of the sources used in the training dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="News articles">
  <data key="d0">Data Source</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">News articles</data>
  <data key="d4">One of the sources used in the training dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Levenshtein distance">
  <data key="d0">Metric</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Levenshtein distance</data>
  <data key="d4">A method used to remove duplicate files in the dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Mitchell et al., 2019">
  <data key="d0">Publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Mitchell et al., 2019</data>
  <data key="d4">Authors of the Model Card for PaLM.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Thoppilan et al., 2022">
  <data key="d0">Publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Thoppilan et al., 2022</data>
  <data key="d4">Authors of the LaMDA model.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Du et al., 2021">
  <data key="d0">Publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Du et al., 2021</data>
  <data key="d4">Authors of the GLaM model.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Bradbury et al., 2018">
  <data key="d0">Publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Bradbury et al., 2018</data>
  <data key="d4">Authors of the JAX framework.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Roberts et al., 2022">
  <data key="d0">Publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Roberts et al., 2022</data>
  <data key="d4">Authors of the T5X framework.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Jouppi et al., 2020">
  <data key="d0">Publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Jouppi et al., 2020</data>
  <data key="d4">Authors of the TPU v4 Pods.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Xu et al., 2021">
  <data key="d0">Publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Xu et al., 2021</data>
  <data key="d4">Authors discussing model and data parallelism.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Huang et al., 2019">
  <data key="d0">Publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Huang et al., 2019</data>
  <data key="d4">Authors discussing pipeline parallelism.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Lopes et al., 2017">
  <data key="d0">Publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Lopes et al., 2017</data>
  <data key="d4">Authors discussing duplicate files in source code.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Allamanis, 2019">
  <data key="d0">Publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Allamanis, 2019</data>
  <data key="d4">Authors discussing duplicate files in source code.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Gebru et al., 2021">
  <data key="d0">Publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Gebru et al., 2021</data>
  <data key="d4">Authors of the datasheet providing additional information.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Pathways system">
  <data key="d0">system</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Pathways system</data>
  <data key="d4">A system designed to scale training across TPU pods using two-way data parallelism.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="TPU v4">
  <data key="d0">hardware</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">TPU v4</data>
  <data key="d4">A type of Tensor Processing Unit used for accelerating machine learning workloads.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="JAX/XLA">
  <data key="d0">software</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">JAX/XLA</data>
  <data key="d4">A framework for high-performance numerical computing and machine learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Python client">
  <data key="d0">software</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Python client</data>
  <data key="d4">A client that constructs a sharded dataflow program for executing computations.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Gradient transfer">
  <data key="d0">method</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Gradient transfer</data>
  <data key="d4">The process of transferring computed gradients between TPU pods.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Model FLOPs utilization (MFU)">
  <data key="d0">metric</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Model FLOPs utilization (MFU)</data>
  <data key="d4">A metric for measuring training efficiency based on observed throughput relative to theoretical maximum throughput.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Hardware FLOPs utilization (HFU)">
  <data key="d0">metric</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Hardware FLOPs utilization (HFU)</data>
  <data key="d4">A metric reflecting the ratio of FLOPs observed on a device to its theoretical peak FLOPs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Rematerialization">
  <data key="d0">method</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Rematerialization</data>
  <data key="d4">A technique to trade off memory usage with compute by recomputing certain operations.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Megatron-Turing NLG">
  <data key="d0">model</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Megatron-Turing NLG</data>
  <data key="d4">A large language model with 530 billion parameters.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Google datacenter network">
  <data key="d0">infrastructure</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Google datacenter network</data>
  <data key="d4">The network infrastructure connecting TPU pods for data transfer.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Barham et al., 2022">
  <data key="d0">publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Barham et al., 2022</data>
  <data key="d4">A reference for the Pathways system and its design.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Singh et al., 2015">
  <data key="d0">publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Singh et al., 2015</data>
  <data key="d4">A reference for the Google datacenter network.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Narayanan et al., 2021b">
  <data key="d0">publication</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Narayanan et al., 2021b</data>
  <data key="d4">A reference for analytical accounting of hardware FLOPs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Appendix B">
  <data key="d0">document section</data>
  <data key="d1">palm</data>
  <data key="d2">1</data>
  <data key="d3">Appendix B</data>
  <data key="d4">Section detailing the mathematical formula to compute MFU.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Classification Token">
  <data key="d0">Model Component</data>
  <data key="d1">reformer</data>
  <data key="d2">1</data>
  <data key="d3">Classification Token</data>
  <data key="d4">A learnable embedding added to the input sequence for classification tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="2D image topology">
  <data key="d0">concept</data>
  <data key="d1">reformer</data>
  <data key="d2">1</data>
  <data key="d3">2D image topology</data>
  <data key="d4">The spatial arrangement of pixels in a two-dimensional image.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="masked patch prediction">
  <data key="d0">method</data>
  <data key="d1">reformer,vision_transformer</data>
  <data key="d2">2</data>
  <data key="d3">masked patch prediction</data>
  <data key="d4">A self-supervised learning task that involves predicting missing parts of an image.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LLaVA">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">LLaVA</data>
  <data key="d4">Large Language and Vision Assistant, an end-to-end trained large multimodal model.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Vicuna">
  <data key="d0">model</data>
  <data key="d1">segment_anything,segment_anything</data>
  <data key="d2">2</data>
  <data key="d3">Vicuna,Vicuna-v0</data>
  <data key="d4">Language decoder connected to the visual encoder in LLaVA.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Science QA">
  <data key="d0">dataset</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">Science QA</data>
  <data key="d4">A multimodal reasoning dataset used for evaluating LLaVA.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LLaVA-Bench">
  <data key="d0">benchmark</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">LLaVA-Bench</data>
  <data key="d4">A set of two challenging benchmarks for evaluating multimodal instruction-following.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ChatGPT">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">ChatGPT</data>
  <data key="d4">A conversational AI model developed by OpenAI, demonstrating the power of aligned LLMs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Alpaca">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">Alpaca</data>
  <data key="d4">An open-source LLM that matches the performance of GPT-3.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="InstructPix2Pix">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">InstructPix2Pix</data>
  <data key="d4">An image editing model that follows human instructions.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Flamingo">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">Flamingo</data>
  <data key="d4">A multimodal model known for strong performance on zero-shot task transfer.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BLIP-2">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">BLIP-2</data>
  <data key="d4">A model trained on image-text pairs for multimodal tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="FROMAGe">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">FROMAGe</data>
  <data key="d4">A model for multimodal tasks, trained on image-text pairs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="KOSMOS-1">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">KOSMOS-1</data>
  <data key="d4">A multimodal model trained on image-text pairs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="PaLM-E">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">PaLM-E</data>
  <data key="d4">A large multimodal model for embodied AI.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="OpenFlamingo">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">OpenFlamingo</data>
  <data key="d4">An open-source effort enabling LLaMA to use image inputs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LangChain">
  <data key="d0">framework</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">LangChain</data>
  <data key="d4">A system that coordinates various models via LLMs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Visual ChatGPT">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">Visual ChatGPT</data>
  <data key="d4">A multimodal model that integrates visual and language capabilities.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="X-GPT">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">X-GPT</data>
  <data key="d4">A multimodal model that integrates visual and language capabilities.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MM-REACT">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">MM-REACT</data>
  <data key="d4">A multimodal model that integrates visual and language capabilities.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="VisProg">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">VisProg</data>
  <data key="d4">A multimodal model that integrates visual and language capabilities.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ViperGPT">
  <data key="d0">model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">ViperGPT</data>
  <data key="d4">A multimodal model that integrates visual and language capabilities.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LMM">
  <data key="d0">Technology</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">LMM</data>
  <data key="d4">Large Multimodal Model used for zero-shot task transfer and in-context learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LLaMA-Adapter">
  <data key="d0">Model</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">LLaMA-Adapter</data>
  <data key="d4">An open-source adaptation of LLaMA for image inputs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="visual instruction tuning">
  <data key="d0">Method</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">visual instruction tuning</data>
  <data key="d4">A method aimed at improving model instruction-following abilities.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="visual prompt tuning">
  <data key="d0">Method</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">visual prompt tuning</data>
  <data key="d4">A method aimed at improving parameter efficiency in model adaptation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="COCO">
  <data key="d0">Dataset</data>
  <data key="d1">segment_anything,swin_transformer</data>
  <data key="d2">2</data>
  <data key="d3">COCO</data>
  <data key="d4">A dataset used for generating instruction-following data.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="CC">
  <data key="d0">Dataset</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">CC</data>
  <data key="d4">A public multimodal dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LAION">
  <data key="d0">Dataset</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">LAION</data>
  <data key="d4">Another public multimodal dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="image-text pairs">
  <data key="d0">Data Type</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">image-text pairs</data>
  <data key="d4">Data consisting of images and their corresponding textual descriptions.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="visual feature Z">
  <data key="d0">data</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">visual feature Z</data>
  <data key="d4">The output feature representation from the visual encoder.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="language embedding tokens H">
  <data key="d0">data</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">language embedding tokens H</data>
  <data key="d4">Tokens representing language embeddings in the model.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="projection matrix W">
  <data key="d0">method</data>
  <data key="d1">segment_anything,segment_anything</data>
  <data key="d2">2</data>
  <data key="d3">projection matrix W,projection matrix</data>
  <data key="d4">A trainable matrix used to convert visual features into language embedding tokens.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="CC3M">
  <data key="d0">dataset</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">CC3M</data>
  <data key="d4">A dataset containing image-text pairs used for training.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="multi-turn conversation data">
  <data key="d0">data</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">multi-turn conversation data</data>
  <data key="d4">Data format used for training the model with multiple conversational turns.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="instruction tokens X">
  <data key="d0">data</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">instruction tokens X</data>
  <data key="d4">Tokens representing instructions given to the model.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="assistant answers X">
  <data key="d0">data</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">assistant answers X</data>
  <data key="d4">Tokens representing the responses generated by the assistant.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LLM">
  <data key="d0">technology</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">LLM</data>
  <data key="d4">Large Language Model used in conjunction with visual encoders.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="visual encoder">
  <data key="d0">architecture</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">visual encoder</data>
  <data key="d4">A component that processes visual inputs.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ScienceQA">
  <data key="d0">dataset</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">ScienceQA</data>
  <data key="d4">A large-scale multimodal science question dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LLaVA-Instruct-158K">
  <data key="d0">dataset</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">LLaVA-Instruct-158K</data>
  <data key="d4">A dataset used for fine-tuning LLaVA.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="A100">
  <data key="d0">hardware</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">A100</data>
  <data key="d4">NVIDIA A100 GPUs used for training the models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="instruction-following capability">
  <data key="d0">metric</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">instruction-following capability</data>
  <data key="d4">A measure of how well the model follows user instructions.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="training data">
  <data key="d0">method</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">training data</data>
  <data key="d4">Data organized as single-turn conversations for training.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="evaluation metric">
  <data key="d0">metric</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">evaluation metric</data>
  <data key="d4">A quantitative measure to assess model performance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="COCO-Val-2014">
  <data key="d0">dataset</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">COCO-Val-2014</data>
  <data key="d4">A dataset used to generate questions for evaluating models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MM-CoT">
  <data key="d0">method</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">MM-CoT</data>
  <data key="d4">Multimodal chain-of-thought method used as a state-of-the-art approach on the ScienceQA dataset.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="mean±std">
  <data key="d0">metric</data>
  <data key="d1">segment_anything</data>
  <data key="d2">1</data>
  <data key="d3">mean±std</data>
  <data key="d4">Statistical representation of model performance results.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Swin Transformer">
  <data key="d0">architecture</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Swin Transformer</data>
  <data key="d4">A hierarchical vision transformer designed for computer vision tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Microsoft Research Asia">
  <data key="d0">organization</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Microsoft Research Asia</data>
  <data key="d4">The organization where the authors of the paper are affiliated.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Ze Liu">
  <data key="d0">person</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Ze Liu</data>
  <data key="d4">One of the authors of the paper.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Yutong Lin">
  <data key="d0">person</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Yutong Lin</data>
  <data key="d4">One of the authors of the paper.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Yue Cao">
  <data key="d0">person</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Yue Cao</data>
  <data key="d4">One of the authors of the paper.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Han Hu">
  <data key="d0">person</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Han Hu</data>
  <data key="d4">One of the authors of the paper.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Yixuan Wei">
  <data key="d0">person</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Yixuan Wei</data>
  <data key="d4">One of the authors of the paper.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Zheng Zhang">
  <data key="d0">person</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Zheng Zhang</data>
  <data key="d4">One of the authors of the paper.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Stephen Lin">
  <data key="d0">person</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Stephen Lin</data>
  <data key="d4">One of the authors of the paper.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Baining Guo">
  <data key="d0">person</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Baining Guo</data>
  <data key="d4">One of the authors of the paper.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ADE20K">
  <data key="d0">dataset</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">ADE20K</data>
  <data key="d4">A dataset used for semantic segmentation tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="feature pyramid networks (FPN)">
  <data key="d0">method</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">feature pyramid networks (FPN)</data>
  <data key="d4">A technique for dense predictions in computer vision.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="U-Net">
  <data key="d0">method</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">U-Net</data>
  <data key="d4">A convolutional network architecture for semantic segmentation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ViT/DeiT">
  <data key="d0">architecture</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">ViT/DeiT</data>
  <data key="d4">Previous vision transformer architectures that Swin Transformer outperforms.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Copy-paste">
  <data key="d0">method</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Copy-paste</data>
  <data key="d4">A technique used in object detection that Swin Transformer improves upon.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="DetectoRS">
  <data key="d0">method</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">DetectoRS</data>
  <data key="d4">A method for object detection that Swin Transformer surpasses.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="SETR">
  <data key="d0">method</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">SETR</data>
  <data key="d4">A method for semantic segmentation that Swin Transformer outperforms.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="mIoU">
  <data key="d0">metric</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">mIoU</data>
  <data key="d4">Mean Intersection over Union, a metric for evaluating segmentation tasks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="AlexNet">
  <data key="d0">architecture</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">AlexNet</data>
  <data key="d4">A pioneering CNN that popularized deep learning in computer vision.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="VGG">
  <data key="d0">architecture</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">VGG</data>
  <data key="d4">A deep CNN architecture known for its simplicity and depth.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="GoogleNet">
  <data key="d0">architecture</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">GoogleNet</data>
  <data key="d4">A CNN architecture that introduced the inception module.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="DenseNet">
  <data key="d0">architecture</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">DenseNet</data>
  <data key="d4">A CNN architecture that connects each layer to every other layer.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="HRNet">
  <data key="d0">architecture</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">HRNet</data>
  <data key="d4">High-Resolution Network for maintaining high-resolution representations.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ViT">
  <data key="d0">architecture</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">ViT</data>
  <data key="d4">Vision Transformer, a model that applies transformer architecture to image classification.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="patch merging">
  <data key="d0">method</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">patch merging</data>
  <data key="d4">A technique used in Swin Transformer to reduce the number of tokens.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="linear embedding">
  <data key="d0">method</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">linear embedding</data>
  <data key="d4">A process to project raw pixel values into an arbitrary dimension.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="DeiT">
  <data key="d0">architecture</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">DeiT</data>
  <data key="d4">Data-efficient image Transformers, which introduces training strategies for ViT.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MLP">
  <data key="d0">method</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">MLP</data>
  <data key="d4">Multi-layer perceptron, a type of neural network.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="W-MSA">
  <data key="d0">module</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">W-MSA</data>
  <data key="d4">Window-based multi-head self-attention module.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="SW-MSA">
  <data key="d0">module</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">SW-MSA</data>
  <data key="d4">Shifted window-based multi-head self-attention module.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Stage 1">
  <data key="d0">process</data>
  <data key="d1">swin_transformer,swin_transformer,swin_transformer,swin_transformer</data>
  <data key="d2">4</data>
  <data key="d3">Stage 3,Stage 2,Stage 1,Stage 4</data>
  <data key="d4">The first stage of the Swin Transformer architecture.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="RegNet">
  <data key="d0">architecture</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">RegNet</data>
  <data key="d4">A family of convolutional neural networks optimized through architecture search.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Relative Position Bias">
  <data key="d0">method</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Relative Position Bias</data>
  <data key="d4">A technique used in self-attention mechanisms to incorporate positional information.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Top-1 Accuracy">
  <data key="d0">metric</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Top-1 Accuracy</data>
  <data key="d4">A metric used to evaluate the performance of classification models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Batch Size">
  <data key="d0">parameter</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Batch Size</data>
  <data key="d4">The number of training examples utilized in one iteration.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Cyclic Shifting">
  <data key="d0">method</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Cyclic Shifting</data>
  <data key="d4">A technique proposed to improve batch computation efficiency in window partitioning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Swin-T">
  <data key="d0">model variant</data>
  <data key="d1">swin_transformer,swin_transformer,swin_transformer,swin_transformer</data>
  <data key="d2">4</data>
  <data key="d3">Swin-T,Swin-B,Swin-S,Swin-L</data>
  <data key="d4">A variant of the Swin Transformer with specific hyperparameters.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Cascade Mask R-CNN">
  <data key="d0">framework</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Cascade Mask R-CNN</data>
  <data key="d4">An object detection framework used for instance segmentation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="ATSS">
  <data key="d0">framework</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">ATSS</data>
  <data key="d4">An object detection framework used for instance segmentation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="RepPoints v2">
  <data key="d0">framework</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">RepPoints v2</data>
  <data key="d4">An object detection framework used for instance segmentation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Sparse RCNN">
  <data key="d0">framework</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Sparse RCNN</data>
  <data key="d4">An object detection framework used for instance segmentation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="HTC++">
  <data key="d0">Framework</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">HTC++</data>
  <data key="d4">An improved version of the HTC framework for object detection.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="APbox">
  <data key="d0">Metric</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">APbox</data>
  <data key="d4">Average Precision for bounding box detection.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="APmask">
  <data key="d0">Metric</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">APmask</data>
  <data key="d4">Average Precision for mask prediction in instance segmentation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="DeiT-S">
  <data key="d0">Model</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">DeiT-S</data>
  <data key="d4">Data-efficient image Transformers, a model architecture for image classification.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="EfficientDet-D7">
  <data key="d0">Model</data>
  <data key="d1">swin_transformer</data>
  <data key="d2">1</data>
  <data key="d3">EfficientDet-D7</data>
  <data key="d4">A model architecture for object detection that balances accuracy and efficiency.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LSTM">
  <data key="d0">architecture</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">LSTM</data>
  <data key="d4">Long Short-Term Memory networks, a standard solution for language modeling.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="RNN">
  <data key="d0">architecture</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">RNN</data>
  <data key="d4">Recurrent Neural Networks, a type of neural network for sequential data.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Carnegie Mellon University">
  <data key="d0">organization</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Carnegie Mellon University</data>
  <data key="d4">An academic institution where some authors are affiliated.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="WikiText-103">
  <data key="d0">dataset</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">WikiText-103</data>
  <data key="d4">A dataset used for language modeling.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="One Billion Word">
  <data key="d0">dataset</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">One Billion Word</data>
  <data key="d4">A large dataset for language modeling.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="context fragmentation">
  <data key="d0">problem</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">context fragmentation</data>
  <data key="d4">The issue of losing contextual information due to fixed-length segments.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="gradient vanishing">
  <data key="d0">problem</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">gradient vanishing</data>
  <data key="d4">A common issue in training RNNs that affects optimization.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="gradient explosion">
  <data key="d0">problem</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">gradient explosion</data>
  <data key="d4">A common issue in training RNNs that affects optimization.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Softmax function">
  <data key="d0">function</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Softmax function</data>
  <data key="d4">A function that converts logits into a categorical probability distribution.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Bengio et al. (2003)">
  <data key="d0">publication</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Bengio et al. (2003)</data>
  <data key="d4">A foundational paper in language modeling.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Mikolov et al. (2010)">
  <data key="d0">publication</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Mikolov et al. (2010)</data>
  <data key="d4">A significant work on RNNs and language modeling.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Merity et al. (2016)">
  <data key="d0">publication</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Merity et al. (2016)</data>
  <data key="d4">Research on language modeling techniques.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Galand Ghahramani (2016)">
  <data key="d0">publication</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Galand Ghahramani (2016)</data>
  <data key="d4">Work on improving optimization algorithms.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Grave et al. (2016a)">
  <data key="d0">publication</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Grave et al. (2016a)</data>
  <data key="d4">Research on speeding up Softmax computation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Yang et al. (2017)">
  <data key="d0">publication</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Yang et al. (2017)</data>
  <data key="d4">Work on enriching output distribution families.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Peters et al. (2018)">
  <data key="d0">publication</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Peters et al. (2018)</data>
  <data key="d4">Research on efficiency in language modeling.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Devlin et al. (2018)">
  <data key="d0">publication</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Devlin et al. (2018)</data>
  <data key="d4">Contributions to language modeling techniques.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="SG function">
  <data key="d0">function</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">SG function</data>
  <data key="d4">Stop-gradient function used to prevent gradient flow.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="positional encodings">
  <data key="d0">concept</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">positional encodings</data>
  <data key="d4">Encodings that provide sequence order information in Transformers.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="hidden state">
  <data key="d0">concept</data>
  <data key="d1">transformer_xl,transformer_xl</data>
  <data key="d2">2</data>
  <data key="d3">hidden states,hidden state</data>
  <data key="d4">The internal state representation in neural networks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="logits">
  <data key="d0">concept</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">logits</data>
  <data key="d4">Raw output scores from the model before applying Softmax.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="long-term dependency">
  <data key="d0">concept</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">long-term dependency</data>
  <data key="d4">The ability to model dependencies over long sequences.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="BPTT">
  <data key="d0">method</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">BPTT</data>
  <data key="d4">Backpropagation Through Time, a technique for training recurrent neural networks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="enwiki8">
  <data key="d0">dataset</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">enwiki8</data>
  <data key="d4">A dataset used for evaluating language models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="GPU memory">
  <data key="d0">resource</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">GPU memory</data>
  <data key="d4">Graphics Processing Unit memory used for storing data during model training and evaluation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="memory augmented neural networks">
  <data key="d0">architecture</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">memory augmented neural networks</data>
  <data key="d4">Neural networks that utilize external memory to enhance learning.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="attention score">
  <data key="d0">metric</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">attention score</data>
  <data key="d4">A score that determines the importance of different elements in a sequence.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="query vector">
  <data key="d0">concept</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">query vector</data>
  <data key="d4">A vector representing the current input in the attention mechanism.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="key vector">
  <data key="d0">concept</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">key vector</data>
  <data key="d4">A vector used in the attention mechanism to determine relevance.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="content-based addressing">
  <data key="d0">method</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">content-based addressing</data>
  <data key="d4">A method of addressing memory based on the content of the input.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="location-based key vectors">
  <data key="d0">concept</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">location-based key vectors</data>
  <data key="d4">Key vectors that are influenced by the position of the input.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Shaw et al. (2018)">
  <data key="d0">publication</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Shaw et al. (2018)</data>
  <data key="d4">A paper that explored relative positional encodings in machine translation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Huang et al. (2018)">
  <data key="d0">publication</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Huang et al. (2018)</data>
  <data key="d4">A paper that applied relative positional encodings in music generation.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Masked-Softmax">
  <data key="d0">method</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Masked-Softmax</data>
  <data key="d4">A variant of the softmax function used in attention mechanisms.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="LayerNorm">
  <data key="d0">method</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">LayerNorm</data>
  <data key="d4">A normalization technique applied to layers in neural networks.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Positionwise-Feed-Forward">
  <data key="d0">method</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Positionwise-Feed-Forward</data>
  <data key="d4">A feed-forward neural network applied independently to each position in the input.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="absolute positional embedding">
  <data key="d0">concept</data>
  <data key="d1">transformer_xl,transformer_xl</data>
  <data key="d2">2</data>
  <data key="d3">absolute positional embedding,relative positional embedding</data>
  <data key="d4">A method for encoding the position of tokens in a sequence.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="u">
  <data key="d0">parameter</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">u</data>
  <data key="d4">A trainable parameter introduced to replace the query vector in the attention mechanism.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="v">
  <data key="d0">parameter</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">v</data>
  <data key="d4">A trainable parameter added to substitute the query vector in the attention mechanism.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="bits per character (bpc)">
  <data key="d0">metric</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">bits per character (bpc)</data>
  <data key="d4">A metric used to evaluate language models based on the number of bits needed to encode characters.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Baevski and Auli">
  <data key="d0">people</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Baevski and Auli</data>
  <data key="d4">Researchers who contributed to the development of adaptive input representations.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Grave et al. (2016)">
  <data key="d0">citation</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Grave et al. (2016)</data>
  <data key="d4">Authors of a paper discussing neural cache mechanisms.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Dauphin et al. (2016)">
  <data key="d0">citation</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Dauphin et al. (2016)</data>
  <data key="d4">Authors of a paper discussing GCNN architectures.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="AWD-LSTM">
  <data key="d0">architecture</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">AWD-LSTM</data>
  <data key="d4">A type of LSTM model that incorporates dropout and weight averaging.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="MoS">
  <data key="d0">architecture</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">MoS</data>
  <data key="d4">A method proposed by Yang et al. for fine-tuning models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Khandelwal et al. (2018)">
  <data key="d0">person</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Khandelwal et al. (2018)</data>
  <data key="d4">Proposed a method to evaluate Effective Context Length (ECL).</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Effective Context Length (ECL)">
  <data key="d0">metric</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Effective Context Length (ECL)</data>
  <data key="d4">The longest length to which increasing context span leads to performance gain.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Relative Effective Context Length (RECL)">
  <data key="d0">metric</data>
  <data key="d1">transformer_xl</data>
  <data key="d2">1</data>
  <data key="d3">Relative Effective Context Length (RECL)</data>
  <data key="d4">A metric to measure the relative improvement of context length in models.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Layer Normalization (LN)">
  <data key="d0">Technique</data>
  <data key="d1">vision_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Layer Normalization (LN)</data>
  <data key="d4">A technique applied before every block in the Transformer encoder.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Residual Connections">
  <data key="d0">Technique</data>
  <data key="d1">vision_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Residual Connections</data>
  <data key="d4">Connections added after every block in the Transformer encoder.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Self-Supervision">
  <data key="d0">Learning Method</data>
  <data key="d1">vision_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Self-Supervision</data>
  <data key="d4">A method explored for training the Vision Transformer.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="R50x1">
  <data key="d0">model</data>
  <data key="d1">vision_transformer,vision_transformer</data>
  <data key="d2">2</data>
  <data key="d3">R50x1,R50x2</data>
  <data key="d4">ResNet model variant</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="R101x1">
  <data key="d0">model</data>
  <data key="d1">vision_transformer</data>
  <data key="d2">1</data>
  <data key="d3">R101x1</data>
  <data key="d4">ResNet model variant</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="R152x1">
  <data key="d0">model</data>
  <data key="d1">vision_transformer,vision_transformer</data>
  <data key="d2">2</data>
  <data key="d3">R152x1,R152x2</data>
  <data key="d4">ResNet model variant</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="R200x3">
  <data key="d0">model</data>
  <data key="d1">vision_transformer</data>
  <data key="d2">1</data>
  <data key="d3">R200x3</data>
  <data key="d4">ResNet model variant</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="hybrids">
  <data key="d0">architecture</data>
  <data key="d1">vision_transformer</data>
  <data key="d2">1</data>
  <data key="d3">hybrids</data>
  <data key="d4">Combination of ResNet and Vision Transformer architectures</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="position embeddings">
  <data key="d0">concept</data>
  <data key="d1">vision_transformer</data>
  <data key="d2">1</data>
  <data key="d3">position embeddings</data>
  <data key="d4">Learned representations that encode the spatial information of image patches.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<node id="Google">
  <data key="d0">organization</data>
  <data key="d1">vision_transformer</data>
  <data key="d2">1</data>
  <data key="d3">Google</data>
  <data key="d4">The organization where the research was conducted.</data>
  <data key="d5">0</data>
  <data key="d6">0</data>
  <data key="d7">0</data>
</node>
<edge source="Transformer" target="Attention Mechanism">
  <data key="d8">based_on</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Transformer" target="BLEU">
  <data key="d8">improves</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Transformer" target="WMT 2014 English-to-German">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Transformer" target="WMT 2014 English-to-French">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Transformer" target="Self-Attention">
  <data key="d8">is_based_on</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Google Brain" target="Ashish Vaswani">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Google Brain" target="Noam Shazeer">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Google Brain" target="Niki Parmar">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Google Brain" target="Jakob Uszkoreit">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Google Brain" target="Llion Jones">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Google Brain" target="Aidan N. Gomez">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Google Brain" target="Łukasz Kaiser">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Google Brain" target="Illia Polosukhin">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Google Research" target="Vision Transformer (ViT)">
  <data key="d8">authored</data>
  <data key="d9">2</data>
  <data key="d10">deit,vision_transformer</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Google Research" target="PaLM">
  <data key="d8">developed</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Jakob Uszkoreit" target="Vision Transformer (ViT)">
  <data key="d8">is a co-author of</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Encoder" target="Multi-Head Attention">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Decoder" target="Multi-Head Attention">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Multi-Head Attention" target="Attention Function">
  <data key="d8">is_a</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Scaled Dot-Product Attention" target="Attention Function">
  <data key="d8">is_a</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Residual Connection" target="Encoder">
  <data key="d8">is_used_in</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Residual Connection" target="Decoder">
  <data key="d8">is_used_in</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Layer Normalization" target="Encoder">
  <data key="d8">is_used_in</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Layer Normalization" target="Decoder">
  <data key="d8">is_used_in</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Feed-Forward Network" target="Encoder">
  <data key="d8">is_used_in</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Feed-Forward Network" target="Decoder">
  <data key="d8">is_used_in</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Softmax Function" target="Decoder">
  <data key="d8">is_used_in</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Self-Attention" target="Transformer">
  <data key="d8">is_used_in</data>
  <data key="d9">1</data>
  <data key="d10">reformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Positional Encoding" target="Transformer">
  <data key="d8">is_used_in</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Positional Encoding" target="Transformer-XL">
  <data key="d8">is used in</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Positional Encoding" target="Positional Encoding">
  <data key="d8">extends</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Penn Treebank" target="Wall Street Journal">
  <data key="d8">contains</data>
  <data key="d9">1</data>
  <data key="d10">attention_is_all_you_need</data>
  <data key="d11">0.9</data>
</edge>
<edge source="CLIP" target="zero-shot transfer">
  <data key="d8">achieves</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.9</data>
</edge>
<edge source="CLIP" target="WIT">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.9</data>
</edge>
<edge source="CLIP" target="zero-shot learning">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.9</data>
</edge>
<edge source="CLIP" target="cross_entropy_loss">
  <data key="d8">is_trained_with</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.9</data>
</edge>
<edge source="CLIP" target="ImageNet">
  <data key="d8">improves</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.9</data>
</edge>
<edge source="CLIP" target="ResNet-50">
  <data key="d8">matches_performance_of</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.8</data>
</edge>
<edge source="CLIP" target="Visual N-Grams">
  <data key="d8">outperforms</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.9</data>
</edge>
<edge source="CLIP" target="YFCC100M">
  <data key="d8">trained_on</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.8</data>
</edge>
<edge source="CLIP" target="Yahoo">
  <data key="d8">reduces_errors_on</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.9</data>
</edge>
<edge source="CLIP" target="SUN">
  <data key="d8">doubles_accuracy_on</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.85</data>
</edge>
<edge source="CLIP" target="visual feature Z">
  <data key="d8">provides</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.9</data>
</edge>
<edge source="GPT-3" target="OpenAI">
  <data key="d8">developed_by</data>
  <data key="d9">2</data>
  <data key="d10">gpt3_language_models,gpt3</data>
  <data key="d11">1.0</data>
</edge>
<edge source="GPT-3" target="few-shot learning">
  <data key="d8">applies_to</data>
  <data key="d9">2</data>
  <data key="d10">gpt3_language_models,gpt3</data>
  <data key="d11">1.0</data>
</edge>
<edge source="GPT-3" target="translation">
  <data key="d8">achieves_performance_on</data>
  <data key="d9">2</data>
  <data key="d10">gpt3_language_models,gpt3</data>
  <data key="d11">0.9</data>
</edge>
<edge source="GPT-3" target="question-answering">
  <data key="d8">achieves_performance_on</data>
  <data key="d9">2</data>
  <data key="d10">gpt3_language_models,gpt3</data>
  <data key="d11">0.9</data>
</edge>
<edge source="GPT-3" target="cloze tasks">
  <data key="d8">achieves_performance_on</data>
  <data key="d9">2</data>
  <data key="d10">gpt3_language_models,gpt3</data>
  <data key="d11">0.9</data>
</edge>
<edge source="GPT-3" target="Natural Questions">
  <data key="d8">evaluated_on</data>
  <data key="d9">2</data>
  <data key="d10">gpt3_language_models,gpt3</data>
  <data key="d11">0.9</data>
</edge>
<edge source="GPT-3" target="CoQA">
  <data key="d8">evaluated_on</data>
  <data key="d9">2</data>
  <data key="d10">gpt3_language_models,gpt3</data>
  <data key="d11">0.9</data>
</edge>
<edge source="GPT-3" target="TriviaQA">
  <data key="d8">evaluated_on</data>
  <data key="d9">2</data>
  <data key="d10">gpt3_language_models,gpt3</data>
  <data key="d11">0.9</data>
</edge>
<edge source="GPT-3" target="in-context learning">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">gpt3_language_models</data>
  <data key="d11">0.95</data>
</edge>
<edge source="GPT-3" target="V100 GPU">
  <data key="d8">uses</data>
  <data key="d9">2</data>
  <data key="d10">gpt3_language_models,gpt3</data>
  <data key="d11">0.9</data>
</edge>
<edge source="GPT-3" target="task-specific fine-tuning">
  <data key="d8">requires</data>
  <data key="d9">1</data>
  <data key="d10">gpt3</data>
  <data key="d11">0.8</data>
</edge>
<edge source="GPT-3" target="CommonCrawl">
  <data key="d8">is trained on</data>
  <data key="d9">1</data>
  <data key="d10">gpt3</data>
  <data key="d11">0.8</data>
</edge>
<edge source="GPT-3" target="Common Crawl">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">gpt3</data>
  <data key="d11">0.9</data>
</edge>
<edge source="GPT-3" target="WebText">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">gpt3</data>
  <data key="d11">0.85</data>
</edge>
<edge source="GPT-3" target="Books1">
  <data key="d8">uses</data>
  <data key="d9">2</data>
  <data key="d10">gpt3,gpt3</data>
  <data key="d11">0.85</data>
</edge>
<edge source="GPT-3" target="Wikipedia">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">gpt3</data>
  <data key="d11">0.85</data>
</edge>
<edge source="GPT-3" target="LLaMA-I">
  <data key="d8">is_compared_with</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="ImageNet" target="ImageNet-21k">
  <data key="d8">is_a_subset_of</data>
  <data key="d9">2</data>
  <data key="d10">reformer,vision_transformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="ImageNet" target="fine-tuning">
  <data key="d8">used_for</data>
  <data key="d9">1</data>
  <data key="d10">vision_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="ResNet-50" target="CLIP">
  <data key="d8">matches accuracy of</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.85</data>
</edge>
<edge source="OpenAI" target="CLIP">
  <data key="d8">developed</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.9</data>
</edge>
<edge source="OpenAI" target="Johns Hopkins University">
  <data key="d8">associated_with</data>
  <data key="d9">1</data>
  <data key="d10">gpt3</data>
  <data key="d11">0.7</data>
</edge>
<edge source="OpenAI" target="GPT-3">
  <data key="d8">developed</data>
  <data key="d9">1</data>
  <data key="d10">gpt3</data>
  <data key="d11">0.9</data>
</edge>
<edge source="zero-shot transfer" target="meta-learning">
  <data key="d8">is_a</data>
  <data key="d9">1</data>
  <data key="d10">gpt3_language_models</data>
  <data key="d11">0.9</data>
</edge>
<edge source="EfficientNet" target="ResNet-101">
  <data key="d8">is_related_to</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.6</data>
</edge>
<edge source="WebText" target="Common Crawl">
  <data key="d8">augments</data>
  <data key="d9">1</data>
  <data key="d10">gpt3_language_models</data>
  <data key="d11">0.85</data>
</edge>
<edge source="ResNet-101" target="Vision Transformer (ViT)">
  <data key="d8">is compared_with,is_compared_with</data>
  <data key="d9">2</data>
  <data key="d10">deit,reformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="ResNet-101" target="ViT">
  <data key="d8">is_used_as_baseline_for</data>
  <data key="d9">1</data>
  <data key="d10">reformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="ResNet-101" target="Transformer">
  <data key="d8">applies_before</data>
  <data key="d9">1</data>
  <data key="d10">vision_transformer</data>
  <data key="d11">0.7</data>
</edge>
<edge source="Vision Transformer (ViT)" target="Transformer">
  <data key="d8">is based_on,is_based_on</data>
  <data key="d9">2</data>
  <data key="d10">deit,reformer</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Vision Transformer (ViT)" target="ImageNet-21k">
  <data key="d8">is trained_on,is_pretrained_on</data>
  <data key="d9">3</data>
  <data key="d10">deit,reformer,vision_transformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Vision Transformer (ViT)" target="JFT-300M">
  <data key="d8">is trained_on,is_pretrained_on</data>
  <data key="d9">3</data>
  <data key="d10">deit,reformer,vision_transformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Vision Transformer (ViT)" target="ImageNet">
  <data key="d8">is evaluated_on</data>
  <data key="d9">2</data>
  <data key="d10">deit,vision_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Vision Transformer (ViT)" target="CIFAR-10">
  <data key="d8">is evaluated_on</data>
  <data key="d9">2</data>
  <data key="d10">deit,vision_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Vision Transformer (ViT)" target="VTAB">
  <data key="d8">is evaluated_on</data>
  <data key="d9">2</data>
  <data key="d10">deit,vision_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Vision Transformer (ViT)" target="Transformer Encoder">
  <data key="d8">is_based_on</data>
  <data key="d9">3</data>
  <data key="d10">deit,reformer,vision_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Vision Transformer (ViT)" target="MLP Head">
  <data key="d8">uses</data>
  <data key="d9">3</data>
  <data key="d10">deit,reformer,vision_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Vision Transformer (ViT)" target="ResNet-101">
  <data key="d8">is_compared_with</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.8</data>
</edge>
<edge source="Vision Transformer (ViT)" target="self-attention">
  <data key="d8">uses</data>
  <data key="d9">3</data>
  <data key="d10">deit,reformer,vision_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Vision Transformer (ViT)" target="Transformers">
  <data key="d8">is based_on</data>
  <data key="d9">1</data>
  <data key="d10">vision_transformer</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Visual N-Grams" target="CLIP">
  <data key="d8">compares_to</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Visual N-Grams" target="Elhoseiny et al. (2013)">
  <data key="d8">dates_back_to</data>
  <data key="d9">1</data>
  <data key="d10">clip</data>
  <data key="d11">0.7</data>
</edge>
<edge source="Alexey Dosovitskiy" target="Vision Transformer (ViT)">
  <data key="d8">is a co-author of</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Lucas Beyer" target="Vision Transformer (ViT)">
  <data key="d8">is a co-author of</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Alexander Kolesnikov" target="Vision Transformer (ViT)">
  <data key="d8">is a co-author of</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Dirk Weissenborn" target="Vision Transformer (ViT)">
  <data key="d8">is a co-author of</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Xiaohua Zhai" target="Vision Transformer (ViT)">
  <data key="d8">is a co-author of</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Thomas Unterthiner" target="Vision Transformer (ViT)">
  <data key="d8">is a co-author of</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Mostafa Dehghani" target="Vision Transformer (ViT)">
  <data key="d8">is a co-author of</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Matthias Minderer" target="Vision Transformer (ViT)">
  <data key="d8">is a co-author of</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Georg Heigold" target="Vision Transformer (ViT)">
  <data key="d8">is a co-author of</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Sylvain Gelly" target="Vision Transformer (ViT)">
  <data key="d8">is a co-author of</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Neil Houlsby" target="Vision Transformer (ViT)">
  <data key="d8">is a co-author of</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.95</data>
</edge>
<edge source="ImageNet-21k" target="ILSVRC-2012 ImageNet">
  <data key="d8">is_a_superset_of</data>
  <data key="d9">2</data>
  <data key="d10">deit,vision_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="ImageNet-21k" target="ImageNet">
  <data key="d8">is_a_superset_of</data>
  <data key="d9">2</data>
  <data key="d10">reformer,vision_transformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="ImageNet-21k" target="pre-training">
  <data key="d8">used_for</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Transformer Encoder" target="Vaswani et al. (2017)">
  <data key="d8">is_inspired_by</data>
  <data key="d9">1</data>
  <data key="d10">reformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Position Embeddings" target="Longformer">
  <data key="d8">supports</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Self-Supervised Learning" target="Vision Transformer (ViT)">
  <data key="d8">is_used_in,is_applied_to</data>
  <data key="d9">2</data>
  <data key="d10">deit,reformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="Vaswani et al. (2017)" target="Transformer architecture">
  <data key="d8">introduces,proposed,introduced</data>
  <data key="d9">5</data>
  <data key="d10">deit,transformer_xl,transformer_xl,transformer_xl,vision_transformer</data>
  <data key="d11">0.95</data>
</edge>
<edge source="ILSVRC-2012 ImageNet" target="ImageNet-21k">
  <data key="d8">is_a_subset_of</data>
  <data key="d9">3</data>
  <data key="d10">deit,reformer,vision_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="ViT-Base" target="BERT">
  <data key="d8">is_based_on</data>
  <data key="d9">3</data>
  <data key="d10">deit,reformer,vision_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="ViT-Large" target="BERT">
  <data key="d8">is_based_on</data>
  <data key="d9">6</data>
  <data key="d10">deit,deit,reformer,reformer,vision_transformer,vision_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="SGD" target="fine-tuning">
  <data key="d8">is_used_for</data>
  <data key="d9">2</data>
  <data key="d10">deit,reformer</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Noisy Student" target="ViT-H/14">
  <data key="d8">is_compared_with,is_compared_to</data>
  <data key="d9">2</data>
  <data key="d10">reformer,vision_transformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Big Transfer (BiT)" target="ViT-H/14">
  <data key="d8">is_compared_with,is_compared_to</data>
  <data key="d9">2</data>
  <data key="d10">reformer,vision_transformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="ViT-L/16" target="Big Transfer (BiT)">
  <data key="d8">compares_to</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.9</data>
</edge>
<edge source="ViT-L/16" target="ImageNet-21k">
  <data key="d8">pre_trained_on,is_pretrained_on</data>
  <data key="d9">4</data>
  <data key="d10">deit,reformer,vision_transformer,vision_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="ViT-L/16" target="TPUv3">
  <data key="d8">trained_using</data>
  <data key="d9">2</data>
  <data key="d10">deit,reformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="ViT-L/16" target="JFT-300M">
  <data key="d8">is_pretrained_on</data>
  <data key="d9">1</data>
  <data key="d10">vision_transformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="ViT-L/16" target="VTAB">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">vision_transformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="BiT" target="ViT">
  <data key="d8">compared_to</data>
  <data key="d9">2</data>
  <data key="d10">reformer,vision_transformer</data>
  <data key="d11">0.75</data>
</edge>
<edge source="ViT-H/14" target="Noisy Student">
  <data key="d8">compares_to</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.9</data>
</edge>
<edge source="ViT-H/14" target="BiT">
  <data key="d8">outperforms</data>
  <data key="d9">1</data>
  <data key="d10">reformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Hybrid models" target="ViT">
  <data key="d8">outperform</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.6</data>
</edge>
<edge source="self-attention" target="Swin Transformer">
  <data key="d8">is_used_in</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">1.0</data>
</edge>
<edge source="CNN" target="Vision Transformer (ViT)">
  <data key="d8">is_compared_with</data>
  <data key="d9">1</data>
  <data key="d10">reformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="self-supervised pre-training" target="accuracy">
  <data key="d8">improves</data>
  <data key="d9">1</data>
  <data key="d10">vision_transformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="NLP" target="language tasks">
  <data key="d8">contains</data>
  <data key="d9">1</data>
  <data key="d10">gpt3_language_models</data>
  <data key="d11">0.9</data>
</edge>
<edge source="NLP" target="few-shot learning">
  <data key="d8">contains</data>
  <data key="d9">1</data>
  <data key="d10">gpt3</data>
  <data key="d11">1.0</data>
</edge>
<edge source="few-shot learning" target="meta-learning">
  <data key="d8">is_a</data>
  <data key="d9">2</data>
  <data key="d10">gpt3_language_models,gpt3_language_models</data>
  <data key="d11">0.9</data>
</edge>
<edge source="pre-training" target="fine-tuning">
  <data key="d8">followed_by</data>
  <data key="d9">1</data>
  <data key="d10">gpt3_language_models</data>
  <data key="d11">0.9</data>
</edge>
<edge source="pre-training" target="Vision Transformer (ViT)">
  <data key="d8">is_applied_to</data>
  <data key="d9">1</data>
  <data key="d10">reformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="fine-tuning" target="Vision Transformer (ViT)">
  <data key="d8">is_applied_to</data>
  <data key="d9">1</data>
  <data key="d10">reformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Common Crawl" target="GPT-3">
  <data key="d8">used_for_training</data>
  <data key="d9">1</data>
  <data key="d10">gpt3_language_models</data>
  <data key="d11">0.95</data>
</edge>
<edge source="societal impacts" target="GPT-3">
  <data key="d8">discussed_in</data>
  <data key="d9">1</data>
  <data key="d10">gpt3_language_models</data>
  <data key="d11">0.9</data>
</edge>
<edge source="in-context learning" target="meta-learning">
  <data key="d8">is_a</data>
  <data key="d9">2</data>
  <data key="d10">gpt3_language_models,gpt3</data>
  <data key="d11">0.95</data>
</edge>
<edge source="RWC+19" target="in-context learning">
  <data key="d8">discusses</data>
  <data key="d9">1</data>
  <data key="d10">gpt3_language_models</data>
  <data key="d11">0.8</data>
</edge>
<edge source="Books1" target="Common Crawl">
  <data key="d8">augments</data>
  <data key="d9">2</data>
  <data key="d10">gpt3_language_models,gpt3_language_models</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Wikipedia" target="Common Crawl">
  <data key="d8">augments</data>
  <data key="d9">1</data>
  <data key="d10">gpt3_language_models</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Sparse Transformer" target="Transformer architecture">
  <data key="d8">extends</data>
  <data key="d9">1</data>
  <data key="d10">gpt3_language_models</data>
  <data key="d11">0.8</data>
</edge>
<edge source="Validation loss" target="GPT-3">
  <data key="d8">is_measured_for</data>
  <data key="d9">1</data>
  <data key="d10">gpt3</data>
  <data key="d11">0.9</data>
</edge>
<edge source="K" target="few-shot learning">
  <data key="d8">is_used_in</data>
  <data key="d9">1</data>
  <data key="d10">gpt3</data>
  <data key="d11">0.8</data>
</edge>
<edge source="LLaMA-I" target="GPT-3">
  <data key="d8">outperforms,compares_with</data>
  <data key="d9">2</data>
  <data key="d10">llama,llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="Chinchilla">
  <data key="d8">is_competitive_with,compares_with</data>
  <data key="d9">2</data>
  <data key="d10">llama,llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="PaLM">
  <data key="d8">is_competitive_with,compares_with</data>
  <data key="d9">2</data>
  <data key="d10">llama,llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="CommonCrawl">
  <data key="d8">trained_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="C4">
  <data key="d8">trained_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="Github">
  <data key="d8">trained_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="Wikipedia">
  <data key="d8">trained_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="Books">
  <data key="d8">trained_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="ArXiv">
  <data key="d8">trained_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="StackExchange">
  <data key="d8">trained_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="Transformer Architecture">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="Performance Metrics">
  <data key="d8">evaluated_by</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="Gopher">
  <data key="d8">compares_with</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="OPT">
  <data key="d8">compares_with</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="OPT-IML">
  <data key="d8">compares_with</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.8</data>
</edge>
<edge source="LLaMA-I" target="LaMDA">
  <data key="d8">compares_with</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.8</data>
</edge>
<edge source="LLaMA-I" target="Natural Questions">
  <data key="d8">evaluates_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="TriviaQA">
  <data key="d8">evaluates_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="MATH">
  <data key="d8">evaluates_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="GSM8k">
  <data key="d8">evaluates_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="RACE">
  <data key="d8">evaluates_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="BoolQ">
  <data key="d8">evaluates_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.8</data>
</edge>
<edge source="LLaMA-I" target="Flan-PaLM">
  <data key="d8">evaluates_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.8</data>
</edge>
<edge source="LLaMA-I" target="Exact Match">
  <data key="d8">achieves_performance</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-I" target="pass@">
  <data key="d8">achieves_performance</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Chinchilla" target="LLaMA-I">
  <data key="d8">is_compared_with</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="PaLM" target="LLaMA-I">
  <data key="d8">is_compared_with</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="PaLM" target="Transformer">
  <data key="d8">is_based_on,based_on</data>
  <data key="d9">2</data>
  <data key="d10">palm,palm</data>
  <data key="d11">0.95</data>
</edge>
<edge source="PaLM" target="Pathways">
  <data key="d8">uses,is based_on</data>
  <data key="d9">2</data>
  <data key="d10">palm,palm</data>
  <data key="d11">0.9</data>
</edge>
<edge source="PaLM" target="TPUv4">
  <data key="d8">trained_on</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">0.9</data>
</edge>
<edge source="PaLM" target="GPT-3">
  <data key="d8">outperforms</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">0.8</data>
</edge>
<edge source="PaLM" target="BIG-bench">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">0.9</data>
</edge>
<edge source="PaLM" target="SwiGLU">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">0.9</data>
</edge>
<edge source="PaLM" target="RoPE">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">0.9</data>
</edge>
<edge source="PaLM" target="SentencePiece">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">0.85</data>
</edge>
<edge source="PaLM" target="WinoGender">
  <data key="d8">evaluates</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">0.8</data>
</edge>
<edge source="PaLM" target="540B parameters">
  <data key="d8">has_model_scale</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">1.0</data>
</edge>
<edge source="PaLM" target="62B parameters">
  <data key="d8">has_model_scale</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">1.0</data>
</edge>
<edge source="PaLM" target="8B parameters">
  <data key="d8">has_model_scale</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">1.0</data>
</edge>
<edge source="PaLM" target="780 billion tokens">
  <data key="d8">trained_on</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">1.0</data>
</edge>
<edge source="PaLM" target="JAX">
  <data key="d8">trained_using</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">1.0</data>
</edge>
<edge source="PaLM" target="T5X">
  <data key="d8">trained_using</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Transformer Architecture" target="Vaswani et al. (2017)">
  <data key="d8">is_based_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Gopher" target="LLaMA-I">
  <data key="d8">is_compared_with</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Gopher" target="GPT-3">
  <data key="d8">outperforms</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.85</data>
</edge>
<edge source="LLaMA-65B" target="Chinchilla">
  <data key="d8">outperforms</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-65B" target="PaLM">
  <data key="d8">outperforms</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaMA-65B" target="RealToxicityPrompts">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.7</data>
</edge>
<edge source="Zhang et al. (2022)" target="Hoffmann et al. (2022)">
  <data key="d8">cites</data>
  <data key="d9">1</data>
  <data key="d10">llama</data>
  <data key="d11">0.8</data>
</edge>
<edge source="Perplexity" target="Transformer-XL">
  <data key="d8">is reduced by</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Longformer" target="self-attention">
  <data key="d8">improves</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Longformer" target="RoBERTa">
  <data key="d8">outperforms,improves,is_based_on</data>
  <data key="d9">3</data>
  <data key="d10">longformer,longformer,longformer</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Longformer" target="text8">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Longformer" target="enwik8">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Longformer" target="WikiHop">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Longformer" target="TriviaQA">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Longformer" target="LED">
  <data key="d8">used_in</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="Longformer" target="Transformer architecture">
  <data key="d8">based_on</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Longformer" target="Sparse Transformer">
  <data key="d8">compared_to</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="Longformer" target="Transformer">
  <data key="d8">is_based_on</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Longformer" target="Attention Pattern">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Longformer" target="Position Embeddings">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Longformer" target="MLM">
  <data key="d8">is_pretrained_with</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Longformer" target="BERT">
  <data key="d8">compared_with</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="enwik8" target="text8">
  <data key="d8">is compared with</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.7</data>
</edge>
<edge source="Transformer-XL" target="Longformer">
  <data key="d8">compared_to</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.75</data>
</edge>
<edge source="Transformer-XL" target="long-term dependency">
  <data key="d8">improves</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Transformer-XL" target="context fragmentation">
  <data key="d8">resolves</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Transformer-XL" target="Positional Encoding">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Transformer-XL" target="Perplexity">
  <data key="d8">improves</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Transformer-XL" target="AWD-LSTM">
  <data key="d8">compared_with</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Transformer-XL" target="One Billion Word">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.8</data>
</edge>
<edge source="Transformer-XL" target="WikiText-103">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.8</data>
</edge>
<edge source="BlockSparse" target="TensorFlow">
  <data key="d8">is_designed_for</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="LED" target="Longformer">
  <data key="d8">is_a_variant_of</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.95</data>
</edge>
<edge source="CPC loss" target="pre-training">
  <data key="d8">is_used_for</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="BigBird" target="ETC">
  <data key="d8">is_an_extension_of</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Ye et al. (2019)" target="BP-Transformer">
  <data key="d8">discusses</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="BERT" target="T5">
  <data key="d8">is_related_to</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">0.7</data>
</edge>
<edge source="Adaptive Span" target="Longformer">
  <data key="d8">compared_to</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.7</data>
</edge>
<edge source="Compressive Transformer" target="Longformer">
  <data key="d8">compared_to</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.7</data>
</edge>
<edge source="Ott et al." target="fairseq">
  <data key="d8">developed</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Devlin et al." target="BERT">
  <data key="d8">developed</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Liu et al." target="RoBERTa">
  <data key="d8">developed</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Rae et al." target="Compressive Transformer">
  <data key="d8">discussed</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="Longformer-large" target="RoBERTa-large">
  <data key="d8">improves</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Longformer-large" target="WikiHop">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Longformer-large" target="TriviaQA">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Longformer-large" target="HotpotQA">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Longformer-large" target="coreference resolution">
  <data key="d8">used_for</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="OntoNotes" target="coreference resolution">
  <data key="d8">used_for</data>
  <data key="d9">1</data>
  <data key="d10">longformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Transformer architecture" target="GPT-3">
  <data key="d8">is used in</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">0.95</data>
</edge>
<edge source="780 billion tokens" target="GitHub">
  <data key="d8">composed_of</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">1.0</data>
</edge>
<edge source="780 billion tokens" target="Wikipedia">
  <data key="d8">composed_of</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Pathways system" target="TPU v4">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Pathways system" target="JAX/XLA">
  <data key="d8">executes</data>
  <data key="d9">1</data>
  <data key="d10">palm</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaVA" target="GPT-3">
  <data key="d8">is_based_on,compared_to,is evaluated by</data>
  <data key="d9">3</data>
  <data key="d10">segment_anything,segment_anything,segment_anything</data>
  <data key="d11">1.0</data>
</edge>
<edge source="LLaVA" target="CLIP">
  <data key="d8">connects,uses</data>
  <data key="d9">2</data>
  <data key="d10">segment_anything,segment_anything</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaVA" target="Vicuna">
  <data key="d8">connects,is based on</data>
  <data key="d9">2</data>
  <data key="d10">segment_anything,segment_anything</data>
  <data key="d11">0.8</data>
</edge>
<edge source="LLaVA" target="Science QA">
  <data key="d8">is_evaluated_on,is_fine_tuned_on</data>
  <data key="d9">2</data>
  <data key="d10">segment_anything,segment_anything</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaVA" target="multi-turn conversation data">
  <data key="d8">is trained on</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaVA" target="Flamingo">
  <data key="d8">compares to</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.6</data>
</edge>
<edge source="LLaVA" target="BLIP-2">
  <data key="d8">compares to,compared_to,compares_with</data>
  <data key="d9">3</data>
  <data key="d10">segment_anything,segment_anything,segment_anything</data>
  <data key="d11">1.0</data>
</edge>
<edge source="LLaVA" target="OpenFlamingo">
  <data key="d8">compared_to,compares_with</data>
  <data key="d9">2</data>
  <data key="d10">segment_anything,segment_anything</data>
  <data key="d11">1.0</data>
</edge>
<edge source="LLaVA" target="LLaVA-Bench">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.95</data>
</edge>
<edge source="LLaVA" target="instruction-following capability">
  <data key="d8">improves</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.9</data>
</edge>
<edge source="LLaVA-Bench" target="COCO-Val-2014">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.9</data>
</edge>
<edge source="BLIP-2" target="LMM">
  <data key="d8">is_a</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.9</data>
</edge>
<edge source="FROMAGe" target="LMM">
  <data key="d8">is_a</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.9</data>
</edge>
<edge source="KOSMOS-1" target="LMM">
  <data key="d8">is_a</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.9</data>
</edge>
<edge source="PaLM-E" target="LMM">
  <data key="d8">is_a</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.9</data>
</edge>
<edge source="OpenFlamingo" target="LLaMA-I">
  <data key="d8">is_based_on</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.8</data>
</edge>
<edge source="LLaMA-Adapter" target="LLaMA-I">
  <data key="d8">is_based_on</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.8</data>
</edge>
<edge source="visual feature Z" target="language embedding tokens H">
  <data key="d8">is converted to</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.8</data>
</edge>
<edge source="projection matrix W" target="visual feature Z">
  <data key="d8">connects</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.85</data>
</edge>
<edge source="multi-turn conversation data" target="instruction tokens X">
  <data key="d8">contains</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.8</data>
</edge>
<edge source="multi-turn conversation data" target="assistant answers X">
  <data key="d8">contains</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">0.8</data>
</edge>
<edge source="evaluation metric" target="instruction-following capability">
  <data key="d8">measures</data>
  <data key="d9">1</data>
  <data key="d10">segment_anything</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Swin Transformer" target="ViT/DeiT">
  <data key="d8">outperforms</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Swin Transformer" target="DetectoRS">
  <data key="d8">outperforms</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Swin Transformer" target="SETR">
  <data key="d8">outperforms</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Swin Transformer" target="ResNet-50">
  <data key="d8">is similar to</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.75</data>
</edge>
<edge source="Swin Transformer" target="ResNet-101">
  <data key="d8">is similar to</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.75</data>
</edge>
<edge source="Swin Transformer" target="ImageNet-21k">
  <data key="d8">evaluated_on</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Swin Transformer" target="DeiT">
  <data key="d8">compared_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Swin Transformer" target="EfficientNet">
  <data key="d8">compared_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="Swin Transformer" target="RegNet">
  <data key="d8">compared_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="Swin Transformer" target="AdamW">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Swin Transformer" target="Relative Position Bias">
  <data key="d8">contains</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Swin Transformer" target="Top-1 Accuracy">
  <data key="d8">achieves</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Swin Transformer" target="FLOPs">
  <data key="d8">has</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Swin Transformer" target="HTC++">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Microsoft Research Asia" target="Ze Liu">
  <data key="d8">affiliated_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Microsoft Research Asia" target="Yutong Lin">
  <data key="d8">affiliated_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Microsoft Research Asia" target="Yue Cao">
  <data key="d8">affiliated_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Microsoft Research Asia" target="Han Hu">
  <data key="d8">affiliated_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Microsoft Research Asia" target="Yixuan Wei">
  <data key="d8">affiliated_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Microsoft Research Asia" target="Zheng Zhang">
  <data key="d8">affiliated_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Microsoft Research Asia" target="Stephen Lin">
  <data key="d8">affiliated_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">1.0</data>
</edge>
<edge source="Microsoft Research Asia" target="Baining Guo">
  <data key="d8">affiliated_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">1.0</data>
</edge>
<edge source="feature pyramid networks (FPN)" target="Swin Transformer">
  <data key="d8">is_used_in</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="U-Net" target="Swin Transformer">
  <data key="d8">is_used_in</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="ViT" target="Transformer architecture">
  <data key="d8">is based on</data>
  <data key="d9">1</data>
  <data key="d10">deit</data>
  <data key="d11">0.95</data>
</edge>
<edge source="ViT" target="JFT-300M">
  <data key="d8">pre_trained_on,requires</data>
  <data key="d9">3</data>
  <data key="d10">reformer,swin_transformer,vision_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="ViT" target="weight decay">
  <data key="d8">optimized_with</data>
  <data key="d9">2</data>
  <data key="d10">reformer,vision_transformer</data>
  <data key="d11">0.7</data>
</edge>
<edge source="ViT" target="dropout">
  <data key="d8">optimized_with</data>
  <data key="d9">2</data>
  <data key="d10">reformer,vision_transformer</data>
  <data key="d11">0.7</data>
</edge>
<edge source="ViT" target="label smoothing">
  <data key="d8">optimized_with</data>
  <data key="d9">2</data>
  <data key="d10">reformer,vision_transformer</data>
  <data key="d11">0.7</data>
</edge>
<edge source="Stage 1" target="Stage 1">
  <data key="d8">is followed by</data>
  <data key="d9">3</data>
  <data key="d10">swin_transformer,swin_transformer,swin_transformer</data>
  <data key="d11">0.95</data>
</edge>
<edge source="Swin-T" target="ImageNet-21k">
  <data key="d8">fine-tuned_on</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Swin-T" target="ViT">
  <data key="d8">compared_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="Swin-T" target="DeiT-S">
  <data key="d8">compared_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="Cascade Mask R-CNN" target="Swin-T">
  <data key="d8">used_with</data>
  <data key="d9">1</data>
  <data key="d10">swin_transformer</data>
  <data key="d11">0.85</data>
</edge>
<edge source="LSTM" target="Transformer-XL">
  <data key="d8">is compared to</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.8</data>
</edge>
<edge source="RNN" target="Transformer-XL">
  <data key="d8">is compared to,compared_to</data>
  <data key="d9">2</data>
  <data key="d10">transformer_xl,transformer_xl</data>
  <data key="d11">0.8</data>
</edge>
<edge source="SG function" target="Transformer-XL">
  <data key="d8">is used in</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.85</data>
</edge>
<edge source="hidden state" target="Transformer-XL">
  <data key="d8">are_cached_in</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.9</data>
</edge>
<edge source="long-term dependency" target="Transformer-XL">
  <data key="d8">is modeled by</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.8</data>
</edge>
<edge source="BPTT" target="RNN">
  <data key="d8">is_based_on</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.85</data>
</edge>
<edge source="query vector" target="key vector">
  <data key="d8">attends_on</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Shaw et al. (2018)" target="Transformer-XL">
  <data key="d8">compares_with</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.7</data>
</edge>
<edge source="Huang et al. (2018)" target="Positional Encoding">
  <data key="d8">uses</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.75</data>
</edge>
<edge source="absolute positional embedding" target="absolute positional embedding">
  <data key="d8">is replaced by</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.8</data>
</edge>
<edge source="u" target="query vector">
  <data key="d8">replaces</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.85</data>
</edge>
<edge source="v" target="query vector">
  <data key="d8">substitutes</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.85</data>
</edge>
<edge source="Khandelwal et al. (2018)" target="Effective Context Length (ECL)">
  <data key="d8">proposed</data>
  <data key="d9">1</data>
  <data key="d10">transformer_xl</data>
  <data key="d11">0.9</data>
</edge>
<edge source="Self-Supervision" target="Vision Transformer">
  <data key="d8">is_explored_for</data>
  <data key="d9">1</data>
  <data key="d10">vision_transformer</data>
  <data key="d11">0.8</data>
</edge>
<edge source="hybrids" target="ViT">
  <data key="d8">outperform</data>
  <data key="d9">2</data>
  <data key="d10">reformer,vision_transformer</data>
  <data key="d11">0.6</data>
</edge>
<edge source="position embeddings" target="2D image topology">
  <data key="d8">represent</data>
  <data key="d9">1</data>
  <data key="d10">vision_transformer</data>
  <data key="d11">0.8</data>
</edge>
</graph></graphml>